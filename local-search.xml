<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>【马克思主义基本原理】论文：马克思技术观在当代的应用和启示</title>
    <link href="/2025/11/28/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E9%A9%AC%E5%85%8B%E6%80%9D%E6%8A%80%E6%9C%AF%E8%A7%82%E5%9C%A8%E5%BD%93%E4%BB%A3%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%90%AF%E7%A4%BA/"/>
    <url>/2025/11/28/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E9%A9%AC%E5%85%8B%E6%80%9D%E6%8A%80%E6%9C%AF%E8%A7%82%E5%9C%A8%E5%BD%93%E4%BB%A3%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E5%90%AF%E7%A4%BA/</url>
    
    <content type="html"><![CDATA[<center><h1 id="马克思眼中的19世纪和我们的21世纪"><a href="#马克思眼中的19世纪和我们的21世纪" class="headerlink" title="马克思眼中的19世纪和我们的21世纪"></a>马克思眼中的19世纪和我们的21世纪</h1><h2 id="——马克思技术观在当代的应用和启示"><a href="#——马克思技术观在当代的应用和启示" class="headerlink" title="——马克思技术观在当代的应用和启示"></a>——马克思技术观在当代的应用和启示</h2></center><h2 id="文本摘录"><a href="#文本摘录" class="headerlink" title="文本摘录"></a>文本摘录</h2><blockquote><p>由于推广机器和分工，无产者的劳动已经失去了任何独立的性质，因而对工人也失去了任何吸引力。工人变成了机器的单纯的附属品，要求他做的只是极其简单、极其单调和极容易学会的操作。因此，花在工人身上的费用，几乎只限于维持工人生活和延续工人后代所必需的生活资料。但是，商品的价格，从而劳动的价格，是同它的生产费用相等的。因此，劳动越使人感到厌恶，工资也就越减少。不仅如此，机器越推广，分工越细致，劳动量也就越增加，这或者是由于工作时间的延长，或者是由于在一定时间内所要求的劳动的增加，机器运转的加速，等等。</p><p>……</p><p>手的操作所要求的技巧和气力越少，换句话说，现代工业越发达，男工也就越受到女工和童工的排挤。对工人阶级来说，性别和年龄的差别再没有什么社会意义了。他们都只是劳动工具，不过因为年龄和性别的不同而需要不同的费用罢了。</p><p>马克思，《共产党宣言》 ——摘自《马克思恩格斯选集》第一卷，人民出版社，2012年，407-408页</p></blockquote><blockquote><p>这里有一件可以作为我们 19 世纪特征的伟大事实，一件任何政党都不敢否认的事实。一方面产生了以往人类历史上任何一个时代都不能想象的工业和科学的力量；而另一方面却显露出衰颓的征兆，这种衰颓远远超过罗马帝国末期那一切载诸史册的可怕情景。</p><p>在我们这个时代，每一种事物好像都包含有自己的反面。我们看到，机器具有减少人类劳动和使劳动更有成效的神奇力量，然而却引起了饥饿和过度的疲劳。财富的新源泉，由于某种奇怪的、不可思议的魔力而变成贫困的源泉。技术的胜利，似乎是以道德的败坏为代价换来的。随着人类愈益控制自然，个人却似乎愈益成为别人的奴隶或自身的卑劣行为的奴隶。甚至科学的纯洁光辉仿佛也只能在愚昧无知的黑暗背景上闪耀。我们的一切发明和进步，似乎结果是使物质力量成为有智慧的生命，而人的生命则化为愚钝的物质力量。现代工业和科学为一方与现代贫困和衰颓为另一方的这种对抗，我们时代的生产力与社会关系之间的这种对抗，是显而易见的、不可避免的和毋庸争辩的事实。有些党派可能为此痛哭流涕；另一些党派可能为了要摆脱现代冲突而希望抛开现代技术；还有一些党派可能以为工业上如此巨大的进步要以政治上同样巨大的倒退来补充。可是我们不会认错那个经常在这一切矛盾中出现的狡狯的精灵。我们知道，要使社会的新生力量很好地发挥作用，就只能由新生的人来掌握它们，而这些新生的人就是工人。</p><p>马克思，在《人民报》创刊纪念会上的演说 ——摘自《马克思恩格斯选集》第一卷，人民出版社，2012年，775-776页</p></blockquote><h2 id="内容分析"><a href="#内容分析" class="headerlink" title="内容分析"></a>内容分析</h2><h3 id="一、马克思眼中的十九世纪"><a href="#一、马克思眼中的十九世纪" class="headerlink" title="一、马克思眼中的十九世纪"></a>一、马克思眼中的十九世纪</h3><p>18世纪60年代，第一次工业革命带来的轰鸣作响的蒸汽机。机器替代了人工，工厂代替了工作坊。在马克思所处的19世纪，欧洲已经出现了广泛的技术变革：蒸汽动力的广泛应用：蒸汽机在工业生产、交通运输中的普及；纺织工业的机械化；电力技术的发展；钢铁工业的进步……</p><p>在生产力由于技术进步而得到了巨大发展的同时，一场暗中的变革也在悄然进行：机械化生产取代手工作坊；工人阶级逐步形成，大量农民转变为工厂工人，形成了新的社会阶层；城市化进程进一步加速，工厂周围逐渐形成了工业城市，人口也向着城市集中。这所带来的社会矛盾也渐渐凸显：贫富差距进一步扩大，工厂主积累大量财富，而工人生活条件却仍然恶劣，只能勉强果腹；劳资冲突频发，工人运动兴起；环境问题由于工业污染开始影响城市环境和居民健康而出现……</p><p>明明技术的发展带来了生产力的提升，为什么看起来社会的矛盾反而被进一步加剧了呢？马克思认为，技术的发展客观上促进了无产阶级的形成：“随着资产阶级即资本的发展，无产阶级即现代工人阶级也在同一程度上得到发展；现代的工人只有当他们找到工作的时候才能生存，而且只有当他们的劳动增殖资本的时候才能找到工作。这些不得不把自己零星出卖的工人，像其他任何货物一样，也是一种商品，所以他们同样地受到竞争的一切变化、市场的一切波动的影响。” </p><p>因此，马克思眼中的19世纪是一个充满矛盾的时代：技术进步带来了生产力的巨大发展，但这种发展并未使工人阶级获得解放，反而加深了他们的异化程度。资本主义生产方式通过技术革新不断扩大再生产的规模，同时也在不断强化对工人阶级的剥削和压迫，使得社会矛盾日益尖锐。</p><h3 id="二、我们所在的21世纪"><a href="#二、我们所在的21世纪" class="headerlink" title="二、我们所在的21世纪"></a>二、我们所在的21世纪</h3><p>在 21 世纪，计算机技术的飞速发展带来了两个强大的工具：生产自动化和互联网。这让社会生产力呈指数形式增长。自动化生产线取代了大量传统工人的工作岗位，而互联网则改变了劳动组织方式，催生出新型的”数字劳工”。这些技术进步虽然提高了生产效率，但也加剧了劳动力市场的不稳定性和工作的碎片化。与19世纪相似的是，技术进步并没有让工人获得更多自由，反而使他们更深地陷入了新形式的劳动异化之中。</p><p>自动化的产线进一步降低了工人的重要性。同时，人工智能和算法管理系统的引入，使得工人不仅要面对机器的物理替代，还要应对数字化监控和管理。在许多现代工厂和办公室中，工人的每一个动作都被精确记录和评估，工作节奏完全由算法决定，这种情况下工人实际上成为了数字系统的附属品。这种现象与马克思描述的工人成为”机器附属品”有着惊人的相似性。</p><p>更加重要的是，马克思在《共产党宣言》中提到的，“由于推广机器和分工，无产者的劳动已经失去了任何独立的性质，因而对工人也失去了任何吸引力。工人变成了机器的单纯的附属品，要求他做的只是极其简单、极其单调和极容易学会的操作。因此，花在工人身上的费用，几乎只限于维持工人生活和延续工人后代所必需的生活资料。……”已经被人工智能和算法管理系统进一步实现了：算法系统通过实时监控和数据分析，能够精确计算出工人的最大工作承受量，并将工资水平控制在一个能够维持基本生存但又难以积累财富的微妙平衡点。例如，在北上广深等一线城市，很多互联网公司的工资水平与当地的房租水平呈现出惊人的相关性：工资刚好能够负担起合租房的费用，但要想独立租房或购房则十分困难。这种精确的算法控制确保了工人只能维持最基本的生活需求，难以跳出”数字化生存”的困境。</p><p>另一个颇具说服力的例子是，大多数公司的“工资倒挂”现象。马克思说：“手的操作所要求的技巧和气力越少，换句话说，现代工业越发达，男工也就越受到女工和童工的排挤。对工人阶级来说，性别和年龄的差别再没有什么社会意义了。他们都只是劳动工具，不过因为年龄和性别的不同而需要不同的费用罢了。”这在当代大公司里被更加生动的体现：大多数应届生的工资可能是老员工的数倍之多，而经过几个月的培训之后，他们同样能胜任“老员工”的工作——甚至由于年轻，还能做得更多——而经过几年的迭代之后，同样成为老员工的他们，也被以各种圆满无漏的理由给“优化”掉。一个当代的笑话反映了这一点：“从来没有一个互联网公司的人事经历过到龄退休的手续。”</p><p>互联网的发展则更加复杂。一方面，互联网给人们提供了廉价的娱乐方式；另一方面，它又成为管理者监控和引导人们的利器。工人们通过互联网获得的娱乐消遣往往是被精心设计的”数字鸦片”，这不仅消耗了他们的闲暇时间，也在某种程度上麻痹了他们对现实处境的认知。同时，互联网平台通过数据收集和算法推送，能够更精准地掌握和引导工人的行为模式：通过算法推送不同的信息茧房，培养不同群体的对立情绪。例如，制造城市与农村、老年人与年轻人、不同地域人群之间的对立。这种分化策略使得工人阶级难以形成统一的阶级意识，反而陷入互相指责和内耗之中。资本正是利用这种分裂来削弱工人的团结，维持其统治地位。<br>总的来说，我们所处的21世纪与马克思所处的19世纪有着惊人的相似之处：技术进步带来的生产力提升并没有真正改善工人阶级的处境。相反，新的技术手段——自动化生产线、人工智能系统和互联网平台——在提高生产效率的同时，也成为了加强劳动控制和社会分化的工具。算法管理系统使工人成为数字系统的附属品，精确的薪资控制将工人维持在最低生存水平，而互联网则通过提供”数字鸦片”和制造群体对立来瓦解工人的团结意识。这些现象印证了马克思关于技术发展在资本主义制度下可能加剧而非缓解社会矛盾的论断。</p><h3 id="三、何去何从？马克思对我们的启示"><a href="#三、何去何从？马克思对我们的启示" class="headerlink" title="三、何去何从？马克思对我们的启示"></a>三、何去何从？马克思对我们的启示</h3><p>在《在人民报创刊上的演说》中，马克思提到：“我们知道，要使社会的新生力量很好地发挥作用，就只能由新生的人来掌握它们，而这些新生的人就是工人。工人也同机器本身一样，是现代的产物。在那些使资产阶级、贵族和可怜的倒退预言家惊慌失措的现象当中，我们认出了我们的勇敢的朋友好人儿罗宾，这个会迅速刨土的老田鼠、光荣的工兵——革命。”</p><p>马克思的这段话在21世纪依然具有深远的启示意义。在当今的技术时代，很大一部分“工人阶级”实际上体现为“技术工作者”，包括程序员、工程师、技术研究人员等。他们既是技术的创造者，也是技术的使用者，同时也面临着被技术异化的风险。这些技术工作者对技术发展方向有着更深入的理解，因此也可能成为推动技术向着更有利于人类发展方向改革的关键力量。</p><p>因此，这对大多数技术从业者的启示是：首先，技术的创造者在创造技术的同时，应当更加积极的关注技术发展所带来的社会影响，而非仅仅盲目的追求技术的进步；其次，作为创造者本身就应当对自己所创造的技术负有足够的责任感——“我应当希望我创造的技术能够给人类带来福祉”，在自己的技术可能给社会带来进一步的伤害的时候，也应当积极的发声和努力；最后，每一个技术工作者都需要团结起来——因为技术工作者虽然对技术发展有所贡献，却并不拥有自己所创造的技术——几乎所有公司都会签署合同表示，所有在职期间利用了公司资源所创造的技术都归公司所有。</p><p>作为新时代的事实上的无产阶级，我们应当深刻的理解：“在当前同资产阶级对立的一切阶级中，只有无产阶级是真正革命的阶级。其余的阶级都随着大工业的发展而日趋没落和灭亡，无产阶级却是大工业本身的产物。”</p><p>我们应当深刻意识到，在这个技术高度发达的时代，技术工作者虽然掌握着先进的生产力，但实际上仍处于被剥削的地位。我们创造的技术成果被资本所占有，我们的劳动时间被精确计算，我们的生存空间被精准控制——这种处境与马克思笔下19世纪的工人阶级惊人地相似。这个困境并不是光靠技术进步就能解决的。然而，正如马克思所指出的，我们技术工作者作为现代工业的产物，也正是改变这一切的关键力量。我们不仅要认清自己的阶级处境，更要认识到自己所掌握的技术力量的革命性潜能。只有团结起来，深刻理解技术发展的社会影响，并积极推动技术向着有利于人类整体发展的方向改革，我们才能真正实现技术进步与社会进步的统一。</p><p>马克思的思想告诉我们：技术本身是中性的，关键在于掌握和使用技术的人。作为新时代的技术工作者，我想，我们不仅仅要保持对技术的热爱与创新精神，更要对技术发展的社会责任保持清醒的认识，并不断把自己的认识落实到实践里。只有这样，我们才能真正成为推动社会进步的积极力量，承担起我们的社会角色所应该发挥的责任。</p>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Overview Of My Research：我的科研工作一览</title>
    <link href="/2025/06/30/MyWorks/"/>
    <url>/2025/06/30/MyWorks/</url>
    
    <content type="html"><![CDATA[<h1 id="My-Works"><a href="#My-Works" class="headerlink" title="My Works"></a>My Works</h1><p>点击可以访问<a href="https://ieeexplore.ieee.org/author/37090055642">我的 IEEE 主页</a></p><h2 id="我主导的工作-1"><a href="#我主导的工作-1" class="headerlink" title="我主导的工作 (1)"></a>我主导的工作 (1)</h2><ul><li><strong>Y. He</strong> andX. Lou*, “Density Estimation-based Effective Sampling Strategy for Neural Rendering,” in Proc., IEEE Int. Symp. Circuits Syst. (ISCAS), 2024.<ul><li><a href="/files/Papers/My-ISCAS2024.pdf">点击下载</a></li></ul></li></ul><h2 id="我参与的工作-4"><a href="#我参与的工作-4" class="headerlink" title="我参与的工作 (4)"></a>我参与的工作 (4)</h2><ul><li>X. Wang, <strong>Y. He</strong>, X. Zhang, P. Zhou andX. Lou*, “An Efficient Hardware Volume Renderer for Convolutional Neural Radiance Fields,” in Proc., IEEE Int. Symp. Circuits Syst. (ISCAS), 2024.</li><li>K. Long, C. Rao, <strong>Y. He</strong>, Z. Yuan, P. Zhou, J. Yu* and X. Lou*, “Analysis and Design of Precision-scalable Computation Array for Efficient Neural Radiance Field Rendering”, in IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 70, no. 11, pp. 4260-4270, Nov. 2023, doi: 10.1109&#x2F;TCSI.2023.3293534.</li><li>Z. Yuan, B. Yuan, Y. Gu, Y. Zheng, <strong>Y. He</strong>, X. Wang, C. Rao, P. Zhou, J. Yu and X. Lou*, “A 0.59μJ&#x2F;pixel High-throughput Energy-efficient Neural Volume Rendering Accelerator on FPGA” in Proc. IEEE Custom Integrated Circuits Conference (CICC), 2024.</li><li>J. Ding, <strong>Y. He</strong>, B. Yuan, Z. Yuan, , P. Zhou, J. Yu and X. Lou*, “Ray Reordering for Hardware-Accelerated Neural Volume Rendering” in IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024.</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>MyPapers</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ShanghaiTech 课程笔记整理</title>
    <link href="/2025/06/30/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/Overview/"/>
    <url>/2025/06/30/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/Overview/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>以下为我在上海科技大学所上的所有课程。</p><ul><li>点击课程名称的链接可以查看我在 Coursebench 上对课程学习的评价</li><li>所有相关资料都会列在课程的子项目中。</li></ul><h1 id="Contents"><a href="#Contents" class="headerlink" title="Contents"></a>Contents</h1><h2 id="21-Fall（大一上学期）"><a href="#21-Fall（大一上学期）" class="headerlink" title="21 Fall（大一上学期）"></a>21 Fall（大一上学期）</h2><ol><li>SI100B 信息科学与技术导论</li><li>GEMA1009 数学分析 I</li><li>MATH1112 线性代数 I</li><li>中华文明通论（刘勋）<ul><li><a href="https://hypoxanthineovo.github.io/2022/05/28/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%85%83%E4%BB%A3%E4%B9%8B%E5%90%8E%E9%99%86%E4%B8%8A%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%E5%87%8B%E6%95%9D%E7%9A%84%E5%BF%85%E7%84%B6%E6%80%A7/">期末论文：元代之后陆上丝绸之路凋敝的必然性</a></li></ul></li></ol><h2 id="22-Spring（大一下学期）"><a href="#22-Spring（大一下学期）" class="headerlink" title="22 Spring（大一下学期）"></a>22 Spring（大一下学期）</h2><ol><li><a href="https://coursebench.geekpie.club/course/84?answer=340">CS100 计算机编程</a></li><li>GEMA1010 数学分析 II</li><li>SI120 离散数学</li></ol><h2 id="22-Fall（大二上学期）"><a href="#22-Fall（大二上学期）" class="headerlink" title="22 Fall（大二上学期）"></a>22 Fall（大二上学期）</h2><ol><li><a href="https://coursebench.geekpie.club/course/347?answer=881">CS101 数据结构与算法</a></li><li><a href="https://coursebench.geekpie.club/course/494?answer=488">SI140A 面向信息科学的概率论与数理统计</a></li><li><a href="https://coursebench.geekpie.club/course/352?answer=1051">CS171 计算机图形学</a></li><li><a href="https://coursebench.geekpie.club/course/403?answer=887">GEHA1152 唐宋文学精华</a><ul><li><a href="https://hypoxanthineovo.github.io/2023/03/10/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%A9%89%E7%BA%A6%E8%AF%8D%E4%B8%AD%E7%9A%84%E9%A3%8E%E9%AA%A8/">期末论文：婉约词中的风骨</a></li></ul></li></ol><h2 id="23-Spring（大二下学期）"><a href="#23-Spring（大二下学期）" class="headerlink" title="23 Spring（大二下学期）"></a>23 Spring（大二下学期）</h2><ol><li><a href="https://coursebench.geekpie.club/course/85?answer=1183">CS110 计算机体系结构</a><ul><li><a href="https://coursebench.geekpie.club/course/86?answer=1193">CS110P 计算机体系结构课程设计</a></li></ul></li><li><a href="https://coursebench.geekpie.club/course/128?answer=876">EE150 信号与系统</a><ul><li><a href="https://epan.shanghaitech.edu.cn/l/lF33j1">课程笔记</a></li></ul></li><li>EE150L 信号与系统实验</li><li><a href="https://coursebench.geekpie.club/course/93?answer=878">CS182 机器学习引论</a><ul><li><a href="https://hypoxanthineovo.github.io/2023/05/27/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS182/Cheatsheet/">Final Review</a></li></ul></li><li><a href="https://coursebench.geekpie.club/course/27?answer=1375">现代生命科学导论 C</a></li><li><a href="https://coursebench.geekpie.club/course/193?answer=1046">思想道德与法治（从思修看“基本写作素养”和通识课绩点的一定相关性)</a></li></ol><h2 id="23-Fall（大三-上学期）"><a href="#23-Fall（大三-上学期）" class="headerlink" title="23 Fall（大三 上学期）"></a>23 Fall（大三 上学期）</h2><ol><li><a href="https://coursebench.geekpie.club/course/92?answer=877">CS181 人工智能 I</a></li><li><a href="https://coursebench.geekpie.club/course/350?answer=875">CS130 操作系统</a><ul><li><a href="https://hypoxanthineovo.github.io/2023/11/22/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Midterm-Cheatsheet/">Midterm Review</a></li><li><a href="https://hypoxanthineovo.github.io/2024/01/08/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Final-Cheatsheet/">Final Review</a></li></ul></li><li><a href="https://coursebench.geekpie.club/course/659?answer=704">GEHA1117 宋词导读</a><ul><li><a href="https://hypoxanthineovo.github.io/2024/01/15/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%AE%8B%E8%AF%8D%E4%B8%AD%E7%9A%84%E6%84%9F%E6%80%A7%E5%92%8C%E7%90%86%E6%80%A7/">读书报告：宋词中的感性与理性</a></li></ul></li><li><a href="https://coursebench.geekpie.club/course/190?answer=712">GESS1023 毛泽东思想和中国特色社会主义理论体系概论</a></li></ol><h2 id="24-Spring（大三-下学期）"><a href="#24-Spring（大三-下学期）" class="headerlink" title="24 Spring（大三 下学期）"></a>24 Spring（大三 下学期）</h2><ol><li><a href="https://coursebench.geekpie.club/course/541?answer=907">EE116 基于FPGA 的硬件系统设计</a></li><li><a href="https://coursebench.geekpie.club/course/262?answer=906">SI114H 计算科学与工程</a></li><li><a href="https://coursebench.geekpie.club/course/156?answer=983">科技文明通论</a><ul><li><a href="https://hypoxanthineovo.github.io/2024/06/11/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E6%99%BA%E8%83%BD%E7%9A%84%E9%80%86%E6%B5%81%E4%B8%8E%E8%BE%B9%E7%95%8C/">期末论文：智能的逆流与边界：AI 浪潮下的“为何”与“如何”</a></li></ul></li><li><a href="https://coursebench.geekpie.club/course/646?answer=908">中外歌剧赏析</a></li></ol><h2 id="24-Fall（大四-上学期）"><a href="#24-Fall（大四-上学期）" class="headerlink" title="24 Fall（大四 上学期）"></a>24 Fall（大四 上学期）</h2><ol><li>SI152 数值最优化</li><li>马克思主义基本原理</li><li>唐前诗文之美<ul><li><a href="https://hypoxanthine.cn/2024/12/18/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E4%BD%A0%E8%A7%81%E8%BF%87%E5%81%9C%E6%BB%9E%E5%9C%A8%E7%A9%BA%E4%B8%AD%E7%9A%84%E4%BA%91%E5%90%97/">创意写作：你见过停滞在空中的云吗</a></li></ul></li></ol><h2 id="25-Spring（大四-下学期）"><a href="#25-Spring（大四-下学期）" class="headerlink" title="25 Spring（大四 下学期）"></a>25 Spring（大四 下学期）</h2>]]></content>
    
    
    <categories>
      
      <category>本科课程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CourseReview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2024 年诗词创作</title>
    <link href="/2024/12/31/2024%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/"/>
    <url>/2024/12/31/2024%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>【WAIT…】</p><h1 id="诗词创作"><a href="#诗词创作" class="headerlink" title="诗词创作"></a>诗词创作</h1><h2 id="鹧鸪天·雪后小记"><a href="#鹧鸪天·雪后小记" class="headerlink" title="鹧鸪天·雪后小记"></a>鹧鸪天·雪后小记</h2><p>白雪攀上小红墙，且行且看且思量。<br>万籁俱寂浮云上，已似逍遥游四方。</p><p>身欢畅，意徜徉，风与月共诉衷肠。<br>君若似此三更雪，何惧输谁一段香？</p><h2 id="临江仙"><a href="#临江仙" class="headerlink" title="临江仙"></a>临江仙</h2><p>晴雨江城真难测，冶游无怪阴云。<br>故园砖瓦已更新。<br>身如新过客，心似旧学生。</p><p>一觉三年魔都梦，吾身虽在堪惊。<br>闲随故友论心情。<br>此间多少事，都入晚风中。</p><h2 id="破阵子"><a href="#破阵子" class="headerlink" title="破阵子"></a>破阵子</h2><p>皎皎山中明月，寥寥夜里浮云<br>应期人间新伙伴，却忆风尘旧姓名。<br>谁唱《水龙吟》？</p><p>徘徊花前念旧，彷徨梦里逢君。<br>忘却和离书上字，犹记初见弦外音。<br>此刻最深情。</p><h2 id="归见故人"><a href="#归见故人" class="headerlink" title="归见故人"></a>归见故人</h2><p>归家何处寻故人？昨日相约话三分。<br>花开街畔如昨梦，烟笼楼间似前尘。<br>料君从前常怀远，知我今此更伤春。<br>尊前莫话红尘事，杯盏停时夜已深。</p><h2 id="鹧鸪天"><a href="#鹧鸪天" class="headerlink" title="鹧鸪天"></a>鹧鸪天</h2><p>漫漫远道音书迟，为谁翻作断肠诗？<br>到相逢时知欢喜，于别离后解相思。</p><p>思往事，忆昔时，世人皆笑我情痴。<br>却看前朝倾天处，无人知晓有顽石。</p><h2 id="七律·有感"><a href="#七律·有感" class="headerlink" title="七律·有感"></a>七律·有感</h2><p>春时花发夏时飞，难免人生无数悲。<br>名士风流成厚土，雕镂锦绣作尘灰。<br>今朝壮志凌云意，明夜无言踏月归。<br>莫让此伤陈旧梦，于平凡处起惊雷。</p><h2 id="与君行有感"><a href="#与君行有感" class="headerlink" title="与君行有感"></a>与君行有感</h2><p>并肩斜目窥云鬓，对坐低眉望罗裙。<br>此刻如在丹青见，要于青史落姓名。</p><h2 id="赠澜睿"><a href="#赠澜睿" class="headerlink" title="赠澜睿"></a>赠澜睿</h2><p>同穴同衾皆所望，红笺小字拟佳期。<br><strong>何须长夜终开眼？愿汝平生尽展眉。</strong></p>]]></content>
    
    
    <categories>
      
      <category>诗与词</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【唐前诗文之美 创意写作】你见过停滞在空中的云吗？</title>
    <link href="/2024/12/18/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E4%BD%A0%E8%A7%81%E8%BF%87%E5%81%9C%E6%BB%9E%E5%9C%A8%E7%A9%BA%E4%B8%AD%E7%9A%84%E4%BA%91%E5%90%97/"/>
    <url>/2024/12/18/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E4%BD%A0%E8%A7%81%E8%BF%87%E5%81%9C%E6%BB%9E%E5%9C%A8%E7%A9%BA%E4%B8%AD%E7%9A%84%E4%BA%91%E5%90%97/</url>
    
    <content type="html"><![CDATA[<h1 id="你见过停滞在空中的云吗？"><a href="#你见过停滞在空中的云吗？" class="headerlink" title="你见过停滞在空中的云吗？"></a>你见过停滞在空中的云吗？</h1><p>你见过停滞在空中的云吗？</p><p>我很喜欢站在上海科技大学东门的门口，向着外面的马路眺望。周边的几幢楼给门口围出了一片小小的空地。你站在那里张开手抬起头，就好像在某个深深的井里攀援而出去拥抱天空，云、太阳和月亮都被你揽入怀中。</p><p>我在那里看到过，停滞在空中的云。</p><p>好吧，站在校门口仰头望天实在是一件很中二的事，所以我并不常做；但确实我经常能在这里看到一些令人感动的景色：阴翳的天空中染上淡淡蓝色的行云，在呼啸狂风里飞卷上天的红色落叶，还有傍晚被渲染成浅金色的楼房外墙。</p><p>但它们大抵不及我看到过的停滞在空中的云。</p><p>那天我看见这样的云的时候，我想起了他们；那天我想起他们的时候，我看见了这样的云。</p><p>很难想象那样一片堪称辽阔又磅礴的云会凝滞在空中，压得我喘不过气来。</p><p>依稀记得四五年前我也见过这样的云：在某个周日的中午，终于考完试的我随着人群从教室里鱼贯而出，在喧闹的走廊间，我不经意撇到了天空中看起来如同静止的云。但并不在意的我，只想着去找同样考完试的他们。</p><p>那时候我们还会在考完试之后并肩而行，用几句粗俗的俚语发泄一下无穷无尽考试的不满，幻想一些自己的大学生活，关于自己所学的专业、所写的论文和所做的工作。那时候我还满怀壮志，和他们说你们看好了，我也要做一回青年才俊，你们等着在新闻上看到我的名字吧！随后众皆嬉笑，谁也没有去质疑，谁的幻想到底有多少分量。</p><p>但大抵只有做了之后才知道世事多艰。作为普通人的我们，每一门课，每一个尝试，每一份经历都比我们幻想的时候显得更艰涩，也更沉重。我们都背着当时的幻想一步又一步的咬牙前行着。说好的聚会被拖延了一次又一次，说好的旅行变成了脑海里的泡影。大家都有太充分的理由，在这样沉重的现实世界里前行，哪有那么多时间去留给我们为虚无缥缈的回忆里温存？</p><p>所以生命注定是一场渐行渐远的旅程。我们为过去的朋友攒下满腹精彩绝伦的经历，但当事人大抵不会有机会再听到了，又或许有某位新朋友去听？于是这份经历又多少沾染了一点遗憾。</p><p>遗憾吗？我抚摸着自己的脸颊，好像摸到一点尚有余温的水迹。摇摇头，我听到他们围着我问：“哎，你脸上怎么了？这是汗水还是泪水呢？”</p><p>“是雨啊，只是温热的雨罢了。”我低声说。</p><p>天空真的下起雨来，朦朦胧胧的雨幕一望无际，分隔了我和他们，分隔了我和过去。淅淅沥沥的雨点汇聚成长河，冲刷着我和我的回忆。我站在雨里，仰头拥抱停滞在空中的云。</p>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Our Courses!</title>
    <link href="/2024/12/14/MyCourses/"/>
    <url>/2024/12/14/MyCourses/</url>
    
    <content type="html"><![CDATA[<h1 id="SI100B-EE-Electrical-Engineering-Part"><a href="#SI100B-EE-Electrical-Engineering-Part" class="headerlink" title="SI100B: EE(Electrical Engineering) Part"></a>SI100B: EE(Electrical Engineering) Part</h1><ul><li><a href="https://hypoxanthine.cn/2024/08/22/%E6%95%99%E7%A8%8B/%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E9%80%89%E8%B4%AD%E6%8C%87%E5%8D%97/">萌新必看: 笔记本电脑选购指南</a></li></ul><h2 id="Fall-2024"><a href="#Fall-2024" class="headerlink" title="Fall 2024"></a>Fall 2024</h2><h3 id="Homeworks-Tutorials"><a href="#Homeworks-Tutorials" class="headerlink" title="Homeworks Tutorials"></a>Homeworks Tutorials</h3><ul><li><a href="/SI100B-24Fa-Tutorials/SI100B_24Fa_Tutorial0.html">0: Enviroment SetUp</a></li><li><a href="/SI100B-24Fa-Tutorials/SI100B_24Fa_Tutorial1.html">1: Homework 1</a></li><li><a href="/SI100B-24Fa-Tutorials/SI100B_24Fa_Tutorial2.html">2: Homework 2</a></li></ul><h3 id="Project-miniCPU"><a href="#Project-miniCPU" class="headerlink" title="Project: miniCPU"></a>Project: miniCPU</h3><p>TO BE RELEASED!</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>【萌新必看】笔记本电脑选购指南</title>
    <link href="/2024/08/22/%E6%95%99%E7%A8%8B/%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E9%80%89%E8%B4%AD%E6%8C%87%E5%8D%97/"/>
    <url>/2024/08/22/%E6%95%99%E7%A8%8B/%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E9%80%89%E8%B4%AD%E6%8C%87%E5%8D%97/</url>
    
    <content type="html"><![CDATA[<p>🔔 Ref: Shanghaitech University, Yifan Liu</p><h1 id="0-一些前置提醒"><a href="#0-一些前置提醒" class="headerlink" title="0. 一些前置提醒"></a>0. 一些前置提醒</h1><p>⚠️ <strong>目前购买到的笔记本电脑基本在开机联网自动激活 Windows 系统后即无法无理由退换货。</strong>因此，如果需要验机或者再次确认自己的需求是否匹配，<strong>务必不要激活机器自带的Windows系统</strong>（这很可能在不经意间发生，尤其是 Windows 11 默认禁用本地账户的情况下）。可以使用U盘系统引导等方式在不激活内置Windows系统的前提下试用验机。</p><h2 id="0-0-购买渠道"><a href="#0-0-购买渠道" class="headerlink" title="0.0. 购买渠道"></a>0.0. 购买渠道</h2><p>对于不了解电脑的人来说，<strong>线上购买是更好的选择</strong>，像京东、淘宝、品牌官网、苏宁易购等都是不错的选项。在实体店购买的话，被坑的可能性较大。因此，对于电脑小白，<strong>不要选择前往实体店购买电脑</strong>。（事实上，即使是老油条，在实体店也很可能被狠狠坑害）</p><ul><li>一线品牌（联想&#x2F;戴尔&#x2F;惠普&#x2F;华硕）可以在任意网上店铺购买。</li><li>对于二线品牌推荐京东自营购买，因为京东也有比较健全的售后可以弥补一些二线品牌（神舟&#x2F;机械&#x2F;小米&#x2F;华为）售后不如一线品牌的缺陷。</li></ul><h2 id="0-1-关于二手机-水货机等渠道"><a href="#0-1-关于二手机-水货机等渠道" class="headerlink" title="0.1. 关于二手机&#x2F;水货机等渠道"></a>0.1. 关于二手机&#x2F;水货机等渠道</h2><p>这些渠道往往有时候会有非常高性价比的选项，但对于没有鉴别能力和判断能力的小白来说一律不推荐！</p><p>对于小白来说，同样<strong>不推荐三线及三线以下品牌</strong>（包括但不限于神舟、雷神及其他不知名品牌），因为这些品牌往往很少有或者根本没有售后网点，也就意味着当电脑出现各种问题时只能通过自己解决。这种缺乏“兜底”措施的选择无疑对“小白”们来说是非常不利的。</p><h2 id="0-2-提前明确需求和预算"><a href="#0-2-提前明确需求和预算" class="headerlink" title="0.2. 提前明确需求和预算"></a>0.2. 提前明确需求和预算</h2><p>我们需要根据自己的需求，来选购不同种类的笔记本。笔记本的种类大致可简单分为：</p><ul><li>轻薄本</li><li>游戏本</li><li>二者之间的产物（如轻薄游戏本，全能本，性能本及其他类似的东西）</li><li>这里忽略移动工作站（因为会买工作站的同学应该不需要看这篇文章）</li></ul><h3 id="便携性"><a href="#便携性" class="headerlink" title="便携性"></a>便携性</h3><ul><li>其轻薄本往往重量在 900g-1.5kg</li><li>游戏本往往重量在2.5kg以上</li></ul><p>请自己估量相应的重量是否能够符合自己对便携性的要求~</p><h3 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h3><p>轻薄游戏本（相对在较小的体积和较低的重量下提供性能较强的硬件）往往在同配置下，散热系统不如传统游戏本（导致其实际性能，尤其是长时间运行下的性能更低），且价格更高，只适合对便携性要求较高的需求（事实上，大部分同学根本没有这样的需求）。</p><p><strong>（2024更新）对轻薄游戏本的补充说明</strong>今年不少搭载 Core Ultra 系列和 Ryzen 8000 系列的轻薄游戏本的产品力有明显增强，<strong>可以做到在保证便携性的情况下拥有相较传统意义上的轻薄本显著增强的GPU能力</strong>。但同样需要注意的是，相同配置（一般相同价位）的轻薄游戏本由于散热能力所限，性能释放一定弱于传统游戏本（15.6寸及以上尺寸，2kg及以上重量），且较小的屏幕如果作为主力机使用可能后期需要外接显示器（不然长时间盯着会比较难受）。在确定准备在寝室购买外接显示器使用的话（回到寝室接显示器，外出拔掉显示器）选购轻薄游戏本也不失为好的选择，但<strong>务必确认好自己的需求</strong>。</p><p>在确定需求时，不仅要考虑当下的需要，也要适当的为未来留有余地（可扩展预留&#x2F;提前加配）。</p><p><strong>时刻记住：</strong></p><ul><li><strong>选购之前，先明确自己的需求</strong></li><li><strong>轻薄和性能在价格不显著提升的情况下无法兼得</strong></li><li><strong>不要在有大量携带需求的情况下选择传统厚重游戏本（大板砖）</strong></li></ul><h1 id="1-电脑硬件的核心-中央处理器-CPU"><a href="#1-电脑硬件的核心-中央处理器-CPU" class="headerlink" title="1. 电脑硬件的核心-中央处理器(CPU)"></a>1. 电脑硬件的核心-中央处理器(CPU)</h1><p>当今主流市场的CPU由Intel（英特尔）和AMD（超微半导体）占据</p><h2 id="Intel篇"><a href="#Intel篇" class="headerlink" title="Intel篇"></a>Intel篇</h2><p>Intel 酷睿 14 代分为酷睿处理器和酷睿 Ultra 处理器，酷睿 Ultra 处理器用于搭载在轻薄本上，酷睿处理器则是专门搭载在游戏本上。</p><h3 id="酷睿Ultra"><a href="#酷睿Ultra" class="headerlink" title="酷睿Ultra"></a><strong>酷睿Ultra</strong></h3><p>酷睿 Ultra 处理器采用了最新的3D性能混合架构，大核+小核+低能耗小核的架构。同时采用全新的命名方式，处理器命名更改为 Ultra5、Ultra7、Ultra9，不再是之前的 i5、i7、i9 了。</p><p><strong>酷睿 Ultra 的中央处理器性能相比上代提升很小</strong>，甚至部分时候存在倒挂的情况，反正处理器性能可以当做和上代差不多，比如 <a href="https://www.zhihu.com/search?q=Ultra5-125H&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22376305519%22%7D">Ultra5-125H</a> 的性能就和 i5-13500H 差不多。</p><p><strong>酷睿 Ultra 处理器主要是提升核显性能</strong>，核显是<a href="https://www.zhihu.com/search?q=%E9%94%90%E7%82%ABXe&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22376305519%22%7D">锐炫Xe</a>，采用 Xe LPG 架构，核显性能相比上代翻倍提升，可以超过独显MX570，在TimeSpy跑分中，也比 AMD 的 Radeon 780M 强一些，可以低画质60帧左右玩大型游戏吃鸡、古墓丽影、原神等有游戏。</p><p>酷睿 Ultra 处理器选择 Ultra5-125H 就可以了，性价比不错，可以满足绝大多数的使用需求，现在处理器性能基本过剩。</p><p>对于 Ultra7-155H 和 Ultra9-185H 处理器，核心规格是一样的，都是6大核+8小核+2低功耗小核，总共 16 核 22 线程，睿频频率高了 0.3GHz。如果价格差不多的情况下，选择 Ultra9-185H，价格相差较多，就选择 Ultra7-155H 。</p><h3 id="酷睿处理器"><a href="#酷睿处理器" class="headerlink" title="酷睿处理器"></a><strong>酷睿处理器</strong></h3><p>Intel 14代酷睿处理器主要是HX结尾的系列，采用性能混合架构，大核+小核的架构，酷睿 Ultra 处理器架构多了一个低功耗小核。酷睿处理器专门搭载在游戏本上。处理器命名和以前一样，使用 i5、i7、i9。</p><p>2024年新品游戏本有不少搭载去年的处理器，这是因为 Intel 酷睿14代处理器性能相比上代提升较小，同时现在笔记本电脑处理器性能基本过剩。比如i9-13980HX和i9-14900HX处理器性能差不多一样，因为核心架构都是一样的，都是8大核+16小核，i9-14900HX处理器睿频频率只比i9-13980HX高0.2GHz，性能区别不大。游戏本搭载上代处理器可以拥有更加实惠的价格，性价比更高，而新处理器一般由于刚发布，即使CPU性能并没有强多少，价格也会贵一些。</p><p>旧款处理器推荐选择i7-13650HX、i9-13980HX，新款处理器可以根据预算选择i7-14650HX、i9-14900HX处理器，其中i7-14650HX虽然是“i6”处理器，但是相比上代提升较大，增加了两个大核，8大核+8小核架构，总共16核24线程。</p><p>总的来说，英特尔第14代CPU最适合在移动计算中需要<strong>最大性能</strong>的用户，而 Core Ultra 系列则提供了更多平衡的选择，具有额外的AI功能和更好的电源效率，适合高端消费者设备<strong>一般用于14寸及以下尺寸的设备</strong></p><p>需要注意：12代以后的多数Intel CPU采用大小核设计     但由于这一设计相对较不成熟(现阶段的操作系统调度问题，如容易将计算量大的后台任务调度到小核上而将前台的轻任务调度到大核上)所以如果有建模&#x2F;视频编辑等重度任务需求的建议谨慎考虑当前的Intel系列 <strong>（2024更新）该问题相对已经优化较为成熟，2024年的当下不必过于担心，但由于部分专业软件（尤其是较老的专业软件）仍然会有调度问题，故保留这一条</strong></p><h2 id="AMD篇"><a href="#AMD篇" class="headerlink" title="AMD篇"></a>AMD篇</h2><p>AMD锐龙8000系处理器采用 Zen4 架构，和同样 Zen4 架构的锐龙7000系处理器性能基本一样，只是换了个名字而已，新处理器并不等于性能提升。</p><p>比如R7-8845H和R7-7840H处理器对比，这两处理器其实是双胞胎，从头到尾一模一样，就名字不一样，都是8核16线程，Zen4架构，频率，核显性能都等一样。</p><p>2024锐龙轻薄本提升主要是在外围配置方面，如果外围配置提升不大，可以选择2023旧款锐龙轻薄本，CPU性能一样，价格更加实惠，性价比更高。</p><p>对于R7-8845H和R9-8945H处理器，都是8核16线程，架构一样，核显性能一样，R9处理器频率高一些，CPU性能相差不大，价格会贵一些，选择R7-8845H处理器就可以了，性价比更高。</p><p>对于R5-8645H处理器，性价比也不高，不推荐选择，是6核12线程，核显性能还被阉割了，相比R7-8845H价格也便宜不了多少。</p><p>对于AMD的HX结尾处理器，性能释放强劲，搭载在游戏本上，最高16核32线程，最高加速频率可达5.4GHz，采用最新的Zen4架构，由于游戏本都有独显，所以处理器核显是Radeon 610M，规格是2CU，核显性能弱一些，影响不大。AMD游戏本处理器推荐选择R9-7940HX、R9-7945HX，这两处理器只是频率相差0.2GHz，在100W功耗以内，R9-7940HX性能表现比R9-7945HX好一些，超过100W之后，R9-7945HX好一些。R9-7945HX是去年发布的处理器，放在今年依旧能打，可以和i9-14900HX处理器打的有来有回。</p><h2 id="Intel-和-AMD-的比较"><a href="#Intel-和-AMD-的比较" class="headerlink" title="Intel 和 AMD 的比较"></a>Intel 和 AMD 的比较</h2><h3 id="价格"><a href="#价格" class="headerlink" title="价格"></a>价格</h3><p>通常情况下，<strong>AMD 的 CPU 在同等性能下比 Intel 的 CPU 更具性价比</strong>。这意味着你可能能够以较低的价格获得相似的性能。</p><h3 id="能效"><a href="#能效" class="headerlink" title="能效"></a>能效</h3><p>一些AMD处理器采用了7nm工艺，这意味着它们在相同性能水平下可能比Intel的CPU消耗更少的能量。但是，具体的能效因素可能因产品而异。</p><h3 id="兼容性"><a href="#兼容性" class="headerlink" title="兼容性"></a>兼容性</h3><p>大多数软件可以在两种CPU上运行，但有时可能会发生不同的性能表现。通常，这种差异并不会对大多数用户产生太大影响。 选择因素：</p><h3 id="预算"><a href="#预算" class="headerlink" title="预算"></a>预算</h3><p>如果预算有限，你可能会倾向于选择AMD，因为它们的产品通常在同等性能下更便宜。 </p><h3 id="性能需求："><a href="#性能需求：" class="headerlink" title="性能需求："></a>性能需求：</h3><p>根据你的使用需求，选择适当的性能水平。如果你需要处理高性能任务，可能需要更强大的CPU，无论是来自Intel还是AMD。</p><h2 id="笔记本CPU性能天梯图（2024-Summer-Updated）"><a href="#笔记本CPU性能天梯图（2024-Summer-Updated）" class="headerlink" title="笔记本CPU性能天梯图（2024 Summer Updated）"></a>笔记本CPU性能天梯图（2024 Summer Updated）</h2><p><img src="https://pic2.zhimg.com/v2-d68ec9bffce1bdf4a9fc863a0431dca9_b.jpg" alt="天梯图种，位置越高的 CPU 型号性能越强"></p><p>天梯图种，位置越高的 CPU 型号性能越强</p><h1 id="2-图形运算和图形处理的中枢-GPU"><a href="#2-图形运算和图形处理的中枢-GPU" class="headerlink" title="2. 图形运算和图形处理的中枢-GPU"></a>2. 图形运算和图形处理的中枢-GPU</h1><p>笔记本电脑显卡分为核显和独显，独显基本是NVIDIA一家独大（这里忽略AMD和Intel家的独立显卡的情况）</p><h2 id="核显篇"><a href="#核显篇" class="headerlink" title="核显篇"></a>核显篇</h2><p>当今时代，无论是Intel还是AMD，核显的性能都有了长足的提升，可以满足轻度负载的需要</p><p>核显通常足够处理日常办公任务、浏览网页、观看高清视频以及轻度游戏等活动。对于一般用户来说，核显已经足够满足需求</p><p>总的来说，核显适用于轻度使用和日常办公任务，可以帮助厂商设计出更轻薄、便携和经济实惠的笔记本电脑。但对于需要更高图形性能的用户，例如游戏玩家和专业设计师，独立显卡仍然是更好的选择。</p><h2 id="独显篇"><a href="#独显篇" class="headerlink" title="独显篇"></a>独显篇</h2><p>由于NVIDIA的Cuda加速和兼容性优化相较其他厂家的绝对优势，选购时一律推荐选购NVIDIA显卡</p><p>同时，鉴于上面已经提到过的核心显卡的性能迅速增长，不推荐购买搭载任何性能低于GTX1650的独立显卡的笔记本（否则可能你花钱买来的独显性能还不如核显）</p><p>对小白的特别提醒：一定不要简单通过显存容量判断显卡性能，否则容易被奸商的虚假宣传误导（如4G大显存显卡但实际上性能还不如核显）</p><p>同时也要注意到，在相对高端的领域，显卡性能的提升往往和价格的提升不成正比，因此应当结合自己的预算量力而行</p><p>对小白的特别提醒2：现阶段一定不要购买任何搭载30系显卡及以前的老款电脑，因为它们很可能参与过挖矿（哪怕是全新机也不能完全排除，尤其是第三方商家），导致寿命严重下降</p><h3 id="RTX-40系列显卡介绍"><a href="#RTX-40系列显卡介绍" class="headerlink" title="RTX 40系列显卡介绍"></a>RTX 40系列显卡介绍</h3><p><strong>RTX 4050</strong>是入门级的显卡，性能相当于上一代的RTX 3060，可以在1080P分辨率下流畅地玩大部分游戏，价格也比较亲民。如果您的预算不多，或者您不追求极致的画面效果，那么RTX 4050是一个不错的选择。</p><p><strong>RTX 4060</strong>是中高端的显卡，性能相当于上一代的RTX 3070，可以在2K分辨率下流畅地玩大部分游戏，甚至一些4K游戏也可以勉强运行。如果您想要更好的游戏体验，或者您有一些3D建模、视频剪辑等需求，那么RTX 4060是一个合适的选择。</p><p><strong>RTX 4070</strong>是高端的显卡，性能略高于上一代的RTX 3070Ti，可以在4K分辨率下流畅地玩大部分游戏。但是它的价格也很高，性价比不太高。除非您有非常高的性能需求，或者您不在乎价格，否则我不建议您选择RTX 4070。</p><p><strong>RTX 4080</strong>是顶级的显卡，性能远超上一代的RTX 3080，可以在4K分辨率下轻松地玩任何游戏。但是它也是非常昂贵的显卡，而且功耗和发热也很大，需要配备很好的散热系统和电源适配器。如果您想要享受最佳的游戏效果，或者您有专业级别的图形处理需求，那么RTX 4080是一个无可挑剔的选择。</p><p><strong>RTX 4090</strong>是超级顶级的显卡，性能比RTX 4080还要高出，可以在比4K更高的分辨率下玩游戏。但是它也是最稀缺和最昂贵的显卡，目前市面上很少有笔记本电脑搭载它。除非您有无限的预算和无穷的需求，否则我认为您没有必要选择RTX 4090。</p><h2 id="显卡天梯图"><a href="#显卡天梯图" class="headerlink" title="显卡天梯图"></a>显卡天梯图</h2><p><a href="https://piazza.com/redirect/s3?bucket=uploads&prefix=paste/lkthtz2uh395co/c39eac75d8db2229ff053436b3c67a4022f7dc7ded6bb4213a6b6f858fc20154/image.png">https://piazza.com/redirect/s3?bucket=uploads&prefix=paste%2Flkthtz2uh395co%2Fc39eac75d8db2229ff053436b3c67a4022f7dc7ded6bb4213a6b6f858fc20154%2Fimage.png</a></p><h1 id="3-运算结果的存储池-内存（Memory）和存储（Shortage）"><a href="#3-运算结果的存储池-内存（Memory）和存储（Shortage）" class="headerlink" title="3. 运算结果的存储池-内存（Memory）和存储（Shortage）"></a>3. 运算结果的存储池-内存（Memory）和存储（Shortage）</h1><h2 id="3-1-内存-Memory-also-RAM"><a href="#3-1-内存-Memory-also-RAM" class="headerlink" title="3.1. 内存(Memory, also RAM)"></a>3.1. 内存(Memory, also RAM)</h2><h3 id="3-1-1-何为内存"><a href="#3-1-1-何为内存" class="headerlink" title="3.1.1. 何为内存"></a>3.1.1. 何为内存</h3><p>RAM 是 “随机存取存储器” 的缩写。它是一种计算机内存类型，用于临时存储中央处理单元（CPU）在执行任务时需要快速访问的数据。与硬盘驱动器或固态驱动器等存储设备不同，RAM 提供了快速临时存储，使CPU能够快速检索和操作数据。</p><p>RAM 是易失性存储器，<strong>这意味着在计算机关闭或重新启动时其内容会丢失</strong>。这与非易失性存储（如硬盘驱动器或固态驱动器）形成对比，在这些设备中，数据在断电时仍然保留。</p><p>存储在RAM中的数据包括运行中的应用程序、操作系统和当前正在处理的数据。计算机的RAM越多，它可以在活动使用中保存的数据越多，这可能会提高性能和更快的多任务处理，因为CPU可以更快地访问所需数据。</p><p>总之，RAM是计算机系统的关键组件，为CPU在运行程序和执行任务时需要访问和操作的数据提供临时和快速的存储。</p><h3 id="3-1-2-内存的大小"><a href="#3-1-2-内存的大小" class="headerlink" title="3.1.2. 内存的大小"></a>3.1.2. 内存的大小</h3><p>常见的内存大小有：8G、16G、32G、64G等</p><p>内存越大越好，但越大越贵，所以我们选择的时候还是要根据自己的使用情况来定。</p><ul><li>8G：入门级，如果是普通娱乐刷剧和office办公这些，8G基本够用，但开多了软件大概率会卡，无法应对多任务需求。</li><li>16G：目前主流偏低配置，应对大多数轻度应用没有问题，而且价格较低。但随着软件对性能要求的逐步提高，16G内存在面对专业生产力需求时也开始显得力不从心</li><li>32G或更高：32G内存对于绝大多数用户都已经足够，可以进行常规的多任务处理</li><li>64G内存主要用于高度生产力用途（科学计算&#x2F;高压力视频渲染等）场景，如果没有此类需求一般没有必要</li></ul><h3 id="3-1-3-内存的速度"><a href="#3-1-3-内存的速度" class="headerlink" title="3.1.3. 内存的速度"></a>3.1.3. 内存的速度</h3><p>现阶段主流电脑的内存主要可分为 DDR4 和 DDR5 两种</p><p>DDR5相比DDR4内存在频率上实现了翻倍。DDR4上市初期，内存频率只有2133和2400MHz，目前主流频率为3200MHz和3600MHz，现阶段旗舰级DDR4内存频率可以做到4266MHz或更高。而DDR5的基础频率就达到了4800MHz，目前已经有5200MHz和6400MHz的产品，未来还有可能出现更高频率的内存。</p><p>DDR5相比DDR4内存在带宽上提高了约50%。DDR4 3200MHz的带宽为25.6GB&#x2F;s，而DDR5 4800MHz的带宽为38.4GB&#x2F;s。</p><p>但实际上，<strong>内存的速度对实际体验的影响往往小于内存容量</strong>。鉴于DDR5内存的售价往往远高于DDR4内存，因此通过降级内存到DDR4以换取更大的内存容量是值得的</p><h2 id="3-2-存储-Shortage-also-ROM"><a href="#3-2-存储-Shortage-also-ROM" class="headerlink" title="3.2. 存储(Shortage, also ROM)"></a>3.2. 存储(Shortage, also ROM)</h2><p>笔记本电脑使用的硬盘包括IDE，SATA，mSATA，m2 NGFF，m2 NVMe(PCIE3)，m2 NVMe(PCIE4)等等。其中，除最后两者接口形态一样可以互插以外，其他均不能相互兼容</p><p>现阶段，笔记本电脑中的机械硬盘往往使用2.5寸的SATA接口（但搭载机械硬盘位置的笔记本已经少见），而固态硬盘往往使用m2 NVMe接口</p><p>现阶段，<strong>固态硬盘已然基本完成了对机械硬盘的取代</strong>，凭借其在速度和可靠性(抗震性)等多方面的碾压性优势。</p><p>PCIE4的硬盘速度往往快于PCIE3的硬盘，但对实际体验的影响并不大，无需过于介意这一点</p><p>固态硬盘的存储颗粒还分为MLC，TLC，QLC三种(SLC已过于少见暂且不论)，其中寿命MLC&gt;TLC&gt;QLC</p><p>QLC的固态硬盘往往同容量价格较低，但寿命较短且速度较慢，不推荐</p><h3 id="关于存储容量"><a href="#关于存储容量" class="headerlink" title="关于存储容量"></a>关于存储容量</h3><p>对于大多数用户来说，保证至少512G的(固态)硬盘空间 如果条件允许，尽可能选择有扩展硬盘位的产品</p><p>关于内存和硬盘的扩展和加装相关内容，见后文”可扩展性”栏目</p><h1 id="4-视觉体验的直观呈现-屏幕"><a href="#4-视觉体验的直观呈现-屏幕" class="headerlink" title="4. 视觉体验的直观呈现-屏幕"></a>4. 视觉体验的直观呈现-屏幕</h1><p>作为人机交互的核心，屏幕的好坏对使用电脑的体验至关重要</p><h2 id="4-1-屏幕尺寸"><a href="#4-1-屏幕尺寸" class="headerlink" title="4.1. 屏幕尺寸"></a>4.1. 屏幕尺寸</h2><p>当前，主流笔记本电脑的尺寸为 13-17 寸</p><p>其中，13-14寸的产品一般以轻薄型为主，性能较低，主打便携和续航，而15.6寸以上的型号一般性能较强，但便携性较弱（不绝对）</p><p>不同尺寸的屏幕相对大小如下：</p><p><a href="https://piazza.com/redirect/s3?bucket=uploads&prefix=paste/lkthtz2uh395co/98436b0075b6d6535b26ac8b11d4208ad9e911b0aea3daf1e62c199af47dff49/image.png">https://piazza.com/redirect/s3?bucket=uploads&prefix=paste%2Flkthtz2uh395co%2F98436b0075b6d6535b26ac8b11d4208ad9e911b0aea3daf1e62c199af47dff49%2Fimage.png</a></p><p><strong>对于影音和创作需求较强的用户来说，大屏幕是必不可少的</strong>！</p><h2 id="4-2-屏幕比例"><a href="#4-2-屏幕比例" class="headerlink" title="4.2. 屏幕比例"></a>4.2. 屏幕比例</h2><p>主流的屏幕宽高比为 16：9，这也是绝大多数在线视频等内容的比例 使用16：9的屏幕欣赏视频可以做到无黑边</p><p>当今，亦有许多新型屏幕比例诞生（如许多主流厂家的 16：10 产品以及华为和微软系列的 3：2 产品），这些产品可以更加高效的浏览文字内容（一屏可以显示更多行信息），但在观看视频等固定以16：9 显示的内容时上下会有黑边，实际显示尺寸更小。</p><h2 id="4-3-屏幕其他参数"><a href="#4-3-屏幕其他参数" class="headerlink" title="4.3. 屏幕其他参数"></a>4.3. 屏幕其他参数</h2><h3 id="4-3-1-屏幕分辨率"><a href="#4-3-1-屏幕分辨率" class="headerlink" title="4.3.1. 屏幕分辨率"></a>4.3.1. 屏幕分辨率</h3><p><strong>当今的 Windows11 系统对高分屏优化已经较好，可以放心选购</strong>。</p><p>分辨率越高，画面的清晰度越强，但对图形处理器（GPU）的压力也越大</p><p>对于普通办公或者开发用途高分辨率并不会带来太大额外负担，但对于游戏场景高分辨率会显著加大显卡的压力，需要在画质和流畅性之间做出权衡</p><p>一般来说，对于15寸以下的屏幕，1080P分辨率是可以接受的；对于15寸以上的屏幕，2K分辨率或许是及格线</p><p>但同时，没有必要盲目推崇4K以上的更高分辨率，在感知不强的同时会对GPU压力更大从而降低帧率</p><h3 id="4-3-2-屏幕刷新率"><a href="#4-3-2-屏幕刷新率" class="headerlink" title="4.3.2. 屏幕刷新率"></a>4.3.2. 屏幕刷新率</h3><p>标准的屏幕刷新率为 60Hz（每秒钟更新60次屏幕上显示的内容）</p><p>高刷新率（例如120Hz、144Hz甚至更高）的显示器能够在显示图像时更频繁地刷新屏幕，这可以提供更平滑的动画和视觉效果，特别是在玩游戏或观看视频时。这有助于减少图像撕裂和模糊。</p><p>高刷新率显示器通常会消耗更多的电力，因为更频繁的刷新需要更多的能量。如果您更关注笔记本电脑的电池寿命，可以在性能和电池续航之间做出权衡</p><p>如果您主要使用笔记本电脑进行办公、浏览网页和观看电影，较低的刷新率（例如60Hz）可能已经足够。但如果您是游戏玩家，特别是喜欢玩竞技类游戏，高刷新率可能会提供更大的优势。</p><p>要确保您的笔记本电脑的硬件能够支持您选择的刷新率。高刷新率在游戏中可能需要更强大的GPU来稳定地达到更高的帧率。</p><h3 id="4-3-3-屏幕色域"><a href="#4-3-3-屏幕色域" class="headerlink" title="4.3.3. 屏幕色域"></a>4.3.3. 屏幕色域</h3><p>显示器的色域是指它可以显示的颜色范围。</p><p>笔记本电脑显示器最常见的色域是45%NTSC、72%NTSC和100%sRGB。</p><p>如果你有选择，最好选择色域更高的显示器，这样你将可以欣赏到更加丰富的颜色和获得更好的视觉体验。</p><p>对于Windows笔记本电脑，sRGB是支持最好的色域，因此选择100%sRGB显示器是一个不错的选择。</p><p>然而，需要注意的是，即使显示器具有高色域，如果没有正确校准，它也可能无法准确显示颜色。</p><p>对于普通用户而言，<strong>我们最好选择支持100% sRGB色域的屏幕，最低也得是72% NTSC色域</strong>。（至于45% NTSC的电子垃圾，我们只需要让它们成为时代的眼泪就可以了）</p><p>对于有专业设计需求的用户而言，还应当参考Adobe RGB(aRGB), DCI-P3等色域的覆盖范围，并对屏幕通过校色仪进行校色处理，以获得最高的色准</p><h3 id="4-3-4-屏幕显示材质"><a href="#4-3-4-屏幕显示材质" class="headerlink" title="4.3.4. 屏幕显示材质"></a>4.3.4. 屏幕显示材质</h3><p>当今，主流的屏幕显示材质为LCD（IPS）材质，一般效果较好；近年来，部分厂家开始在笔记本上应用 OLED 材质。</p><ul><li>LCD（液晶显示器）屏幕：<ul><li>成本相对较低： LCD 屏幕相对于 OLED 屏幕来说通常更便宜，因为生产工艺相对成熟且成本较低。</li><li>持久性： LCD 屏幕在长时间使用时通常比 OLED 屏幕更持久，不容易出现“烧屏”（图像保留）问题。</li><li>亮度均匀性： LCD 屏幕在整个屏幕表面上的亮度均匀性较好，不容易出现亮度差异。</li><li>适合办公和一般用途： LCD 屏幕适用于办公、互联网浏览、文档处理等一般用途。</li></ul></li><li>OLED（有机发光二极管）屏幕：<ul><li>色彩和对比度： OLED 屏幕在颜色和对比度方面表现出色，能够呈现深黑色和高对比度，因为每个像素都是自发光的。</li><li>薄型和轻便： OLED 屏幕较薄，可以使笔记本更轻巧、便携。</li><li>快速响应时间： OLED 屏幕响应时间快，适合观看视频和玩游戏，可以减少动态图像模糊。</li><li>潜在的烧屏风险： OLED 屏幕可能存在“烧屏”问题，特别是在显示静态图像时，会导致图像在屏幕上保留。</li><li>频闪伤眼:  OLED 屏幕往往使用低频PWM调光，长时间使用会对眼睛造成较大的不可逆伤害，容易导致散光加重</li></ul></li></ul><p>少数无良商家在笔记本上使用劣质 TN 材质的屏幕（我被坑过），但现如今已经几乎无法见到，对于这种要果断避开（追求TN的极低延时的特定需求除外）</p><h3 id="4-3-5-镜面屏与雾面屏"><a href="#4-3-5-镜面屏与雾面屏" class="headerlink" title="4.3.5. 镜面屏与雾面屏"></a>4.3.5. 镜面屏与雾面屏</h3><p>选择镜面屏（也称为光泽屏）还是雾面屏（也称为防眩光屏）取决于您对于显示效果和使用环境的偏好。以下是两种类型的特点：</p><ul><li>镜面屏（光泽屏）：<ul><li>高对比度和鲜艳色彩： 镜面屏通常具有更高的对比度和更鲜艳的颜色，因为光线在表面上反射，使图像更生动。</li><li>较深的黑色： 由于反射效果，镜面屏可以呈现深黑色，给图像带来更多层次感。</li><li>外观精致： 镜面屏通常看起来更时尚、精致，适合展示优美的设计。</li><li>指纹和反射： 镜面屏容易收集指纹和环境反射，可能在强光下或户外使用时产生眩光和不便。</li></ul></li><li>雾面屏（防眩光屏）：<ul><li>抗反射： 雾面屏采用特殊涂层减少反射和眩光，适合在室外或强光环境下使用。</li><li>减少指纹和污渍： 雾面屏相对不易留下指纹和污渍，保持屏幕清洁。</li><li>更好的阅读体验： 雾面屏在室内环境下可以提供更好的阅读体验，因为它不会受到环境光线的干扰。</li><li>降低反射： 如果您在工作时需要长时间看屏幕，雾面屏可以减少眼睛疲劳，因为它不会产生强烈的反射。</li></ul></li></ul><p>在选择时，考虑以下因素：</p><ul><li>使用环境： 您的笔记本在室内使用多还是在户外使用多？在阳光下，雾面屏可能更适合，因为它可以减少反射和眩光。</li><li>用途： 如果您主要是观看多媒体内容、进行设计或需要鲜艳的颜色和高对比度，镜面屏可能更适合。如果您更注重阅读和长时间使用时的舒适度，雾面屏可能更合适。</li><li>个人喜好： 您是否喜欢镜面屏的光泽外观，还是更偏好雾面屏的抗反射性能？</li></ul><p>最好的方法是在实际环境中比较两种屏幕类型的效果，以确定哪种类型最符合您的需求和偏好。</p><h1 id="5-人机交互的通道-键盘，接口及硬件做工"><a href="#5-人机交互的通道-键盘，接口及硬件做工" class="headerlink" title="5. 人机交互的通道-键盘，接口及硬件做工"></a>5. 人机交互的通道-键盘，接口及硬件做工</h1><h2 id="5-1-是否需要数字小键盘"><a href="#5-1-是否需要数字小键盘" class="headerlink" title="5.1. 是否需要数字小键盘"></a>5.1. 是否需要数字小键盘</h2><p>是否需要笔记本电脑配备数字小键盘取决于您的使用需求。以下是一些考虑因素：</p><ul><li>如果您经常需要输入数字，例如进行数据输入、会计工作、编程、数学等，那么数字小键盘可能会提高您的效率，因为它们使数字输入更快捷。</li><li>数字小键盘会增加笔记本电脑键盘区域的尺寸，这可能导致键盘整体变得较大或更沉重。如果您经常需要携带笔记本电脑旅行或使用有限的工作空间，可能会更喜欢没有数字小键盘的紧凑键盘设计。</li><li>一般地，在尺寸允许的情况下，我们更加推荐使用带有数字小键盘的型号</li></ul><h2 id="5-2-键盘手感"><a href="#5-2-键盘手感" class="headerlink" title="5.2. 键盘手感"></a>5.2. 键盘手感</h2><p>笔记本电脑的键盘手感是一个相当主观的评价标准，因为不同人对于键盘的喜好有所不同。然而，一些品牌在键盘设计方面一直受到好评，被认为在手感方面表现较好的品牌包括Thinkpad，ROG，Razer，Lenovo等。但由于这是一个高度主观的评价标准，我们更推荐通过前往线下体验店亲身上手实验</p><h2 id="5-3-外设接口"><a href="#5-3-外设接口" class="headerlink" title="5.3. 外设接口"></a>5.3. 外设接口</h2><h3 id="5-3-1-USB"><a href="#5-3-1-USB" class="headerlink" title="5.3.1. USB"></a>5.3.1. USB</h3><p><a href="https://piazza.com/redirect/s3?bucket=uploads&prefix=paste/lkthtz2uh395co/bbf673313006c6453ce08b7660e1f19cb55e32475c42eeb19a5139f0badda5e3/image.png">https://piazza.com/redirect/s3?bucket=uploads&prefix=paste%2Flkthtz2uh395co%2Fbbf673313006c6453ce08b7660e1f19cb55e32475c42eeb19a5139f0badda5e3%2Fimage.png</a></p><p>一定要注意：<strong>USB 3.1 和 USB 3.2 这两个称呼不能代表具体的传输速度</strong>，要具体区分Gen x</p><p>（雷电和USB4这一类接口，只要你不需要外接显卡用处是不大的，正常情况下用不到）</p><h3 id="5-3-2-显示输出"><a href="#5-3-2-显示输出" class="headerlink" title="5.3.2. 显示输出"></a>5.3.2. 显示输出</h3><p>一定要注意笔记本搭载的type-C接口是否为全功能（是否支持视频输出&#x2F;支持的视频输出规格） 一般地，最好选购搭载有至少10Gbps传输速率且支持4K 60Hz显示输出的type-C接口的设备，以方便未来的拓展使用 其他形态的接口（HDMI&#x2F;DP&#x2F;VGA）等依照自己的需求选购即可</p><h3 id="5-3-3-音频（3-5mm）接口"><a href="#5-3-3-音频（3-5mm）接口" class="headerlink" title="5.3.3. 音频（3.5mm）接口"></a>5.3.3. 音频（3.5mm）接口</h3><p>少部分轻薄型笔记本电脑已经不再搭载3.5mm接口，因此你将无法在不使用转换器的情况下在这些设备上使用有线耳机，3.5mm接口音响，3.5mm接口麦克风等设备，选购时需要注意</p><h3 id="5-3-4-触摸板"><a href="#5-3-4-触摸板" class="headerlink" title="5.3.4. 触摸板"></a>5.3.4. 触摸板</h3><p>随着时代的进步，Windows电脑对触摸板的支持亦在逐步增强。</p><p>选购时，要注意触摸板的材质（如是否为玻璃面板）和尺寸</p><p>一块好的触摸板可以做到在大部分情况下替代鼠标（如：隔壁 MacBook 的触摸板支持）</p><h1 id="6-面向未来的可能性-可扩展性"><a href="#6-面向未来的可能性-可扩展性" class="headerlink" title="6.面向未来的可能性-可扩展性"></a>6.面向未来的可能性-可扩展性</h1><h2 id="6-1-硬盘的拓展"><a href="#6-1-硬盘的拓展" class="headerlink" title="6.1. 硬盘的拓展"></a>6.1. 硬盘的拓展</h2><p>现阶段的笔记本电脑已经极少见有搭载机械硬盘的配置，故此处只讨论固态硬盘</p><p>笔记本电脑使用的硬盘包括IDE，SATA(2.5寸)，mSATA，m2 NGFF(SATA)，m2 NVMe(PCIE3)，m2 NVMe(PCIE4)等等。其中，除最后两者接口形态一样可以互插以外，其他均不能相互兼容</p><p>在购买拓展硬盘时，一定要注意接口(尺寸)和协议匹配，并在安装时极其小心，<strong>切忌大力出奇迹</strong></p><p>理论上，PCIE3和PCIE4的硬盘可以相互兼容，实际速度按照主板和硬盘的协议的较低的一档（但不推荐这么做，除非存在将老电脑的硬盘拆下来装在新电脑上这种情况）</p><h2 id="6-2-内存的拓展"><a href="#6-2-内存的拓展" class="headerlink" title="6.2. 内存的拓展"></a>6.2. 内存的拓展</h2><ul><li>现阶段，笔记本电脑使用的内存通常是DDR4或者DDR5内存，频率介于2400MHz到5600MHz之间</li><li><strong>DDR4和DDR5的内存物理接口不同，无法相互兼容，切记不要买错然后大力出奇迹</strong></li><li><strong>相同代数的台式机内存的物理接口和笔记本同样不同，同上</strong></li><li>在购买内存时同样注意频率要相同，以免造成性能损失.</li><li>关于内存时序&#x2F;内存超频等内容如果需要请自行上网搜索，风险较大，不推荐小白尝试</li></ul><h3 id="板载内存"><a href="#板载内存" class="headerlink" title="板载内存"></a>板载内存</h3><p>部分轻薄型笔记本电脑的内存为板载焊死(或者一个通道板载一个通道插槽)，板载内存无法升级</p><p><strong>板载内存产品一般都不会标明自己是板载内存，需要查阅相关资料</strong></p><p>若确需购买搭载板载内存的产品，一定要注意一次性预留足够大的内存，以免未来悔恨</p><p>极少部分产品的硬盘也是焊死板载的（但除非是Microsoft Surface&#x2F;Apple等品牌否则极少见），购买时也需要注意</p><h2 id="6-3-可扩展性与轻薄的取舍"><a href="#6-3-可扩展性与轻薄的取舍" class="headerlink" title="6.3. 可扩展性与轻薄的取舍"></a>6.3. 可扩展性与轻薄的取舍</h2><p>通常情况下，可扩展性（甚至包括接口数量）和轻薄是无法二者兼得的，我们应当结合自身的需求（便携需求和对容量的要求）在二者之间达到一个平衡</p><h1 id="7-散热"><a href="#7-散热" class="headerlink" title="7. 散热"></a>7. 散热</h1><p>笔记本电脑的散热对于持续性性能发挥和硬件稳定性至关重要</p><p>高性能的处理器和显卡在运行过程中会产生大量的热量，如果散热不足，温度过高可能会导致性能下降，甚至引起系统崩溃。通过加强散热，可以保持硬件运行在适当的温度范围内，确保系统性能的稳定性和一致性。</p><p>高温环境可能对笔记本电脑的内部组件造成损害，缩短硬件的使用寿命。适当的散热可以降低硬件的工作温度，减少内部组件的磨损和老化，从而延长笔记本电脑的寿命。</p><p>为了控制温度，一些笔记本电脑可能会自动降低处理器和显卡的频率，以减少热量产生。这会导致性能下降，影响用户的工作和娱乐体验。通过有效的散热，可以避免不必要的降频，保持高性能。</p><p>选购时，要注意散热风扇和热管的数量，以及风道的设计</p><p>对于部分搭载液态金属（液金）散热的笔记本型号，往往其散热更加优秀，但需要注意使用过程中需要平放，以避免液金偏移（具体可查阅网络相关资料）</p><h1 id="8-总结-最后提醒"><a href="#8-总结-最后提醒" class="headerlink" title="8.总结&amp;最后提醒"></a>8.总结&amp;最后提醒</h1><h2 id="8-1-实践是检验真理的唯一标准"><a href="#8-1-实践是检验真理的唯一标准" class="headerlink" title="8.1. 实践是检验真理的唯一标准"></a>8.1. 实践是检验真理的唯一标准</h2><p>在线下体验店，你可以实际触摸、查看和操作笔记本电脑，以更好地了解其外观、手感、屏幕质量、键盘舒适度等物理特性。这有助于你决定是否喜欢该产品的实际使用体验。</p><p>在体验店里，你可以启动笔记本电脑，尝试运行一些应用程序或游戏，以了解其性能表现。这样可以帮助你判断是否符合你的使用需求，例如处理办公任务、娱乐、图形设计等。</p><p>观察笔记本电脑屏幕的色彩、亮度、对比度等特性可以帮助你判断是否满足你的视觉需求，尤其是如果你需要进行影像处理或观看高质量媒体内容。</p><p>如果你在笔记本电脑上需要大量的键盘输入，实际尝试键盘的手感和布局，以及触控板的响应性，都是很重要的。</p><p>在体验店里，你可以感受笔记本电脑的实际尺寸和重量，判断是否适合你的携带需求。</p><p>通过触摸和检查笔记本电脑的外壳、接口、散热系统等，你可以对其构建质量有更清晰的了解。</p><p>然而，考虑到现在在线购物的便利性和可靠的退换货政策，你不一定非要去体验店亲身感受。如果你对某个品牌或型号已经有了足够的了解，或者之前已经在其他地方体验过类似型号，那么在线购买也是一个方便的选择。最重要的是，你应该在购买之前仔细阅读用户评价、专业评测以及产品规格，以确保你选择的笔记本电脑能够满足你的需求。</p><h2 id="8-2-关注售后维修的便利性"><a href="#8-2-关注售后维修的便利性" class="headerlink" title="8.2. 关注售后维修的便利性"></a>8.2. 关注售后维修的便利性</h2><p>对于小白来说，售后的便利性能够让我们在遇到问题时更加从容不迫</p><p>在其他条件相同时，最好选择相对较大的一线品牌，能够获得更有保障的售后</p><p>同时，关注产品的保修期限，是否带有意外保障等也非常重要</p><h1 id="Wish-you-all-the-best！"><a href="#Wish-you-all-the-best！" class="headerlink" title="Wish you all the best！"></a><strong>Wish you all the best！</strong></h1>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>准备工作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【宋词导读 讨论课】《不醒人之梦》创作手记</title>
    <link href="/2024/07/13/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E4%B8%8D%E9%86%92%E4%BA%BA%E4%B9%8B%E6%A2%A6-%E5%88%9B%E4%BD%9C%E5%B0%8F%E8%AE%B0/"/>
    <url>/2024/07/13/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E4%B8%8D%E9%86%92%E4%BA%BA%E4%B9%8B%E6%A2%A6-%E5%88%9B%E4%BD%9C%E5%B0%8F%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="《不醒人之梦》"><a href="#《不醒人之梦》" class="headerlink" title="《不醒人之梦》"></a>《不醒人之梦》</h1><h2 id="作品链接"><a href="#作品链接" class="headerlink" title="作品链接"></a>作品链接</h2><p><a href="https://www.bilibili.com/video/BV1PH4y157hY/?share_source=copy_web&vd_source=8695b289ba29767ea98c28659617ac9a">不醒人之梦：用《小谪风月》打开“睡不醒小晏”的一生</a></p><h2 id="歌词"><a href="#歌词" class="headerlink" title="歌词"></a>歌词</h2><p>斗草阶前初见，穿针楼上的那一眼【斗草阶前初见，穿针楼上曾逢】<br>心字罗衣翩翩，只微笑便留住春天【小颦若解愁春暮。一笑留春春也住】<br>云随水歌声转，临镜一缕红斜照晚【云随碧水歌声转；一缕斜红临晚镜】<br>汉渚星桥佳期谁共期盼？【行人莫便消魂去，汉渚星桥尚有期】</p><p>曾有才名京城传遍，也曾与红颜漫步高轩【少陵诗思旧才名】<br>却一朝倾覆，堕入那凡尘间<br>忆往昔都如幻如电，昨梦前尘九重城上烟【云鸿相约处，烟雾九重城】<br>如何消遣？醉与梦中流连</p><p>我用千百次沉眠，换多见你们一眼<br>梦中江南踏遍 未曾逢 朱颜【梦入江南烟水路，行尽江南，不与离人遇】<br>繁花易落月难圆，酩酊夜中忆小莲【手捻香笺忆小莲，…归来独卧逍遥夜，梦里相逢酩酊天。花易落，月难圆…】<br>春又晚，拨秦筝断了弦，谁与你暗换流年【碧草池塘春又晚……绿柱频移弦易断，红颜暗与流年换】</p><p>这数万万天的每一个日夜<br>我都曾 诚心祈祷你我如月重圆【莫如云易散，须似月频圆】<br>那已无色的小字红笺【情至深处，红笺为无色】<br>承着山盟海誓入诗篇<br>何时将它兑现</p><p>彩袖殷勤捧玉钟，当年拚却醉颜红【彩袖殷勤捧玉钟，当年拚却醉颜红】<br>自从别后多少魂梦与君同？【从别后，忆相逢，几回魂梦与君同？】<br>银灯照月下相拥，原来竟不是梦中【今宵剩把银釭照，犹恐相逢是梦中】<br>这相逢太易碎太朦胧，怕恍惚间又成空</p><p><strong>这人生聚散间睡梦中</strong><br><strong>不知不觉就成空</strong></p><h1 id="创作手记"><a href="#创作手记" class="headerlink" title="创作手记"></a>创作手记</h1><p>当第一次看到宋词导读的讨论课内容（把一首宋词改编到现有的流行歌曲中）的时候，我的内心是充满着雀跃的。无论是宋词还是流行音乐，都是陪伴我从小长大的爱好：在我初中的时候，我就尝试过模仿着所谓流行的“古风音乐”，去给一些歌剧填上自己编撰的歌词——因此，我暗暗下定决心，要交出一份至少让我自己满意的答卷。</p><p>开始着手准备歌词的前两周，我并没有取得什么进展：在我的眼里，作词最重要的是动机——你为什么要写词，你想表达什么？我试图去回答这个问题，但我不知道。我所喜爱的小令都太短，如果想用它们去支撑一首完整的流行歌曲，必然要进行大量的扩写或者改写；而我对自己扩写和改写的能力，并没有太多的信心。</p><p>于是时间在纠结和思考中流逝。某一天，我在 B 站上又刷到几条古风填词的视频：“用《爱情转移》打开辛弃疾的一生”“苏东坡《落笔应风雨》自制 MV”……我突然有了一个全新的想法：我何不尝试着用某位词人的词去串联起他自己的一生呢？</p><p>在向陈老师提出我的想法并获得“可以尝试”的肯定答复之后，我就投入到了选曲和写词的事务中。选曲其实并没有遇到太多困难：我选了自己最有感触也最喜欢的一首《小谪风月》作为原曲。这首歌是网易云的古风制作《恋恋故人难》的第六首“尘埃之歌”，描述的是为爱人而仿佛卑微至尘埃里的心绪，副歌中“我若捐那多情身，为你死死又生生，可否与你共度世世或生生”更是在连环的叠词里给我以强烈的震撼。</p><p>怀抱着这首歌所传达的心境，我毫不犹豫的选择了小晏——晏几道，作为我的叙事主人公。但选择之后，我却为歌词的撰写犯了难：有没有哪一句话，可以给人以强烈的张力和震撼，作为全词的主要动机呢？</p><p>这时候，陈老师在课堂上的讲述好像又略过我的耳畔：“同学们有没有注意到，我们所选的晏几道的词都是关于‘梦’的？事实上，晏几道的词中，‘梦’‘酒醒’是非常高频的情境。因此我以前和朋友聊到晏几道的时候，朋友戏称晏几道是‘睡不醒小晏’“。</p><p>“睡不醒”小晏！这个词仿佛电闪雷鸣般击中我的大脑：这就是我想要的主题！</p><p>——为什么他要睡不醒呢？大概是因为，他在梦里有美好的事物可以追寻吧，我想。我又想到自己每每在午夜梦回的时候，梦到曾经美好的事物，梦到我曾经的朋友，过去的恋人，或者是某次无忧无虑的旅行，此刻我感觉自己好像穿越了千年的时空，和他小晏取得了某种情绪上的共鸣：</p><p>如果那里有你们，我愿永远停留在那里。</p><p>所以他要喝酒，要在醉后带着一缕笑意沉眠，所以他在梦醒的时候会恍惚，内心仿佛被某种沉重的现实从天上拖到黄土间，这种落差和痛苦让他不禁要用词句去纾解。</p><p>这时候我写下了歌词的最核心的句子：</p><p>“我用千百次沉眠，换多见你们一眼。”</p><p>于是我觉得这首歌词已经几乎圆满，接下来的工作无非是把他写过的词按照他生平的落差填进对应的位置：从一开始的“斗草阶前初见，穿针楼上的那一眼（斗草阶前初见，穿针楼上曾逢）”的年少欢时，到“忆往昔都如幻如电，昨梦前尘九重城上烟“的家道旁落，再到副歌部分引出主旨，再到第二次副歌用”彩袖殷勤捧玉钟“来引出某个不经意间的重逢的不真实和美好，整首歌的起、承和转都已经做的非常让人满意。</p><p>可是最后一句呢？</p><p>第二段副歌的最后一句是“这相逢太易碎太朦胧，怕恍惚间又成空”，是直接化用了“今宵剩把银釭照，犹恐相逢是梦中”的原句；但最后一句歌词必然要对此做一点细微的改动，以达到相似又递进的效果。</p><p>某一天夜里我从实验室骑着平衡车向着寝室行进的时候，突然同时看到一位朋友和相恋数年的恋人分手的消息；而在那条消息的下面是另一个同学和爱人激动的官宣。这种强烈的对比和反差让我感觉很不真实，就好像时间被割裂，分手的那对爱人几年前也如胶似漆至此，而几年里便时过境迁、物是人非。</p><p>在这种强烈的不真实感的围绕下，那一瞬间我突然觉得，所有的美好和悲伤都会消失而去的，时间是最平滑最锋利的刃，无论我们挣扎还是沉眠，它平等切割过一切我们能看到和能想到的事物。</p><p>——“这人生，聚散间睡梦中，不知不觉就成空”。</p><p>我写下。</p><p>然后我觉得这首歌至此在逻辑和情感上已经足够圆满；虽然在遣词造句上还有许多可以改进的地方，但在结构上已经彻底达成了我给自己定下的目标。</p><p>一份让人满意的答卷。</p><p>未来的某一天，再看到自己现在写的歌词，我也会感觉在“聚散间睡梦中”，人生便不知不觉成空了吗？在点击提交的那一瞬间，我想。</p><p>提交之后我熄灭电脑，躺在床上，直直的盯着天花板；我也要去梦里找寻我所希求的美好了吧？</p>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【科技文明通论 期末论文】智能的逆流与边界</title>
    <link href="/2024/06/11/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E6%99%BA%E8%83%BD%E7%9A%84%E9%80%86%E6%B5%81%E4%B8%8E%E8%BE%B9%E7%95%8C/"/>
    <url>/2024/06/11/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E6%99%BA%E8%83%BD%E7%9A%84%E9%80%86%E6%B5%81%E4%B8%8E%E8%BE%B9%E7%95%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="智能的逆流和边界：AI浪潮下的“为何”与“如何”"><a href="#智能的逆流和边界：AI浪潮下的“为何”与“如何”" class="headerlink" title="智能的逆流和边界：AI浪潮下的“为何”与“如何”"></a>智能的逆流和边界：AI浪潮下的“为何”与“如何”</h1><blockquote><p>摘要：在 2023 年，由 OpenAI 推出的 ChatGPT 带来了人工智能的新时代，成为增长最快的网络平台之一。然而，这并不意味着 AI 已经能够替代人类处理所有事务。它仍然出现了一些不完美的地方：即所谓的“逆流”与“边界”——人工智能虽然可以在一些领域取得远超人类的能力，却仍然在很多看起来并不复杂的事情上具有相当的局限性。本文尝试从技术、经济和社会三个角度分析和解释人工智能出现“逆流”和“边界”的原因，并思考和探索这样一个问题：在这样的时代背景下，我们——科研工作者、智能产业的一员，以及时代里的普通人，应该何去何从？</p></blockquote><blockquote><p>关键词：人工智能，逆流，边界，科学态度，技术与人</p></blockquote><h2 id="1-背景介绍"><a href="#1-背景介绍" class="headerlink" title="1. 背景介绍"></a>1. 背景介绍</h2><p>在刚刚过去的 2023 年里，随着 OpenAI 推出的 ChatGPT 一炮而红，成为有史以来增长最快的网络平台之一，AI 大模型这个概念几乎横扫了全球的学术圈和创业-投资圈。学术圈里，和大模型结合的论文占据了机器学习相关会议、期刊的半壁江山；创业-投资圈里，大量打着大模型旗号的创业公司风生水起，推出各色各样相近又不相同的大模型服务。几乎所有学校都有大量实验室在大模型方向开始耕耘，几乎所有的互联网公司都推出了自己的大模型服务。</p><p>在人工智能的历史里，除了少数的几个爆发时刻，它都只是在跌宕起伏里沉寂。而无疑，ChatGPT 带来的这个新时代里，是人工智能闪耀的爆发时代。人们又开始重拾自己对所谓“强人工智能【Goertzel, Ben. (2014). Artificial General Intelligence: Concept, State of the Art, and Future Prospects. Journal of Artificial General Intelligence. 10.2478&#x2F;jagi-2014-0001.】”的渴望，我们都在期待着它能够带我们步入全新的幸福世界里。</p><p>但这一切并不是完美的。有人感慨：我们希望机器人帮助人类扫地、洗碗，是因为人类要去写诗、画画。现在机器人都去写诗、画画了，人类却还在扫地、洗碗——</p><p>这就是我们要提出的两个概念：“逆流”和“边界”。</p><p>“逆流”，是指在某些我们认为需要高级智能和复杂思考的任务上，比如艺术创作或深度学习，人工智能表现出了超出人类的能力。然而，在一些看似简单的任务上，如清洁或洗碗，人工智能却面临挑战。这是因为人工智能并不是通过理解和感受来学习，而是通过对大量数据和其中模式的分析。<br>另一方面，“边界”揭示了人工智能的局限。人工智能的性能和功能取决于其训练数据和算法，只能在特定的任务和环境中表现出优越性。一旦超出这些预设的范围，“边界”，人工智能的表现就可能大幅度下降。这就解释了为什么人工智能在一些特定的领域中能超越人类，但在全面的、需要广泛理解和适应性的任务上，人工智能仍然无法与人类相匹敌。</p><p>本文将主要包含两个部分：</p><ul><li>首先，我们尝试从技术、经济和社会这几个不同角度分析，“逆流”和“边界”出现的原因是什么；</li><li>其次，我们思考，在这个新的时代里，我们应该如何去引导技术的发展，去突破这所谓的边界？我们应该如何对待那些我们生活中的新技术？</li></ul><p>或许，我们想要的答案并不在于，去简单地直接期待机器人替代我们所做的各种琐事，而在于重新审视人与技术之间的关系。站在逆流之中，我们应当审视自身，思考技术的本质意义，以及如何在这个瞬息万变的科技时代中保持人性的温暖和智慧。或许，只有在人与技术相互融合、共同发展的道路上，我们才能找到答案，迈向一个更加美好、和谐的未来。</p><h2 id="2-逆流与边界：AI-技术为何偏离我们曾经的预期"><a href="#2-逆流与边界：AI-技术为何偏离我们曾经的预期" class="headerlink" title="2. 逆流与边界：AI 技术为何偏离我们曾经的预期"></a>2. 逆流与边界：AI 技术为何偏离我们曾经的预期</h2><p>纵观上世纪以来，在有关于人工智能的幻想里，我们对人工智能【阿瑟·克拉克 著 郝明义 译．2001太空漫游．上海．上海人民出版社．2014-5】的幻想几乎都是，人工智能用强大的生产能力替代了工人、农民和服务业人员，让绝大多数的人无所事事，从而引发一系列的现象或者问题。</p><p>但这轮热潮中，我们见到的现象并非如此：人工智能似乎在写作、绘画、智力工作（比如围棋【人工智能取得新突破, 电脑程序首次击败围棋专业选手．新华网．2016-01-28】）和音乐上体现了惊人的，媲美乃至于超过人类的能力，但似乎那些在我们生活中各色各样的琐碎的事务，诸如扫地、洗碗……等等事情，却仍然是由我们人类自己来做。有人调侃道：“我们希望机器人帮助人类扫地、洗碗，是因为人类要去写诗、画画。现在机器人都去写诗、画画了，人类却还在扫地、洗碗。”</p><p>这是为什么？</p><h3 id="2-1-技术角度"><a href="#2-1-技术角度" class="headerlink" title="2.1. 技术角度"></a>2.1. 技术角度</h3><p>对于人类来说，扫地洗碗是非常简单的事情，甚至几乎不需要学习；而写作、绘画和音乐则需要大量的学习才能做到。因此，我们认为，前者是“简单”的事情，后者是“困难”的事情。因此，当我们的人工智能能够做到写作、绘画这类我们认为“复杂”的事情时，我们会下意识地认为，那些被我们认为“简单”的事情，一定能被人工智能所轻易掌握。</p><p>但是事实并非如此。事实上，这就是当前人工智能浪潮中所存在的两个问题：</p><ol><li>“逆流”：人工智能能处理一些我们觉得非常困难的事务，比如写作、绘画；</li><li>“边界”：人工智能在一些我们觉得并不困难的事物上表现平平。</li></ol><p>这是为什么呢？让我们关注两个角度的事实：</p><h4 id="1-对于不同的方法而言，“简单”和复杂不能一概而论"><a href="#1-对于不同的方法而言，“简单”和复杂不能一概而论" class="headerlink" title="1. 对于不同的方法而言，“简单”和复杂不能一概而论"></a>1. 对于不同的方法而言，“简单”和复杂不能一概而论</h4><p>在一些问题上，人类和计算机处理信息的方案有非常明显的区别：<br>在计算能力上，大部分普通人只能心算两位数左右的乘法，或者三四位数的加法，而计算机执行乘法运算则强大的多。现在的一台计算设备（如：RTX 4060）的算力是15.1 TFLOPS【GeForce RTX 4060 Ti &amp; 4060 显卡, NVIDIA．<a href="https://nvidia.cn/geforce/graphics-cards/40-series/rtx-4060-4060ti/%E3%80%91%EF%BC%8C%E4%B9%9F%E5%B0%B1%E6%98%AF%E8%AF%B4%EF%BC%8C%E5%AE%83%E5%8F%AF%E4%BB%A5%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%B8%80%E7%A7%92%E5%86%85%E8%BF%9B%E8%A1%8C%E4%B8%80%E4%B8%87%E4%BA%BF%E6%AC%A1%E5%87%86%E7%A1%AE%E7%9A%8432%E4%BD%8D%E6%B5%AE%E7%82%B9%E6%95%B0%E4%B9%98%E6%B3%95%E8%BF%90%E7%AE%97%EF%BC%8C%E8%BF%99%E9%9C%80%E8%A6%81%E4%B8%80%E4%B8%AA%E4%BA%BA%E7%B1%BB%E7%AE%97%E6%95%B0%E7%99%BE%E4%B8%87%E5%B9%B4%EF%BC%9B%E4%BD%86%E6%98%AF%E5%9C%A8%E4%BC%B0%E7%AE%97%E8%83%BD%E5%8A%9B%E4%B8%8A%EF%BC%8C%E4%BA%BA%E8%84%91%E7%9A%84%E6%9F%90%E4%BA%9B%E6%9C%AA%E7%9F%A5%E7%9A%84%E6%9C%BA%E5%88%B6%E5%8F%AF%E4%BB%A5%E8%AE%A9%E4%BA%BA%E8%84%91%E5%9C%A8%E6%9F%90%E4%B8%AA%E6%97%B6%E9%97%B4%E5%86%85%E5%AF%B9%E6%9F%90%E4%BA%9B%E9%9D%9E%E5%B8%B8%E5%A4%8D%E6%9D%82%E7%9A%84%E9%97%AE%E9%A2%98%E7%BB%99%E5%87%BA%E4%B8%80%E4%B8%AA%E9%9D%9E%E5%B8%B8%E6%8E%A5%E8%BF%91%E6%9C%80%E4%BC%98%E8%A7%A3%E7%9A%84%E8%BE%B9%E7%95%8C%EF%BC%8C%E8%80%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BD%BF%E7%94%A8%E7%9A%84%E5%A4%A7%E9%83%A8%E5%88%86%E7%AE%97%E6%B3%95%EF%BC%8C%E5%8D%B3%E4%BD%BF%E6%8B%A5%E6%9C%89%E6%9B%B4%E5%BC%BA%E5%A4%A7%E7%9A%84%E7%AE%97%E5%8A%9B%EF%BC%8C%E4%B9%9F%E9%9C%80%E8%A6%81%E9%9D%9E%E5%B8%B8%E4%B9%85%E7%9A%84%E6%97%B6%E9%97%B4%E3%80%82">https://nvidia.cn/geforce/graphics-cards/40-series/rtx-4060-4060ti/】，也就是说，它可以可以在一秒内进行一万亿次准确的32位浮点数乘法运算，这需要一个人类算数百万年；但是在估算能力上，人脑的某些未知的机制可以让人脑在某个时间内对某些非常复杂的问题给出一个非常接近最优解的边界，而计算机使用的大部分算法，即使拥有更强大的算力，也需要非常久的时间。</a><br>以旅行商问题为例：假设每个点代表一个城市，一个售货员必须访问所有城市，并且恰好访问每个城市一次，并最终回到出发城市。旅行商问题就是找总路径最短的走法。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240706131933.png"></p><p>我们随机给出20个点，几乎大部分人都能在相当短的时间内找到一个接近最优解的方案：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240706131950.png"></p><p>通过计算机模拟，这个路径的总长度是20.45。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240706132107.png"></p><p>而使用计算机的常见算法（例如：贪心算法）也能给出一个解答，但即使我们不提到这个方案的距离结果，我们也能“感觉”到，它不是一个很好的解答。（事实上，这个解法的距离是24.48）。</p><p>事实上，目前对人类到底通过什么样的方案去估算，并没有一个确定的解答。有人认为是人类自动采取了一些经验策略，也有人说人类可以快速排除那些劣等的方案，得到一个比较不错的结果。但无论如何，这种估算能力，是目前开发的各种经验算法所难以完全媲美的。</p><p>因此，我们可以认为，在一些问题上，我们所体会到的复杂程度与计算机和其中的人工智能相比，会有很明显的区别。</p><p>就以扫地的例子，我们来尝试用逻辑去构建一个程序，来实现相应的功能：</p><ul><li>首先，我们需要知道什么时候扫地：可能需要判断“场景”是否合适——在宴请宾客的时候显然不适合扫地；在需要安静的时候也不应该扫地；在刚扫完不久又没有意外情况的时候，也不应该扫地……事实上，这个判断就已经是非常主观的问题，想准确划定边界就已经是难中之难。</li><li>然后，扫把在哪里？对于一个完全自主的机器人来说，它可能需要先去寻找上次存放扫把的位置；但如果不在的话怎么办呢？用什么策略去搜索？是否需要向它的“主人”询问？什么时候询问？……这又涉及到一系列问题。</li><li>现在，机器人已经拿到了扫把。它该如何去进行扫地工作？如何去防止碰到其他人？在场景可能和上次有所不同的情况下，如何判断哪些地方需要扫，哪些地方（诸如地上的玩具）是不该扫的？怎么规划路线？……这又是一些没有固定解的问题。甚至某些相似的场景里，它可能需要做出不同的决策。（比如：孩子把玩具打坏了，或者只是放在地上）</li></ul><p>仅仅是进行一些简单的分析，我们就能意识到，这些日常事务的复杂程度远远超出了我们原本的预期。那为什么我们会觉得它们并不困难呢？</p><h4 id="2-人类经过了非常足够的“预训练”"><a href="#2-人类经过了非常足够的“预训练”" class="headerlink" title="2. 人类经过了非常足够的“预训练”"></a>2. 人类经过了非常足够的“预训练”</h4><p>事实上，我们所经受的预训练比我们所以为的更多：且不谈从出生开始，我们每时每刻都在接受周围的信息【每天接收约34GB信息，大脑要超载. 新华网, 2009 年 12 月 15 日，<a href="https://www.chinanews.com.cn/it/it-itxw/news/2009/12-15/2019016.shtml%E3%80%91%E3%80%82%E6%97%A0%E8%AE%BA%E6%98%AF%E7%9C%8B%E5%88%B0%E7%88%B6%E6%AF%8D%E7%9A%84%E8%A1%8C%E4%B8%BA%EF%BC%8C%E8%BF%98%E6%98%AF%E5%90%AC%E5%88%B0%E5%85%B6%E4%BB%96%E4%BA%BA%E4%B9%8B%E9%97%B4%E7%9A%84%E5%AF%B9%E8%AF%9D%EF%BC%8C%E9%83%BD%E5%AF%B9%E6%88%91%E4%BB%AC%E7%9A%84%E8%A1%8C%E4%B8%BA%E6%9C%89%E6%BD%9C%E7%A7%BB%E9%BB%98%E5%8C%96%E7%9A%84%E5%BD%B1%E5%93%8D%EF%BC%9B%E5%B0%B1%E5%8D%95%E8%AF%B4%E7%94%B1%E5%9F%BA%E5%9B%A0%E6%8C%87%E5%AF%BC%E5%8F%91%E8%82%B2%E8%80%8C%E6%9D%A5%E7%9A%84%E5%A4%A7%E8%84%91%EF%BC%8C%E5%85%B6%E6%9C%AC%E8%BA%AB%E5%B0%B1%E5%B7%B2%E7%BB%8F%E6%90%BA%E5%B8%A6%E4%BA%86%E7%9B%B8%E5%BD%93%E5%A4%9A%E7%9A%84%E4%BF%A1%E6%81%AF%E3%80%82%E5%8F%AF%E4%BB%A5%E8%AF%B4%EF%BC%8C%E5%A4%A7%E8%84%91%E5%9C%A8%E8%BF%9B%E8%A1%8C%E2%80%9C%E5%88%9D%E5%A7%8B%E5%8C%96%E2%80%9D%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%B0%B1%E5%B7%B2%E7%BB%8F%E6%98%AF%E7%BB%8F%E8%BF%87%E4%B8%80%E6%AC%A1%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E7%8A%B6%E6%80%81%E4%BA%86%E3%80%82">https://www.chinanews.com.cn/it/it-itxw/news/2009/12-15/2019016.shtml】。无论是看到父母的行为，还是听到其他人之间的对话，都对我们的行为有潜移默化的影响；就单说由基因指导发育而来的大脑，其本身就已经携带了相当多的信息。可以说，大脑在进行“初始化”的时候，就已经是经过一次预训练的状态了。</a></p><p>因此，对于一个在正常社会中健康成长的人来说，上述问题恐怕都未必是问题：</p><ul><li>什么时候扫地？——需要扫的时候就扫嘛！这本质上是个经验和习惯使然的概率问题；</li><li>如何找？按照逻辑去寻找！正常人当然不会把扫把放在一些很奇怪的地方，而且也可以通过回忆去推理可能的位置；</li><li>扫地的路线更不是问题，从某个房间开始扫扫就行了；</li><li>…</li></ul><p>我们所经过的大量“预训练”给了我们足够的“经验”，让我们在遇到大多数情况的时候，可以下意识做出一些接近最优解——至少原理劣解的方案，并且很多经验可能具有相当强的泛化性。<br>这也就解释了为什么很多我们认为简单的事情 AI 难以处理。那，美术、音乐等事情，AI 又是如何解决的呢？</p><h4 id="3-艺术的体验和评价仍然是人类进行的"><a href="#3-艺术的体验和评价仍然是人类进行的" class="headerlink" title="3. 艺术的体验和评价仍然是人类进行的"></a>3. 艺术的体验和评价仍然是人类进行的</h4><p>与此相比，无论是视觉艺术如绘画，还是听觉艺术如音乐，它们都有一个共同的特点：艺术的创造和欣赏都是由人类主导的。</p><p>以绘画为例，每一幅画作都是画家内心情感的外化，是他们对世界的理解和感受的记录。画家的每一笔、每一色，都载着他们的喜怒哀乐，他们的思考和追求。而当我们欣赏这些画作时，我们也会在画家的世界中找到共鸣，感受到他们的情感，理解他们的思想。这个欣赏的过程是作者和读者共同完成的。</p><p>然而，AI 的创作方式【McIntosh, Timothy &amp; Susnjak, Teo &amp; Tong, Liu &amp; Watters, Paul &amp; Halgamuge, Malka. (2023). From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape. 10.48550&#x2F;arxiv.2312.10868.】截然不同。AI 通过以大量的艺术作品作为输入，去用类似记忆的方式，学习不同的作品描述所对应的概率函数，掌握了一种”模拟”创作的能力。它可以生成样式各异的画作，甚至能模仿出莫奈、毕加索等大师的风格。然而，这些产生的作品并不包含AI的情感或思想，因为 AI 并不能理解这些概念。它只是在模仿和生成，而非真正的创作。</p><p>因此，我们似乎感觉 AI 能够创作出很多奇妙的作品，但是，当我们欣赏 AI 生成的艺术作品时，我们其实是在体验自己的情感和思想。我们在这些作品中看到的美和感动，其实是我们自己的内心反映。这就是为什么，尽管AI可以生成出色的艺术作品，但人类仍然是艺术创作和欣赏的主导者。</p><p>这就是我们之前所提到的”逆流”现象的体现。通常，我们会认为艺术创作是一项复杂的任务，需要深度的理解和感受，需要丰富的经验和技巧。这种逆流现象揭示了人工智能的一种根本特性：AI的能力并不是按照我们的直觉或经验来分布的。它的能力取决于它的学习和训练，取决于它可以获取和处理的数据。</p><p>因此，在技术角度，我们可以总结“逆流”和“边界”的出现的原因：</p><ul><li>首先，”逆流”现象的出现，主要源于人工智能的学习方式。人工智能并不是通过理解和感受来学习，而是通过分析大量的数据和找出其中的模式。因此，AI在那些可以获取大量数据并且有明确模式的任务上，如艺术创作，表现出了惊人的能力。</li><li>其次，”边界”现象的出现，主要源于人工智能的局限性。在某些看似简单但实际上需要深度理解和感知的任务上，如清扫或洗碗，AI 却意外地表现出了困难。AI 的能力取决于它的训练数据和算法，因此，它只能在特定的任务和环境中表现出优越性。一旦超出了这些范围，AI 的性能就会大幅下降。这就是为什么 AI 在一些特定的任务上表现出了超越人类的能力，但在整体上，尤其是在需要广泛理解和适应力的任务上，AI 仍然无法与人类相比。</li><li>但是，人工智能没有深入进入我们生活的原因绝不仅限于技术。如果有足够投入的话，刚才提到的很多问题，都有可能被聪明的人们设法解决。接下来，我将从其他两个角度——经济和社会，来分析人工智能技术的局限性。</li></ul><h3 id="2-2-经济角度"><a href="#2-2-经济角度" class="headerlink" title="2.2. 经济角度"></a>2.2. 经济角度</h3><p>考虑一项技术是否实用，不能仅仅考察其效果，更要考察其成本。如果一项技术只有全球前十万分之一的人能用的起，那恐怕这项技术就很难谈得上“进入我们的生活”。因此，一个技术的实用价值，还要考虑其广泛可用性和可负担性。</p><p>一个非常现实的事情是，现在绝大多数 AI 技术的成本【数据猿. 云计算成本大揭秘，2023年6月22日，<a href="https://new.qq.com/rain/a/20230622A003YD00%E3%80%91%EF%BC%8C%E5%87%A0%E4%B9%8E%E9%83%BD%E8%BF%9C%E8%BF%9C%E5%A4%A7%E4%BA%8E%E4%BA%BA%E7%B1%BB%EF%BC%9A%E8%B4%AD%E4%B9%B0%E4%B8%80%E5%BC%A0%E5%A4%A7%E5%9E%8B%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8D%A1%E6%89%80%E9%9C%80%E7%9A%84%E8%B5%84%E9%87%91%EF%BC%8C%E5%8F%AF%E8%83%BD%E7%9B%B8%E5%BD%93%E4%BA%8E%E4%B8%80%E4%B8%AA%E5%85%A8%E8%81%8C%E6%B8%85%E6%B4%81%E5%B7%A5%E5%87%A0%E5%B9%B4%E7%9A%84%E5%B7%A5%E8%B5%84%E3%80%82%E8%80%8C%E5%A4%A7%E5%9E%8B%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87%E9%9C%80%E8%A6%81%E6%95%B0%E4%BB%A5%E5%8D%83%E8%AE%A1%E7%9A%84%E8%AE%A1%E7%AE%97%E5%8D%A1%EF%BC%8C%E5%B9%B6%E4%B8%94%E8%BF%98%E4%BC%B4%E9%9A%8F%E7%9D%80%E5%B7%A8%E5%A4%A7%E7%9A%84%E7%94%B5%E5%8A%9B%E3%80%81%E6%95%A3%E7%83%AD%E5%92%8C%E7%BB%B4%E6%8A%A4%E6%88%90%E6%9C%AC%EF%BC%8C%E8%BF%99%E5%AF%B9%E6%99%AE%E9%80%9A%E4%BA%BA%E6%9D%A5%E8%AF%B4%E6%98%AF%E6%97%A0%E6%B3%95%E6%89%BF%E5%8F%97%E7%9A%84%E3%80%82">https://new.qq.com/rain/a/20230622A003YD00】，几乎都远远大于人类：购买一张大型计算设备的计算卡所需的资金，可能相当于一个全职清洁工几年的工资。而大型计算设备需要数以千计的计算卡，并且还伴随着巨大的电力、散热和维护成本，这对普通人来说是无法承受的。</a></p><p>这就引出了一个关键问题：即使我们投入大量人力物力，研发出的最先进的 AI 模型能够处理各种杂务，对于数十亿分之一的我们而言，又有何意义呢？</p><p>我们需要意识到，技术的发展并非简单直接的线性行为，而是需要在效果和成本之间找到一个平衡。如果一种技术只关注于提升效果，而忽视了其对使用者的负担，那么这种技术的实用性就大打折扣。<br>另外，我们还需要考虑到技术的普及程度。一个技术如果只有少数人能用，那么它的影响力就会大大减小，不能真正推动社会进步。因此，我们在研发新技术的时候，不仅要考虑到其科技水平，也要考虑到其普及性和可持续性。</p><p>总的来说，一个真正有意义的技术，应该是既可以提升效果，又可以被大多数人所接受和使用的。这样的技术，才能真正改变我们的生活，推动我们的社会向前发展。当下，AI 技术的成本问题，限制了它的广泛应用。对于大多数人来说，高昂的设备成本和运营成本使得他们难以接触和使用这些先进的技术。这导致 AI 技术的普及程度低，无法在更广泛的领域发挥其潜在价值。</p><h3 id="2-3-社会角度"><a href="#2-3-社会角度" class="headerlink" title="2.3. 社会角度"></a>2.3. 社会角度</h3><p>如今的 AI 浪潮下，我们面临着一个至关重要的挑战，那就是在众多关键的社会事务中，人工智能往往无法承担起应由人类承担的责任。这不仅涉及到技术的局限性，更触及到我们对于责任、道德和社会公正的理解。在此背景下，我们需要深入探讨AI的边界，理解其在处理复杂社会问题时的逆流，从而寻找到一种能够平衡技术进步和社会责任的方法。我们以两个不同领域的例子来分析问题：</p><h4 id="2-3-1-智能驾驶中的社会责任问题"><a href="#2-3-1-智能驾驶中的社会责任问题" class="headerlink" title="2.3.1. 智能驾驶中的社会责任问题"></a>2.3.1. 智能驾驶中的社会责任问题</h4><p>智能驾驶是人工智能在现实生活中的重要应用之一。然而，当发生意外情况时，人工智能的处理能力就显得相对薄弱。例如，在一次由于天气原因导致的交通事故中，虽然自动驾驶车辆已经尽可能执行了预设的避险程序，但由于无法像人类驾驶员那样对状况进行深度理解和即时判断，最终还是未能避免事故的发生。</p><p>在这种情况下，我们面临的主要问题就是如何确定人工智能的责任归属【刘凯，自动驾驶车祸谁担责？AGI专家详解法律责任，突破伦理困境：渤海大学教育科学学院、渤海大学通用人工智能研究所，2021. <a href="https://mp.weixin.qq.com/s/ZRauhiypIKqJxf9uDetS3A%E3%80%91%E3%80%82%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AC%E8%B4%A8%E4%B8%8A%E6%98%AF%E4%B8%80%E7%A7%8D%E7%94%B1%E5%A4%8D%E6%9D%82%E7%AE%97%E6%B3%95%E5%92%8C%E7%A8%8B%E5%BA%8F%E6%9E%84%E6%88%90%E7%9A%84%E7%B3%BB%E7%BB%9F%EF%BC%8C%E5%AE%83%E6%8C%89%E7%85%A7%E9%A2%84%E8%AE%BE%E7%9A%84%E8%A7%84%E5%88%99%E5%92%8C%E5%8F%82%E6%95%B0%E8%BF%9B%E8%A1%8C%E6%93%8D%E4%BD%9C%EF%BC%8C%E4%BD%86%E5%B9%B6%E6%97%A0%E6%B3%95%E7%90%86%E8%A7%A3%E6%88%96%E6%89%BF%E6%8B%85%E9%81%93%E5%BE%B7%E5%92%8C%E8%B4%A3%E4%BB%BB%E7%9A%84%E5%90%AB%E4%B9%89%E3%80%82%E8%BF%99%E5%B0%B1%E4%BD%BF%E5%BE%97%E8%B4%A3%E4%BB%BB%E5%BD%92%E5%B1%9E%E9%97%AE%E9%A2%98%E5%8F%98%E5%BE%97%E6%9E%81%E5%85%B7%E6%8C%91%E6%88%98%EF%BC%8C%E6%97%A2%E6%B6%89%E5%8F%8A%E5%88%B0%E6%8A%80%E6%9C%AF%E5%B1%82%E9%9D%A2%E7%9A%84%E8%AE%A8%E8%AE%BA%EF%BC%8C%E4%B9%9F%E5%BC%95%E5%8F%91%E4%BA%86%E6%B3%95%E5%BE%8B%E5%92%8C%E9%81%93%E5%BE%B7%E5%B1%82%E9%9D%A2%E7%9A%84%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E3%80%82">https://mp.weixin.qq.com/s/ZRauhiypIKqJxf9uDetS3A】。人工智能本质上是一种由复杂算法和程序构成的系统，它按照预设的规则和参数进行操作，但并无法理解或承担道德和责任的含义。这就使得责任归属问题变得极具挑战，既涉及到技术层面的讨论，也引发了法律和道德层面的深度思考。</a></p><p>此外，人工智能的可解释性问题也令人担忧。对于人类驾驶员来说，他们可以通过保持良好的休息、避免在恶劣天气中驾驶等方式来降低出错的可能性。然而，人工智能的错误往往源于模型的不可预测性和不可解释性，这使得错误发生的可能性变得难以预料。人们通常会更难接受这种无法预防和理解的错误。这些问题都凸显了，尽管人工智能在智能驾驶等领域具有巨大的潜力，但在实际应用中，我们仍然需要面对其存在的局限性和挑战。</p><h4 id="2-3-2-经济、法律等领域中的责任问题"><a href="#2-3-2-经济、法律等领域中的责任问题" class="headerlink" title="2.3.2. 经济、法律等领域中的责任问题"></a>2.3.2. 经济、法律等领域中的责任问题</h4><p>现在网络上有一个笑话：人工智能永远不能代替会计和律师，因为它不能坐牢。事实也确实如此：</p><p>在经济领域，AI已经广泛应用于金融市场预测、投资决策等方面。然而，当某一投资决策失败，导致经济损失时，我们不能简单地将责任归咎于AI。因为，AI只是根据预先输入的数据和算法进行决策，它并无法理解和承担责任的含义。</p><p>类似地，在法律领域，AI 可以帮助我们分析大量的法律文本、案例和先例，但当需要进行法律判断、道德考量以及责任归属确定等复杂任务时，AI 的局限性就会显现出来。因为这些任务不仅需要理性的逻辑分析，更需要深度的情感理解、道德判断以及对法律精神的深入把握，这是目前的 AI 技术无法实现的。</p><p>在这个过程中，我们需要对 AI 的应用有更深入的理解和更审慎的态度。AI 是一种强大的工具，它可以帮助我们处理大量的数据和复杂的问题，但它并不能替代人类进行深度的思考和责任的承担。我们应该适当地使用 AI ，而不是过度依赖它，更不能期待它来承担应由人类承担的责任。</p><p>总结，人工智能在处理复杂社会事务上的局限性揭示了我们需要在技术进步与社会责任之间找到平衡，这需要我们整合多领域的知识，包括计算机科学、经济、法律、伦理学等，以构建一个全面、合理的 AI 责任框架。这样，我们才能保证 AI 的持续发展，同时确保社会的公平、公正和稳定。 </p><h2 id="3-界中人：浪潮下，我们如何自处"><a href="#3-界中人：浪潮下，我们如何自处" class="headerlink" title="3. 界中人：浪潮下，我们如何自处"></a>3. 界中人：浪潮下，我们如何自处</h2><p>在前文中，我们总结了一些人工智能的现状，我们称之为“逆流”和“边界”——一方面，由于技术路线的原因，人工智能能够解决某些我们认为很复杂的问题；另一方面，它却在我们觉得简单的事情上遇到很大的困难乃至于束手无策。在这种矛盾而又不可思议的现状下，我们需要思考一个问题：面对这股涌动的浪潮，我们应该如何定位自己，如何在其中找到自己的立足之处？</p><h3 id="3-1-求知：对于理论上的可解释性的持续追求"><a href="#3-1-求知：对于理论上的可解释性的持续追求" class="headerlink" title="3.1. 求知：对于理论上的可解释性的持续追求"></a>3.1. 求知：对于理论上的可解释性的持续追求</h3><p>对于从事人工智能理论研究的科学家们，可解释性成为了他们的首要追求。在大部分情况下，我们并不能满足于一个庞大且神秘的”黑箱”，即使它的表现超越了所有人类。我们渴望理解其内在工作原理，掌握其背后的逻辑和规则，这是我们对知识的尊重，也是对科学的敬畏。</p><p>作为一名专注于计算机科学研究的学者，我认为追求人工智能的可解释性可以从以下两个方向深入开展：</p><ol><li>基于高维数学物理方法的深度学习解释：深度学习模型的内部机制复杂且高维，要理解其工作原理，我们需要借助于高维数学和物理学的理论。这可能包括研究高维空间的几何性质，理解深度学习模型如何将输入数据映射到这个高维空间，以及如何在这个空间中寻找最优解【Na Lei, Dongsheng An, Yang Guo, Kehua Su, Shixia Liu, Zhongxuan Luo, Shing-Tung Yau, Xianfeng Gu.A Geometric Understanding of Deep Learning[J].Engineering,2020,6(3):361-374.】。这一方向的研究可以帮助我们揭示深度学习模型的内部运作逻辑，理解其如何处理和理解数据，以及为何能够取得如此出色的效果。</li><li>结合传统数理方法的新智能框架：另一方向是尝试将传统的数理方法与现代的人工智能技术结合，构建新的智能框架。这可能包括将统计学习理论、图论、最优化理论等传统数理方法引入到人工智能模型中【Ren, Qihan &amp; Gao, Jiayang &amp; Shen, Wen &amp; Zhang, Quanshi. (2023). Where We Have Arrived in Proving the Emergence of Sparse Symbolic Concepts in AI Models.】，以提高模型的可解释性和鲁棒性。这一方向的研究可以帮助我们构建出既有强大性能，又具有良好可解释性的新型人工智能模型。</li></ol><p>热潮过后，我们需要深入探索，去理解ChatGPT等复杂模型背后的原理和逻辑。这是科学家们的责任，也是我们理解和把握新时代关键的途径。只有真正理解了这些技术，我们才能充分利用它们，才能在人工智能的浪潮中找到自己的位置。而这一切，都离不开我们对知识的深度追求，对理论上的可解释性的持续探索。</p><h3 id="3-2-拓荒：在技术上，拓展人工智能与生活的边界"><a href="#3-2-拓荒：在技术上，拓展人工智能与生活的边界" class="headerlink" title="3.2. 拓荒：在技术上，拓展人工智能与生活的边界"></a>3.2. 拓荒：在技术上，拓展人工智能与生活的边界</h3><p>除了深入探索学术理论，我们也需要考虑人工智能技术如何更好地融入我们的日常生活。这是一个至关重要的议题，因为如果人工智能只能为少数拥有高端计算设备的富裕人群提供服务，那么它的影响力将非常有限。<br>在追求技术进步和提升智能能力的同时，我们必须关注如何更好地将这些技术应用到我们的日常生活中。无论是与传统产业的融合，如小米的智能工厂，这种将人工智能技术应用在生产线上，提升效率，降低人工成本；还是与传统科学的结合，如 AI For Science 项目，通过利用人工智能技术解决科学问题，推动科学发展，都是值得我们深入探索的方向。</p><p>另一方面，我们也需要鼓励和推崇开发低功耗的智能系统。任何技术，无论其效果有多么出色，如果其能耗过高，那它就很难真正融入我们的日常生活。除非我们突然找到了实用的可控核聚变技术，否则我们必须一直关注能源效率问题。例如，我们的智能手机就是一种低功耗的设备。尽管它们的计算能力远不及大型数据中心，但是它们仍然能够运行各种复杂的人工智能应用，如语音识别、图像识别等。另外，像一些智能家居设备，比如智能恒温器、智能灯泡等，也是在低能耗的前提下，实现了智能化。</p><p>因此，我们在拓展人工智能技术的边界时，不仅要注重提升其智能水平，也要考虑其能耗问题，只有这样我们才能真正将人工智能带入每个人的生活中。</p><h3 id="3-3-拥抱：于我们自身，永远不对新技术设限"><a href="#3-3-拥抱：于我们自身，永远不对新技术设限" class="headerlink" title="3.3. 拥抱：于我们自身，永远不对新技术设限"></a>3.3. 拥抱：于我们自身，永远不对新技术设限</h3><p>抛开学术界的身份，作为时代中的一粒尘埃般的人，我们该如何自处？或许我们能做的，也只有永远不设限这一件事情了。</p><p>面对 GPT 的时候，先不去反驳“这种东西肯定不靠谱”；面对 AI 绘画的时候，不要一开始就否定其作品的艺术价值，而是先尝试理解和欣赏；面对那些 AI 换脸、拟声技术的时候，认真对待，和朋友约定一些暗号防止被这些技术欺骗，而不是大大咧咧的说“我怎么可能会上当”……这些细节体现的是我们对技术的尊重，是一种不预设任何结论，而是去亲身实践的科学态度。</p><p>无论我们是青年、中年还是老年，无论我们是普通百姓、白领工作人员还是达官显贵，只有我们怀揣着科学的态度，尊重新技术，才能在这个飞速变化的时代里找到方向，掌握未来的机会。在过去的百多年里，我们经历了无数的废弃和创新，无数的旧事物消失，无数的新事物诞生。在那十八弯的时代洪流里，唯有科学的思考是不变的灯塔。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文旨在探讨，人工智能（AI）的发展现状及其对社会的影响。AI技术在许多领域，如艺术创作和深度学习，已经显示出超越人类的能力，这被称为“逆流”。然而，AI在一些看上去简单的任务上却遇到挑战，比如扫地和洗碗，这被称为“边界”。这种现象揭示了AI的局限性：它的能力取决于其训练数据和算法，只能在特定的任务和环境中表现出优越性。然而，一旦超出这些预设的范围，AI的表现就可能大幅度下降。</p><p>本文从技术、经济和社会三个角度分析了AI的“逆流”和“边界”现象。在技术角度，我们需要了解和掌握AI的工作原理，这需要进行深入的理论研究和实践探索。在经济角度，我们必须考虑AI技术的成本问题，以及技术的普及程度。在社会角度，我们需要面对AI在处理复杂社会事务上的局限性，包括确定AI的责任归属，以及处理AI的可解释性问题。</p><p>在面对AI的发展浪潮时，我们应该怀揣科学态度，尊重新技术，并永远不对新技术设限。我们应该适当地使用AI，而不是过度依赖它，更不能期待它来承担应由人类承担的责任。只有在人与技术相互融合、共同发展的道路上，我们才能找到答案，迈向一个更加美好、和谐的未来。</p>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【实用工具】Marp 和 ShanghaiTech Marp 主题</title>
    <link href="/2024/05/25/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Marp/"/>
    <url>/2024/05/25/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Marp/</url>
    
    <content type="html"><![CDATA[<h1 id="What’s-Marp"><a href="#What’s-Marp" class="headerlink" title="What’s Marp?"></a>What’s Marp?</h1><p>Marp 是一个利用 Markdown 制作幻灯片的工具。相比于 PowerPoint 等工具，它可以将人们从排版问题解放出来；相比于 LateX Beamer，它的操作更简单，在对格式要求不高的场合更加轻松方便。</p><p>详情参见：<a href="https://sspai.com/post/55718#!">Marp: Markdown 制作 PPT 的新选择</a></p><h1 id="ShanghaiTech-Marp-Template"><a href="#ShanghaiTech-Marp-Template" class="headerlink" title="ShanghaiTech Marp Template"></a>ShanghaiTech Marp Template</h1><p>在看到 <a href="https://sspai.com/post/83182#!">Awesome Marp: 一套好用的 Marp 美化主题</a> 之后，我就萌生了修改模板来方便平时 PPT 制作的念头。</p><p>具体而言，我选择了一套能展现校徽的子主题，并且重新整理了校徽的图像资源，调整了 Awesome 的 Red 主题的色调，制作了一套 ShanghaiTech 主题：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240525134153.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240525134246.png"></p><p>如果大家希望快速制作课程 Tutorial，又不想完全失去美观性的话，可以考虑用这套主题进行制作。</p><h1 id="我的仓库"><a href="#我的仓库" class="headerlink" title="我的仓库"></a>我的仓库</h1><p>我的 GitHub 仓库 <a href="https://github.com/HypoxanthineOvO/SHTU-PPT-Template">ShanghaiTech PPT Template</a> 整理了三种不同的 ShanghaiTech 模板：</p><ol><li>LaTeX Beamer：这套应该是毕业论文答辩等可以使用的模板</li><li>PowerPoint：学校官方给出的 PPT 模板</li><li>Markdown Marp：我存了三个不同的部分，Pure Marp 是原生 Marp 只放了背景图片的版本；Awesome Tutorial 是图示的版本。</li></ol><p>欢迎大家尝试使用！</p>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
      <category>实用工具</category>
      
    </categories>
    
    
    <tags>
      
      <tag>实用工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【环境配置】LaTeX 环境配置</title>
    <link href="/2024/05/06/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/LaTeX/"/>
    <url>/2024/05/06/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/LaTeX/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="https://www.overleaf.com/">OverLeaf</a> 无疑是非常好用的在线 LaTeX工具。但在使用中也时常遇到编译慢、掉线等问题。因此，在此整理一套本地 LaTeX 的环境配置教程，以方便后续使用。</p><h1 id="Install-Guide"><a href="#Install-Guide" class="headerlink" title="Install Guide"></a>Install Guide</h1><h2 id="安装-texlive"><a href="#安装-texlive" class="headerlink" title="安装 texlive"></a>安装 <code>texlive</code></h2><p>点击 <a href="https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/">清华大学 LaTeX 镜像站</a>，选择 <code>textlive202x.iso</code> 下载即可。</p><ul><li>注意，安装环境不可以有中文</li></ul><p>在下载好之后，点击 <code>.iso</code> 文件，然后点击里面的 <code>install-tl-windows.bat</code> 会进入 Windows Texlive 的安装。</p><blockquote><p>Linux 应该是使用 <code>install-tl</code> 脚本</p></blockquote><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p>在 Windows 系统的 PATH 里加上 texlive 的安装路径。</p><ul><li>注意，路径的后缀应该是 <code>202x/windows/</code></li></ul><p>然后，使用 <code>latex -v</code> 检查是否输出版本信息。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs powershell">pdfTeX <span class="hljs-number">3.141592653</span><span class="hljs-literal">-2</span>.<span class="hljs-number">6</span><span class="hljs-literal">-1</span>.<span class="hljs-number">40.26</span> (TeX Live <span class="hljs-number">2024</span>)<br>kpathsea version <span class="hljs-number">6.4</span>.<span class="hljs-number">0</span><br>Copyright <span class="hljs-number">2024</span> Han The Thanh (pdfTeX) et al.<br>There is NO warranty.  Redistribution of this software is<br>covered by the terms of both the pdfTeX copyright and<br>the Lesser GNU General Public License.<br><span class="hljs-keyword">For</span> more information about these matters, see the file<br>named COPYING and the pdfTeX source.<br>Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.<br>Compiled with libpng <span class="hljs-number">1.6</span>.<span class="hljs-number">43</span>; <span class="hljs-keyword">using</span> libpng 1.6.43<br>Compiled with zlib <span class="hljs-number">1.3</span>.<span class="hljs-number">1</span>; <span class="hljs-keyword">using</span> zlib 1.3.1<br>Compiled with xpdf version <span class="hljs-number">4.04</span><br></code></pre></td></tr></table></figure><p>如果有相应版本信息输出，则说明安装成功。</p><h2 id="VSCode-配置"><a href="#VSCode-配置" class="headerlink" title="VSCode 配置"></a>VSCode 配置</h2><h3 id="插件安装"><a href="#插件安装" class="headerlink" title="插件安装"></a>插件安装</h3><p>安装插件 LaTeX Workshop。</p><h3 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h3><p>在 <code>settings.json</code> 里加入：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;latex-workshop.latex.tools&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-string">&quot;-synctex=1&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;-interaction=nonstopmode&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;-file-line-error&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-string">&quot;%DOC%&quot;</span><br>      <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;bibtex&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;command&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;bibtex&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;%DOCFILE%&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;latex-workshop.latex.recipes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;tools&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;xelatex -&gt; bibtex -&gt; xelatex*2&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;tools&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;bibtex&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;xelatex&quot;</span><span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>理论上即可正确使用 Latex。</p><blockquote><p>MD 我的怎么环境变量有问题，回头有时间重启一下再看看怎么个事儿</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【讲座笔记】从 0 开始构建 GPU 生态——以沐曦集成电路（MeTax）为例</title>
    <link href="/2024/04/07/%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/MeTax-GPUEchoSystem/"/>
    <url>/2024/04/07/%E8%AE%B2%E5%BA%A7%E7%AC%94%E8%AE%B0/MeTax-GPUEchoSystem/</url>
    
    <content type="html"><![CDATA[<h1 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h1><p>本笔记整理于 2024 年 4 月 7 日，上海沐曦集成电路 CTO 杨建博士来上科大进行的产业分享讲座。</p><h1 id="1-什么是软件生态"><a href="#1-什么是软件生态" class="headerlink" title="1. 什么是软件生态"></a>1. 什么是软件生态</h1><ul><li><p>软件和软件生态是不同的。只有有人使用，有反馈和迭代，最终形成的比软件更为复杂的系统才能称之为生态。</p></li><li><p>定义：软件与开发者及其之间的关系，在同一环境下共同演化的社会-技术系统。</p></li><li><p>Example：</p><ul><li>Apple 垂直生态</li><li>NVIDIA CUDA 生态</li></ul></li></ul><h1 id="2-MeTax-生态全景图"><a href="#2-MeTax-生态全景图" class="headerlink" title="2. MeTax 生态全景图"></a>2. MeTax 生态全景图</h1><table><thead><tr><th align="center">层级</th><th align="center">内容</th><th align="center"></th><th align="center"></th></tr></thead><tbody><tr><td align="center">MXMACA Libs</td><td align="center">DNN</td><td align="center">ONNX RT</td><td align="center">Converter &amp; Quantizer</td></tr><tr><td align="center">MXMACA Languages</td><td align="center">MXMACA C++</td><td align="center">MXMACA Fortran</td><td align="center">MXMACA OpenMP</td></tr><tr><td align="center">MXMACA Drivers</td><td align="center">KMD</td><td align="center">UMD</td><td align="center">……</td></tr><tr><td align="center">Hardware</td><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><h1 id="3-GPU-软件生态的硬件环境"><a href="#3-GPU-软件生态的硬件环境" class="headerlink" title="3. GPU 软件生态的硬件环境"></a>3. GPU 软件生态的硬件环境</h1><ul><li><p>不同的 CPU、OS、软件栈，总共有成千上万种组合。</p></li><li><p>即使是和服务器厂商合作，也需要 2.5 - 6 个月</p><ul><li>板卡定制、大量的启动测试</li></ul></li></ul><h1 id="4-Setup-Step-By-Step"><a href="#4-Setup-Step-By-Step" class="headerlink" title="4. Setup Step By Step"></a>4. Setup Step By Step</h1><h2 id="4-1-Video-BIOS"><a href="#4-1-Video-BIOS" class="headerlink" title="4.1. Video BIOS"></a>4.1. Video BIOS</h2><ul><li><p>识别 Device ID</p></li><li><p>GPU 与 CPU 的 100MHz PCIe RC 对齐</p></li><li><p>注册最多六个基地址寄存器</p><ul><li>特权寄存器，用户态寄存器，Firmwave 空间寄存器，Device Memory Space……</li><li>形成一个树状结构，供 OS 管理</li></ul></li><li><p>硬件状态的初始化</p></li><li><p>加密保护</p></li></ul><p>挑战：在不同硬件环境下的健壮性</p><h2 id="贯通任务"><a href="#贯通任务" class="headerlink" title="贯通任务"></a>贯通任务</h2><p>证明某个功能被正确实现的测试任务。</p><h2 id="4-2-GPU-Kernel-Mode-Driver-KMD"><a href="#4-2-GPU-Kernel-Mode-Driver-KMD" class="headerlink" title="4.2. GPU Kernel Mode Driver (KMD)"></a>4.2. GPU Kernel Mode Driver (KMD)</h2><ul><li>也称之为 Direct Rendering Manager</li><li>进程管理、内存管理……</li><li>贯通任务：数据的拷贝</li></ul><h2 id="4-3-User-Mode-Driver-UMD"><a href="#4-3-User-Mode-Driver-UMD" class="headerlink" title="4.3. User Mode Driver (UMD)"></a>4.3. User Mode Driver (UMD)</h2><ul><li>C++ Runtime，C++ 数学函数，Device &#x2F; Context &#x2F; Stream 管理，API 支持，GPU Kernel 加载，JIT，测试……</li><li>贯通任务：Vector Add 的二进制 Kernel</li></ul><h2 id="4-4-Compiler"><a href="#4-4-Compiler" class="headerlink" title="4.4. Compiler"></a>4.4. Compiler</h2><ul><li>C++，Fortran，OpenAcc，OpenMP，OpenCL，HLSL（DirectX），GLSI（Vulkan）……</li><li>需要支持混合编译</li><li>贯通任务：VectorAdd</li><li>Challenge：GCC &#x2F; LLVM 的更新<ul><li>编译器的难点不在于开发而在于测试！</li><li>测试集的覆盖率是非常重要的</li></ul></li><li>因此，体系结构的支持也非常重要</li></ul><h2 id="4-5-数学库"><a href="#4-5-数学库" class="headerlink" title="4.5. 数学库"></a>4.5. 数学库</h2><ul><li>GEMM，Conv……</li><li>对于某个特定的 Kernel，可能有无数种 Implementation</li><li>常见的性能下降点<ul><li>Long Tail（长尾问题）：SM 跑满了，新的任务被迫等待</li><li>Bank Conflict</li></ul></li></ul><h2 id="4-6-AI-编译器（训练-推理框架）"><a href="#4-6-AI-编译器（训练-推理框架）" class="headerlink" title="4.6. AI 编译器（训练&#x2F;推理框架）"></a>4.6. AI 编译器（训练&#x2F;推理框架）</h2><ul><li>推理：基本只剩下 OpenAI Triton</li><li>训练：基本都是 PyTorch</li></ul><p>框架支持的精度准确很重要！除了不能太低，也不能太高</p><h1 id="4-7-其他生态"><a href="#4-7-其他生态" class="headerlink" title="4.7  其他生态"></a>4.7  其他生态</h1><ul><li>科学计算生态<ul><li>需要专业人士的参与</li></ul></li><li>大模型生态<ul><li>目前大模型四个月一次迭代，即使是 NVIDIA 的 TensoRT 的迭代也落后十个月左右</li><li>Triton 采用 JIT 模式，因此有明显的竞争优势。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>讲座笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>沐曦集成电路，GPU 生态</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【科研思考】辐射场中的显式表达和隐式表达</title>
    <link href="/2024/03/10/%E7%A7%91%E7%A0%94%E6%80%9D%E8%80%83/%E8%BE%90%E5%B0%84%E5%9C%BA%E4%B8%AD%E7%9A%84%E6%98%BE%E5%BC%8F%E8%A1%A8%E8%BE%BE%E5%92%8C%E9%9A%90%E5%BC%8F%E8%A1%A8%E8%BE%BE/"/>
    <url>/2024/03/10/%E7%A7%91%E7%A0%94%E6%80%9D%E8%80%83/%E8%BE%90%E5%B0%84%E5%9C%BA%E4%B8%AD%E7%9A%84%E6%98%BE%E5%BC%8F%E8%A1%A8%E8%BE%BE%E5%92%8C%E9%9A%90%E5%BC%8F%E8%A1%A8%E8%BE%BE/</url>
    
    <content type="html"><![CDATA[<h1 id="光场（Light-Field）和辐射场（Radiance-Field）"><a href="#光场（Light-Field）和辐射场（Radiance-Field）" class="headerlink" title="光场（Light Field）和辐射场（Radiance Field）"></a>光场（Light Field）和辐射场（Radiance Field）</h1><p>光场被定义为 <strong>“空间中光线集合的完备表示”</strong> 。采集并且显示光场，就能在视觉上重现真实世界。</p><ul><li>全光函数（Plenoptic Function）包含7个维度，是表示光场的数学模型。</li></ul><p>与之类似的概念还有“辐射场”。光场是以人眼为中心对光线集合进行描述，而辐射场则以发光表面为中心来描述光线集合。两者是等效的描述。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/LightField.png"></p><p>人眼位于三维世界中不同的位置进行观察所看到的图像不同，用 $(x, y, z)$ 表示人眼在三维空间中的位置坐标。光线可以从不同的角度进入人眼，用 $(\theta, \phi)$ 表示进入人眼光线的水平夹角和垂直夹角。每条光线具有不同的颜色和亮度，可以用光线的波长 $λ$ 来统一表示。进入人眼的光线随着时间 $t$ 的推移会发生变化。这七个参数可以描述三维世界中的光线，被称之为“全光函数”（Plenoptic Function）：<br>$$P(x, y, z, \theta, \phi, λ, t)$$</p><p>如果以物体的表面为中心来描述光线集合，我们就得到了辐射场。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/RadianceField.png"></p><p>比起光场来说，辐射场更适合用于描述“场景”。从某个角度来说，“场”的客观存在并不一定需要用人眼去观测。</p><p>在 NeRF（Neural Radiance Field）使用神经网络去拟合辐射场之后，就掀起了一阵使用辐射场来描述场景的热潮，其大体分为显式表达和隐式表达两种类型。</p><h1 id="Overview：Explicit-Representation-And-Implicit-Representation"><a href="#Overview：Explicit-Representation-And-Implicit-Representation" class="headerlink" title="Overview：Explicit Representation And Implicit Representation"></a>Overview：Explicit Representation And Implicit Representation</h1><p>接下来，我们讨论的主要是“辐射场”中的显式表示和隐式表示。在这里我们做一些简化的假设：</p><ol><li>去除时间轴。我们只讨论静态场景。动态场景暂时可以理解为沿时间方向的静态场景的叠加。</li><li>我们将光线的波长 $\lambda$ 分解为 $(R, G, B, \sigma)$ 四个参数，可以简单的表示某个点的颜色和密度。</li></ol><p>在这些假设下，我们来分析显式表达和隐式表达的区别。</p><h2 id="隐式表达"><a href="#隐式表达" class="headerlink" title="隐式表达"></a>隐式表达</h2><p>所谓隐式表达，就是不直接写出场景的表达式，而是通过某个函数去描述我们所需要的值。RF 系列作品中，最为纯粹的隐式表达就是 NeRF（Neural Radiance Field）。作为神经渲染的开山之作，NeRF 完全使用 MLP 对辐射场进行拟合。</p><p>值得注意的是，NeRF 的 Encoding 操作（包括 Positional Encoding，使用傅立叶编码和 SH Encoding，使用球谐编码）完全不需要参数（不是“超参数”），其本质只是把点的位置和方向信息从低频空间转化到高频空间，从而解决 MLP 不擅长学习高频细节的问题。（有研究表明，在使用梯度下降的时候，MLP 优先拟合场景中平滑的信息，随后才会“过拟合”到高频细节）。</p><p>隐式表达最大的问题是：慢。NeRF 使用了 8 层 256 宽度的 MLP，渲染一张图片需要数以秒记的时间。但其参数量也非常小，原因可能是 MLP 这种形式的拟合器是对数据的一种良好的压缩。</p><h2 id="显式表达"><a href="#显式表达" class="headerlink" title="显式表达"></a>显式表达</h2><p>显式表达直接存储空间中点的特征。从某种程度上来说，在辐射场里，显式表达约等于“基于点的表达”（Point-Based Representation）。例如：我们可以将空间划分为“网格”（Grid），或者直接存储“体素”（Voxel）。</p><p>在 RF 系列作品中，较为出名的、使用了显式表达的方法有：</p><ul><li>Point NeRF。存储空间中的显式点特征，但仍然使用 Ray Marching 去进行采样。采样之后，根据不同点云到采样点的距离进行获取特征并插值。</li><li>Plenoxels：用八叉树显示表示空间信息，并且对八叉树直接进行优化。</li><li>3D Gaussian Splatting：最为纯粹的显式表达，用各向异性的高斯点云拟合场景，使用 <strong>光栅化管线</strong> 进行投影操作，从而达到足够快的渲染速度。</li><li>Binary Opacity Grids 采样 Grid 编码场景，并 Baking 成 Mesh。</li></ul><p>显式表达的速度普遍快于隐式表达，但与之相应的代价是内存消耗的快速增长。而众所周知的是，内存在如今仍然是一个相当昂贵的资源。因此，纯粹采用显式表达未必是最优选择。</p><h1 id="显示表达和隐式表达的结合"><a href="#显示表达和隐式表达的结合" class="headerlink" title="显示表达和隐式表达的结合"></a>显示表达和隐式表达的结合</h1><p>事实上，大部分神经渲染工作并没有完全抛弃 MLP。例如 Instant NGP 虽然采用 Hash Table 编码场景，但仍然使用了小型 MLP 作为解码器。小型的 MLP 运算速度并不慢，又能良好的压缩数据，因此仍然是可以被考虑的选择。</p><h2 id="显式表达和隐式表达的分析"><a href="#显式表达和隐式表达的分析" class="headerlink" title="显式表达和隐式表达的分析"></a>显式表达和隐式表达的分析</h2><p>以 Synthetic 场景为例：</p><ul><li>NeRF：5MB，&lt;&#x3D;1 FPS</li><li>Instant NGP：28MB，30+FPS</li><li>Gaussian：100MB，100+FPS</li><li>Plenoxels：1G+，慢的不谈了</li></ul><p>……</p><p>可以看出，显式表示确实需要巨大的内存开销。因此，如何平衡：</p><ul><li>显式表达的高质量和快速渲染</li><li>隐式表达的内存开销</li></ul><p>就成为一个重要的课题。</p>]]></content>
    
    
    <categories>
      
      <category>科研思考</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Radiance Fields, Neural Rendering</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【数字IC设计】Testbench 编写基础</title>
    <link href="/2024/03/08/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5/Testbench%E7%BC%96%E5%86%99%E5%9F%BA%E7%A1%80/"/>
    <url>/2024/03/08/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5/Testbench%E7%BC%96%E5%86%99%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="How-to-write-Testbench"><a href="#How-to-write-Testbench" class="headerlink" title="How to write Testbench"></a>How to write Testbench</h1><p>本文将讲述如何使用Verilog 编写一个基础的<strong>测试脚本（testbench）</strong>。</p><p>在考虑一些关键概念之前，先来看看 Testbench 的架构是什么样的。架构包括建模时间、initial 块（initial block）和任务（task）。此文最后将以一个完整的 Testbench 编写作为示例。</p><p>在使用verilog设计数字电路时，设计人员通常还会创建一个testbench来仿真代码以确保其按预期设计运行。设计人员可以使用多种语言构建 Testbench，其中最流行的是 VHDL、Verilog 和 System verilog 。</p><p>System Verilog 在行业中被广泛应用，可能是用于测试的最常用语言，但本文仅介绍 verilog 中Testbench 设计的基本原则。</p><h1 id="1-Testbench-的架构"><a href="#1-Testbench-的架构" class="headerlink" title="1. Testbench 的架构"></a><strong>1. Testbench 的架构</strong></h1><p>Testbench由<strong>不可综合</strong>的 Verilog 代码组成，这些代码生成被测设计的输入并验证被测设计的输出是否正确（输出是否符合预期）。</p><p>下图展示了一个基本testbench的典型架构。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/TestbenchArch.png"></p><ul><li><strong>激励（stimulus block）</strong>是为 FPGA 设计生成的输入</li><li><strong>输出校验（output checker）</strong>检查被测模块的输出是否符合预期</li><li><strong>被测模块（design under test，DUT）</strong>即是编写的 Verilog 模块，Testbench 的主要设计目的就是对其进行验证，以确保在特定输入下，其输出均与预期一致</li></ul><p>对于较大规模的设计，激励和输出校验可以位于单独的文件中，也可以将所有这些不同的模块都包含在同一个文件中。</p><h1 id="2-例化被测模块"><a href="#2-例化被测模块" class="headerlink" title="2. 例化被测模块"></a><strong>2. 例化被测模块</strong></h1><p>编写 Testbench 的第一步是<strong>创建一个 Verilog 模块作为测试的顶层</strong>。</p><p>与的 Verilog module 不同，在这种情况下，设计人员要创建的是一个<strong>没有输入和输出的模块</strong>。这是因为设计人员希望 Testbench 模块是完全独立的（self contained）。</p><p>下面的代码片段展示了一个空模块的语法，这可以被用作testbench。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">module</span> &lt;module_name&gt; ();<br>    <span class="hljs-comment">// 在这里写testbench</span><br><span class="hljs-keyword">endmodule</span> : &lt;module_name&gt;<br></code></pre></td></tr></table></figure><p>创建了一个 Testbench 之后，必须例化被测设计，这可以将信号连接到被测设计以激励代码运行。</p><p>下面的代码片段展示了如何例化一个被测模块。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><br>&lt;module_name&gt; # (<br>  <span class="hljs-comment">// 例化参数</span><br>  .&lt;parameter_name&gt; (&lt;parameter_value&gt;)<br>)<br>&lt;instance_name&gt; (<br>  <span class="hljs-comment">// 连接端口信号</span><br>  .&lt;port_name&gt; (&lt;signal_name&gt;),<br>  .&lt;port_name&gt; (signal_name&gt;)<br>);<br></code></pre></td></tr></table></figure><p>完成此操作后，就可以开始将激励写入testbench。激励包括时钟信号和复位信号，以及创建发送到testbench的测试数据。</p><p>为此，需要使用一些尚未学过的 verilog 结构：<strong>initial块</strong>（initial block）、<strong>foever循环</strong>（foever loop）和<strong>时间控制</strong>（time consuming）语句。</p><h1 id="3-Verilog-中的建模时间（Modelling-Time）"><a href="#3-Verilog-中的建模时间（Modelling-Time）" class="headerlink" title="3. Verilog 中的建模时间（Modelling Time）"></a><strong>3. Verilog 中的建模时间（Modelling Time）</strong></h1><p>Testbench 代码和设计代码之间的主要区别是 Testbench 并不需要被综合成实际电路，为此可以使用时间控制语句这种特殊结构。事实上，这对于创建测试激励至关重要。</p><p>在 Verilog 中有一个可用的结构——它能够对仿真进行延时。在 verilog 中使用 <strong>#</strong> 字符后跟多个时间单位来模拟延时。</p><p>例如，下面的 Verilog 代码展示使用延时运算符等待 10 个时间单位。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs verilog">#<span class="hljs-number">10</span><br></code></pre></td></tr></table></figure><p>这里要注意的是代码末尾并<strong>没有分号</strong>。</p><p>将延时语句写在与赋值相同的代码行中也很常见，这可以有效地行使调度功能，将信号的变化安排在延迟时间之后。下面的代码片段是此种情况的一个示例。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs verilog">#<span class="hljs-number">10</span> a = <span class="hljs-number">1&#x27;b1</span>;    <span class="hljs-comment">// 在10个时间单位后，a 将被赋值为1</span><br></code></pre></td></tr></table></figure><h2 id="3-1-时间单位（Timescale-）编译指令"><a href="#3-1-时间单位（Timescale-）编译指令" class="headerlink" title="3.1. 时间单位（Timescale ）编译指令"></a><strong>3.1. 时间单位（Timescale ）编译指令</strong></h2><p>在上一节已经讨论了十个时间单位的延时用法，但在设计人员真正定义所使用的时间单位之前，这样的讨论是毫无意义的。</p><p>为了指定在仿真期间所使用的时间单位，需要使用指定<strong>时间单位</strong>和<strong>时间精度</strong>（分辨率）的 Verilog 编译器指令。这只需要在 Testbench 中运行该指令一次，而且应在模块外完成。</p><p>下面的代码片段展示用来在 Verilog 中指定时间单位和精度的编译指令。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-meta">`<span class="hljs-keyword">timescale</span> &lt;unit_time&gt; / &lt;resolution&gt;</span><br></code></pre></td></tr></table></figure><p><strong><code>&lt;unit_time&gt;</code></strong> 指定时间的单位，**<code>&lt;resolution&gt;</code>** 则指定时间精度。</p><p><code>&lt;resolution&gt;</code> 很重要，因为设计人员可以使用小数来指定 verilog 代码中的延时。例如，如果设计人员想要 10.5ns 的延迟，就可以简单地写为 <strong>#10.5</strong>。因此，编译指令中的 <code>&lt;resolution&gt;</code> 决定了可以实现最小时间的步长（即精度）。</p><p>此编译指令中的两个参数都采用时间类型，例如 1ps 或 1ns。</p><h1 id="4-Verilog-initial-block（初始块）"><a href="#4-Verilog-initial-block（初始块）" class="headerlink" title="4. Verilog initial block（初始块）"></a><strong>4. Verilog initial block（初始块）</strong></h1><p>在<strong>initial 块</strong>中编写的任何代码都会在仿真开始时<strong>执行一次且仅执行一次</strong>。</p><p>下面的 Verilog 代码展示了initial 块的一般语法。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>  <span class="hljs-comment">// 这里写代码</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>与 always 块不同，在 initial 块中编写的 verilog 代码几乎是<strong>不可综合的</strong>，因此其几乎只被用于仿真。但是，在verilog RTL 中<strong>也可以使用 initial 块来初始化信号（几乎很少用）</strong>。</p><p>为了更好地理解如何使用 initial 块在 Verilog 中编写激励，请来看一个基本示例：</p><p>假设现在想要测试一个基本的两输入与门，为此需要编写代码来生成所有可能的四种输入。此外还需要使用延时运算符以在生成不同的输入之间延迟一段时间。这很重要，因为这可以允许信号有时间来传播。</p><p>下面的 Verilog 代码展示了在 initial 块中编写此测试的方法。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>  <span class="hljs-comment">// 每隔10个时间单位就生成一个输入</span><br>  and_in = <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">00</span>;<br>  #<span class="hljs-number">10</span> and_in = <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">01</span>;<br>  #<span class="hljs-number">10</span> and_in = <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">10</span>;<br>  #<span class="hljs-number">10</span> and_in = <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">11</span>;<br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><p>值得注意的是，这种写法的时延是相对时延，如果想使用相对 0 时刻的绝对时延，可以使用非阻塞性赋值：</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>  <span class="hljs-comment">// 每隔 10 个时间单位就生成一个输入</span><br>  and_in &lt;= <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">00</span>;<br>  and_in &lt;= #<span class="hljs-number">10</span> <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">01</span>;<br>  and_in &lt;= #<span class="hljs-number">30</span> <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">10</span>;<br>  and_in &lt;= #<span class="hljs-number">50</span> <span class="hljs-number">2</span>b&#x27;<span class="hljs-number">11</span>;<br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><h1 id="5-Verilog-Foever-循环（Loop）"><a href="#5-Verilog-Foever-循环（Loop）" class="headerlink" title="5. Verilog Foever 循环（Loop）"></a><strong>5. Verilog Foever 循环（Loop）</strong></h1><p>在 Verilog Testbench中可以使用一种重要的循环类型——<strong>forever</strong>循环。</p><p>使用这个构造时，实际上是创建了一个无限的循环——这意味着创建了一段在仿真过程中将永远运行的代码。</p><p>下面的 verilog 代码展示了用来编写foever循环的一般语法。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">forever</span> <span class="hljs-keyword">begin</span><br>  <span class="hljs-comment">// our code goes here</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>当用其他编程语言编写代码时，无限循环一般被视为应极力避免的严重错误。但是，verilog 与其他编程语言不同，编写 verilog 代码是在描述硬件而不是在编写软件。</p><p>因此，<strong>至少有一种情况是可以使用无限循环的——时钟信号</strong>。为此需要一种定期连续反转信号的方法，foever 循环与此相当契合。</p><p>下面的 verilog 代码展示了如何使用 foever 循环在 testbench 中生成一个时钟。需要注意的是，所编写的任何循环都必须包含在过程块（procedural block）中或生成块（generate块）中。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>   clk = <span class="hljs-number">1&#x27;b0</span>;<br>   <span class="hljs-keyword">forever</span> <span class="hljs-keyword">begin</span><br>     #<span class="hljs-number">1</span> clk = ~clk;<br>   <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><p>当然，重复序列也可以使用 always 语句产生。</p><h1 id="6-Verilog-系统任务（System-Tasks）"><a href="#6-Verilog-系统任务（System-Tasks）" class="headerlink" title="6. Verilog 系统任务（System Tasks）"></a><strong>6. Verilog 系统任务（System Tasks）</strong></h1><p>在 verilog 中编写testbench时，有一些内置的任务和函数可以提供帮助。这些被统称为<strong>系统任务或系统函数</strong>，它们很容易被识别—-总是以<strong>美元符号（$）</strong>开头。</p><p>虽然有很多这样的系统任务可用，但是这三个是最常用的 ：**<code>$display</code>、<code>$monitor</code> 和 <code>$time</code>**。</p><h2 id="6-1-display"><a href="#6-1-display" class="headerlink" title="6.1. $display"></a><strong>6.1. <code>$display</code></strong></h2><p><code>$display</code> 是 verilog 中最常用的系统任务之一。设计人员可以使用它来输出一条消息，该消息在仿真时将会显示在控制台上。</p><p><code>$display</code> 的使用方式与C语言中的 <code>printf</code> 函数非常类似，这意味着设计人员可以轻松地在 Testbench 中创建文本语句，并使用它们来显示有关仿真状态的信息。</p><p>设计人员还可以在字符串中使用特殊字符 (%) 来显示设计中的信号。这样做时，还必须使用一个格式字母来决定以何种格式显示变量。最常用的格式是 <strong>b（二进制）、d（十进制）和 h（十六进制）</strong>。设计人员还可以在这个格式代码前面加上一个数字来确定要显示的位数。</p><p>下面的 verilog 代码展示了 $display 系统任务的一般语法。此代码片段还包括一个示例用例。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-comment">// 一般语法</span><br><span class="hljs-built_in">$display</span>(&lt;string_to_display&gt;, &lt;variables_to_display);<br><br><span class="hljs-comment">// 例子：分别用2进制、16进制和10进制来打印x的值</span><br><span class="hljs-built_in">$display</span>(<span class="hljs-string">&quot;x (bin) = %b, x (hex) = %h, x (decimal) = %d&quot;</span>, x, x, x);<br><br></code></pre></td></tr></table></figure><p>设计人员可以在 <code>$display</code> 系统任务中使用的不同格式的完整列表如下所示。</p><table><thead><tr><th>格式代码</th><th>描述</th></tr></thead><tbody><tr><td>%b 或 %B</td><td>显示为二进制</td></tr><tr><td>%d 或 %D</td><td>显示为十进制</td></tr><tr><td>%h 或 %H</td><td>显示为十六进制</td></tr><tr><td>%o 或 %O</td><td>显示为八进制格式</td></tr><tr><td>%c 或 %C</td><td>显示为 ASCII 字符</td></tr><tr><td>%m 或 %M</td><td>显示模块的层级名称</td></tr><tr><td>%s 或 %S</td><td>显示为字符串</td></tr><tr><td>%t 或 %T</td><td>显示为时间</td></tr></tbody></table><h2 id="6-2-monitor"><a href="#6-2-monitor" class="headerlink" title="6.2. $monitor"></a><strong>6.2. <code>$monitor</code></strong></h2><p><code>$monitor</code> 函数与 <code>$display</code> 函数非常相似，但它一般被用来监视 Testbench 的信号值，这些信号中的任何一个改变状态，都会在终端打印一条消息。</p><p>所有的系统任务在使用时都会被综合工具忽略，因此甚至可以在 Verilog RTL 代码中使用 <code>$monitor</code> 语句，尽管这并不常见。</p><p>此系统任务的一般语法显示在下面的代码片段中。此代码片段还包括一个示例用例。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-comment">//一般语法</span><br>$ monitor(&lt;message_to_display&gt;, &lt;variables_to_display&gt;);<br><br><span class="hljs-comment">//例子：监控信号in_a和in_b的值。其中任何一个发生变化都会立即在终端打印出两个信号的值</span><br>$ monitor(<span class="hljs-string">&quot;in_a=%b, in_b=%b\n&quot;</span>, in_a, in_b);<br><br></code></pre></td></tr></table></figure><h2 id="6-3-time"><a href="#6-3-time" class="headerlink" title="6.3. $time"></a><strong>6.3. <code>$time</code></strong></h2><p>在 Testbench 中常用的最后一个系统任务是 <code>$time</code> 。这个系统任务可以用来获取当前的仿真时间。</p><p>在 Testbench 中通常将 <code>$time</code> 与 <code>$display</code> 或 <code>$monitor</code> 一起使用，以便在打印的消息中显示具体仿真时间。</p><p>下面的 verilog 代码展示了如何一起使用 <code>$time</code> 和 <code>$display</code> 来打印信息。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-built_in">$display</span>(<span class="hljs-string">&quot;Current simulation time = %t&quot;</span>, <span class="hljs-built_in">$time</span>);    <span class="hljs-comment">//打印当前仿真时间</span><br></code></pre></td></tr></table></figure><h2 id="6-4-readmemb"><a href="#6-4-readmemb" class="headerlink" title="6.4. $readmemb"></a>6.4. <code>$readmemb</code></h2><p>系统任务 <code>$readmemb</code> 从文件中将向量读入到存储器 VMem 中。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">reg</span> [<span class="hljs-number">1</span>:BITS] VMem[<span class="hljs-number">1</span>:WORDS];<br><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br><span class="hljs-built_in">$readmemb</span> (<span class="hljs-string">&quot;Test.vec&quot;</span>, VMem);<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure><h2 id="6-5-向文本中写入向量-fdisplay-fmonitor-fstrobe"><a href="#6-5-向文本中写入向量-fdisplay-fmonitor-fstrobe" class="headerlink" title="6.5. 向文本中写入向量: $fdisplay , $fmonitor , $fstrobe"></a>6.5. 向文本中写入向量: <code>$fdisplay</code> , <code>$fmonitor</code> , <code>$fstrobe</code></h2><p>信号值可以通过这些系统任务输出到文件中，这样可以避免通过复杂的重定向操作输出结果。</p><h1 id="7-Verilog-testbench示例"><a href="#7-Verilog-testbench示例" class="headerlink" title="7. Verilog testbench示例"></a><strong>7. Verilog testbench示例</strong></h1><p>接下来将为一个非常简单的电路构建一个 Testbench 以检查其功能的正确性。</p><p>下面显示的电路是将用于此示例的电路，由一个简单的两输入与门以及一个寄存器组成。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Example_Module.png"></p><h2 id="7-1-创建一个-Testbench-模块"><a href="#7-1-创建一个-Testbench-模块" class="headerlink" title="7.1. 创建一个 Testbench 模块"></a><strong>7.1. 创建一个 Testbench 模块</strong></h2><p>在 <strong>Testbench</strong> 中做的第一件事就是声明一个空模块来写入代码。</p><p>下面的代码片段展示了此 <strong>Testbench</strong> 的模块声明。请注意，最好让被测试设计的名称与 Testbench 的名称<strong>保持相似</strong>。一般可以简单地将 <strong><code>_tb</code> 或 <code>_test</code></strong> 附加到被测设计名称的末尾。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">module</span> example_tb ();<br>  <span class="hljs-comment">//在这里写测试代码</span><br><span class="hljs-keyword">endmodule</span> : example_tb<br><br></code></pre></td></tr></table></figure><h2 id="7-2-例化被测模块"><a href="#7-2-例化被测模块" class="headerlink" title="7.2. 例化被测模块"></a><strong>7.2. 例化被测模块</strong></h2><p>现在只有一个空白的 Testbench 模块，接下来需要例化要测试的设计模块。</p><p>下面的代码片段展示了如何例化被测模块，假设信号 <code>clk</code>、<code>in_a</code>、<code>in_b</code> 和 <code>out_q</code> 之前就已声明。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs verilog">example_design dut (<br>    <span class="hljs-variable">.clock</span> (clk),<br>    <span class="hljs-variable">.reset</span> (reset),<br>    <span class="hljs-variable">.a</span>     (in_a),<br>    <span class="hljs-variable">.b</span>     (in_b),<br>    <span class="hljs-variable">.q</span>     (out_q)<br>);<br><br></code></pre></td></tr></table></figure><h2 id="7-3-生成时钟和复位信号"><a href="#7-3-生成时钟和复位信号" class="headerlink" title="7.3. 生成时钟和复位信号"></a><strong>7.3. 生成时钟和复位信号</strong></h2><p>接下来要做的是在 Testbench 中生成一个时钟和复位信号。可以在 initial 块中为时钟和复位信号编写代码，然后使用延时运算符来实现信号状态的变化。</p><p>对于时钟信号，可以使用 <code>forever</code> 关键字在仿真期间持续运行时钟信号。使用此语法将每 1 ns 进行一次反转，从而实现 500MHz 的时钟频率——选择此频率纯粹是为了实现快速仿真，实际上FPGA 中的 500MHz 时钟速率很难实现，所以 Testbench 的时钟频率应尽量与硬件时钟频率匹配。</p><p>下面的 verilog 代码展示了如何在 Testbench 中生成时钟和复位信号。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-comment">// 生成时钟信号</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>    clk = <span class="hljs-number">1&#x27;b0</span>;<br>    <span class="hljs-keyword">forever</span> #<span class="hljs-number">1</span> clk = ~clk;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">// 生成复位信号</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>   reset = <span class="hljs-number">1&#x27;b1</span>;<br>    #<span class="hljs-number">10</span><br>   reset = <span class="hljs-number">1&#x27;b0</span>;<br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><h3 id="7-4、编写测试激励信号"><a href="#7-4、编写测试激励信号" class="headerlink" title="7.4、编写测试激励信号"></a><strong>7.4、编写测试激励信号</strong></h3><p>最后一部分是编写测试激励。为了测试被测电路，需要依次生成四种可能输入中的每一种，然后需要等待一小段时间，让信号通过代码块传播。</p><p>为此，将为输入赋值，然后使用延时语句来通过 FPGA 进行传播。如果还想监控输入和输出的值，可以使用 <code>$monitor</code> 这个系统任务来完成。</p><p>下面的代码片段展示了相关代码。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>    <span class="hljs-built_in">$monitor</span>(<span class="hljs-string">&quot;time=%3d, in_a=%b, in_b=%b, q=%2b \n&quot;</span>,<br>              <span class="hljs-built_in">$time</span>, in_a, in_b, q);<br><br>    in_a = <span class="hljs-number">1&#x27;b0</span>;in_b = <span class="hljs-number">1&#x27;b0</span>;<br>    #<span class="hljs-number">20</span> in_a = <span class="hljs-number">1&#x27;b1</span>;<br>    #<span class="hljs-number">20</span> in_a = <span class="hljs-number">1&#x27;b0</span>;in_b = <span class="hljs-number">1&#x27;b1</span>;<br>    #<span class="hljs-number">20</span> in_a = <span class="hljs-number">1&#x27;b1</span>;<br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><h2 id="7-5-完整示例代码"><a href="#7-5-完整示例代码" class="headerlink" title="7.5. 完整示例代码"></a><strong>7.5. 完整示例代码</strong></h2><p>下面的 verilog 代码展示了完整的 Testbench 示例。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-meta">`<span class="hljs-keyword">timescale</span> 1ns / 1ps    </span><span class="hljs-comment">//时间单位1ns，精度1ps</span><br><br><span class="hljs-keyword">module</span> example_tb ();<br><br><span class="hljs-comment">//声明时钟和复位信号</span><br><span class="hljs-keyword">reg</span> clk;<br><span class="hljs-keyword">reg</span> reset;<br><br><span class="hljs-comment">//输入和输出信号</span><br><span class="hljs-keyword">reg</span> in_a;<br><span class="hljs-keyword">reg</span> in_b;<br><span class="hljs-keyword">wire</span> out_q;<br><br><span class="hljs-comment">//例化被测模块</span><br>example_design dut (<br>  <span class="hljs-variable">.clock</span> (clk),<br>  <span class="hljs-variable">.reset</span> (reset),<br>  <span class="hljs-variable">.a</span>     (in_a),<br>  <span class="hljs-variable">.b</span>     (in_b),<br>  <span class="hljs-variable">.q</span>     (out_q)<br>);<br><br><span class="hljs-comment">//生成时钟信号</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>  clk = <span class="hljs-number">1&#x27;b0</span>;<br>  <span class="hljs-keyword">forever</span> #<span class="hljs-number">1</span> clk = ~clk;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">//生成复位信号</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br> reset = <span class="hljs-number">1&#x27;b1</span>;<br> #<span class="hljs-number">10</span> reset = <span class="hljs-number">1&#x27;b0</span>;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">//生成测试激励信号</span><br>  <span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>  <span class="hljs-built_in">$monitor</span>(<span class="hljs-string">&quot;time=%3d, in_a=%b, in_b=%b, q=%2b \n&quot;</span>,<br>            <span class="hljs-built_in">$time</span>, in_a, in_b, q);<br><br>  in_a = <span class="hljs-number">1&#x27;b0</span>;<br>  in_b = <span class="hljs-number">1&#x27;b0</span>;<br>  #<span class="hljs-number">20</span><br>  in_a = <span class="hljs-number">1&#x27;b1</span>;<br>  #<span class="hljs-number">20</span><br>  in_a = <span class="hljs-number">1&#x27;b0</span>;<br>  in_b = <span class="hljs-number">1&#x27;b1</span>;<br>  #<span class="hljs-number">20</span><br>  in_a = <span class="hljs-number">1&#x27;b1</span>;<br>  <span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">endmodule</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数字电路设计与实践</category>
      
      <category>工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数字电路, 仿真</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【数字IC设计】使用 VCS 与 Verdi 的前端仿真流程</title>
    <link href="/2024/03/02/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5/%E5%89%8D%E7%AB%AF%E4%BB%BF%E7%9C%9F/"/>
    <url>/2024/03/02/%E6%95%B0%E5%AD%97%E7%94%B5%E8%B7%AF%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E8%B7%B5/%E5%89%8D%E7%AB%AF%E4%BB%BF%E7%9C%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="前端仿真"><a href="#前端仿真" class="headerlink" title="前端仿真"></a>前端仿真</h1><p>首先，本地新建项目一般需要一个工程文件夹，其文件结构大致是：</p><p>Design（RTL，filelist），Flow（Syn，Lint等等），VRF（Verify）（tb，tc等等）</p><h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><p>在这里，我们使用 VCS 和 Verdi 进行前端仿真和波形查看。</p><p>首先，我们需要保证环境变量里存在 <code>vcs</code> 和 <code>verdi</code> 。例如，大部分环境下，可以使用 <code>module load</code> 来进行环境变量的加载。</p><h1 id="文件结构"><a href="#文件结构" class="headerlink" title="文件结构"></a>文件结构</h1><p>这里以我们实现一个 Adder 为例子</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">.<br>├── Design<br>│   ├── Filelist<br>│   │   └── filelist<br>│   └── RTL<br>│       └── Adder.v<br>├── Flow<br>├── Makefile<br>└── Verification<br>    └── TestBench<br>        └── tb_0.v<br></code></pre></td></tr></table></figure><ul><li>Design：设计文件夹<ul><li>Filelist：用于向 VCS，Verdi 等</li><li>RTL：工程文件</li></ul></li><li>Flow：执行流程，包括 Syn，Lint 等子文件夹</li><li>Verification：用于验证的文件夹<ul><li>Testbench</li><li>Testcase</li></ul></li><li>Makefile：脚本</li></ul><h1 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h1><h2 id="Example-1：Adder"><a href="#Example-1：Adder" class="headerlink" title="Example 1：Adder"></a>Example 1：Adder</h2><p>首先以一个简单的加法器为例子。这里的 Testbench 中的时钟纯属于摆设。</p><h3 id="Adder-v"><a href="#Adder-v" class="headerlink" title="Adder.v"></a>Adder.v</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-keyword">module</span> Adder( <br>    <span class="hljs-keyword">input</span> a, <br>    <span class="hljs-keyword">input</span> b, <br>    <span class="hljs-keyword">output</span> out <br>);<br>    <span class="hljs-keyword">assign</span> out = a + b;<br><span class="hljs-keyword">endmodule</span><br></code></pre></td></tr></table></figure><h3 id="filelist"><a href="#filelist" class="headerlink" title="filelist"></a>filelist</h3><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">/home/heyx1/Demo/Design/RTL/Adder.v<br><br>/home/heyx1/Demo/Verification/TestBench/tb_0.v<br></code></pre></td></tr></table></figure><h3 id="tb-0-v"><a href="#tb-0-v" class="headerlink" title="tb_0.v"></a>tb_0.v</h3><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-meta">`<span class="hljs-keyword">timescale</span> 1ns / 1ps    </span><span class="hljs-comment">//时间单位1ns，精度1ps</span><br><br><span class="hljs-keyword">module</span> tb_0 ();<br><span class="hljs-comment">// Clock and reset</span><br><span class="hljs-keyword">reg</span> clk;<br><span class="hljs-keyword">reg</span> reset;<br><br><span class="hljs-comment">// Input and Output signal</span><br><span class="hljs-keyword">reg</span> in_a;<br><span class="hljs-keyword">reg</span> in_b;<br><span class="hljs-keyword">wire</span> out_q;<br><br><span class="hljs-comment">// 例化被测模块</span><br>Adder adder (<br><span class="hljs-variable">.a</span>     (in_a),<br><span class="hljs-variable">.b</span>     (in_b),<br><span class="hljs-variable">.out</span>     (out_q)<br>);<br><br><span class="hljs-comment">// Generate Clock</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>clk = <span class="hljs-number">1&#x27;b0</span>;<br><span class="hljs-keyword">forever</span> #<span class="hljs-number">1</span> clk = ~clk;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">// Generate Reset</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>reset = <span class="hljs-number">1&#x27;b1</span>;<br>#<span class="hljs-number">10</span> reset = <span class="hljs-number">1&#x27;b0</span>;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-comment">// Generate signal</span><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br><span class="hljs-built_in">$monitor</span>(<span class="hljs-string">&quot;time=%3d, in_a=%b, in_b=%b, q=%2b \n&quot;</span>,<br><span class="hljs-built_in">$time</span>, in_a, in_b, out_q);<br><br>in_a = <span class="hljs-number">1&#x27;b0</span>;<br>in_b = <span class="hljs-number">1&#x27;b0</span>;<br>#<span class="hljs-number">20</span><br>in_a = <span class="hljs-number">1&#x27;b1</span>;<br>#<span class="hljs-number">20</span><br>in_a = <span class="hljs-number">1&#x27;b0</span>;<br>in_b = <span class="hljs-number">1&#x27;b1</span>;<br>#<span class="hljs-number">20</span><br>in_a = <span class="hljs-number">1&#x27;b1</span>;<br><br><br><span class="hljs-built_in">$finish</span>;<br><span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">initial</span> <span class="hljs-keyword">begin</span><br>$fsdbDumpfile(<span class="hljs-string">&quot;tb_0.fsdb&quot;</span>);<br>$fsdbDumpvars(<span class="hljs-number">0</span>, <span class="hljs-string">&quot;tb_0&quot;</span>);<br>#<span class="hljs-number">10000</span><br><br><span class="hljs-built_in">$finish</span>;<br><span class="hljs-keyword">end</span><br>  <br><span class="hljs-keyword">endmodule</span><br></code></pre></td></tr></table></figure><h2 id="Makefile"><a href="#Makefile" class="headerlink" title="Makefile"></a>Makefile</h2><p>我们把常见操作编写到脚本里，这样可以方便的进行操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash">TC=OurTC<br>TB=tb_0<br><br>initialize:<br>module load synopsys/vcs/R-2020.12-SP<br>module load synopsys/verdi/R-2020.12-SP2<br>compile:<br>@<span class="hljs-built_in">echo</span> $(TC)<br><span class="hljs-built_in">mkdir</span> <span class="hljs-built_in">log</span><br>vcs-f &#123;BASE_PATH_TO_PROJECT&#125;/Design/Filelist/filelist \<br>-l ./log/test.log \<br>-full64 \<br>-debug_acc+pp+dmptf \<br>-debug_region+cell+encrypt \<br>-debug_access \<br>-sverilog \<br>-top $(TB) \<br>-R \<br>-fgp \<br>-V -Mupdate -full64  -sverilog +v2k +notimingcheck +no_tchk_msg \<br>+lint=all \<br>-timescale=1ns/1ps -notice \<br>-cm line+cond+tgl+fsm+branch -cm_dir ../cov/$(TC).vdb \<br><br>verdi:<br>verdi \<br>-sv \<br>-f &#123;BASE_PATH_TO_PROJECT&#125;/Demo/Design/Filelist/filelist \<br>-ssf $(TB).fsdb &amp; <br><br>clear:<br><span class="hljs-built_in">rm</span> -rf verdiLog<br><span class="hljs-built_in">rm</span> -rf simv.daidir<br><span class="hljs-built_in">rm</span> -rf <span class="hljs-built_in">log</span><br><span class="hljs-built_in">rm</span> -rf csrc<br><span class="hljs-built_in">rm</span> .fsm.sch.verilog.xml<br><span class="hljs-built_in">rm</span> novas_dump.log<br><span class="hljs-built_in">rm</span> cm.log<br><span class="hljs-built_in">rm</span> simv<br><span class="hljs-built_in">rm</span> ucli.key<br><br>clear_all:<br>make clear<br><span class="hljs-built_in">rm</span> tb_0.fsdb<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>数字电路设计与实践</category>
      
      <category>工程</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数字电路, 仿真, VCS, Verdi,</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【环境配置】CUDA环境配置</title>
    <link href="/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/CUDA/"/>
    <url>/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/CUDA/</url>
    
    <content type="html"><![CDATA[<h1 id="前置知识"><a href="#前置知识" class="headerlink" title="前置知识"></a>前置知识</h1><h2 id="什么是-CUDA？"><a href="#什么是-CUDA？" class="headerlink" title="什么是 CUDA？"></a>什么是 CUDA？</h2><p>CUDA 的全称是<strong>统一计算设备架构</strong>（Compute Unified Device Architecture, CUDA），是由 NVIDIA 推出的通用并行计算架构。</p><p>在当前最热门的领域：人工智能里，由于深度学习的热门程度独占鳌头，而深度学习的模型结构又非常适合 GPU 上的并行计算架构，因此 CUDA 也成为了深度学习的必备环境。</p><h2 id="CUDA-Driver-和-CUDA-Runtime"><a href="#CUDA-Driver-和-CUDA-Runtime" class="headerlink" title="CUDA Driver 和 CUDA Runtime"></a>CUDA Driver 和 CUDA Runtime</h2><h3 id="CUDA-Driver"><a href="#CUDA-Driver" class="headerlink" title="CUDA Driver"></a>CUDA Driver</h3><p>CUDA Driver 是 CUDA 的<strong>驱动</strong>，有点类似 GPU 的“操作系统”，一个硬件设备上只会有一个版本。</p><p>我们可以通过 <code>nvidia-smi</code> 命令查看当前系统中的 CUDA Driver 版本。</p><h3 id="CUDA-Runtime"><a href="#CUDA-Runtime" class="headerlink" title="CUDA Runtime"></a>CUDA Runtime</h3><p>CUDA Runtime 是 CUDA 的<strong>运行时库</strong>，是一个软件库，用于在程序中调用 GPU 的计算资源。一个系统中可以有很多个 CUDA Runtime，不同的程序可能会使用不同的 CUDA Runtime。</p><p>我们可以通过 <code>nvcc --version</code> 命令查看当前系统中的 CUDA Runtime 版本。通常，CUDA Runtime 的路径是 <code>/usr/local/cuda-xxx</code>。</p><h1 id="CUDA-On-Linux（以-Ubuntu-为例）"><a href="#CUDA-On-Linux（以-Ubuntu-为例）" class="headerlink" title="CUDA On Linux（以 Ubuntu 为例）"></a>CUDA On Linux（以 Ubuntu 为例）</h1><p>首先，进入 NVIDIA 的官网，进入对应的下载页面：<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240226122713.png"></p><p>你需要依次选择这些项目，以便获得合适的安装包。</p><p>通常，最后一项推荐选择 <code>runfile</code>，这是一个自解压文件，你可以通过命令行来安装。</p><h1 id="CUDA-On-Windows"><a href="#CUDA-On-Windows" class="headerlink" title="CUDA On Windows"></a>CUDA On Windows</h1><p>Windows 下的 CUDA 安装相对来说更加简单，只需要下载对应的安装包，然后一路下一步即可。</p>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【环境配置】C 与 C++ 的编译环境</title>
    <link href="/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/C_And_CPP/"/>
    <url>/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/C_And_CPP/</url>
    
    <content type="html"><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>环境配置确实是一个非常痛苦的问题，经常能遇到让人感觉摸不着头脑的问题。</p><p>关于比较完整的，适合上课使用的 C&amp;C++ 环境配置，可以参考视频 <a href="https://www.bilibili.com/video/BV1id4y1n7Kw/?spm_id_from=333.337.search-card.all.click&vd_source=3bbc7395fdcea11b679cb15cd7812635">GKxx: C&#x2F;C++环境配置</a>。这里对其内容做一个梳理和总结，方便懒得看视频的同学。</p><h1 id="常用术语"><a href="#常用术语" class="headerlink" title="常用术语"></a>常用术语</h1><ul><li>编辑器：用于编辑代码文本的工具。<ul><li>On Windows：记事本，VS Code……</li><li>On Linux：Vim，Emacs……</li></ul></li><li>编译器：用于<strong>将源代码转换为可执行文件（“计算机能看懂的代码”）</strong>的工具。<ul><li>On Windows：MSVC</li><li>On Linux：GCC, Clang</li></ul></li><li>IDE（Integrated Development Environment）：集成开发环境，包含编辑器、编译器、调试器等工具。<ul><li>On Windows：Visual Studio……</li><li>On Linux：CLion, Eclipse……</li></ul></li></ul><h1 id="Compiler-On-Linux（以-Ubuntu-为例）"><a href="#Compiler-On-Linux（以-Ubuntu-为例）" class="headerlink" title="Compiler On Linux（以 Ubuntu 为例）"></a>Compiler On Linux（以 Ubuntu 为例）</h1><p>Linux 上我们一般使用 gcc 编译器，它是 GNU Compiler Collection 的缩写，是一个由 GNU 开发的编程语言编译器。</p><h2 id="默认版本的安装"><a href="#默认版本的安装" class="headerlink" title="默认版本的安装"></a>默认版本的安装</h2><p>以 Ubuntu 为例，我们通常直接使用系统自带的 <code>apt</code> 工具来安装软件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt update <span class="hljs-comment"># 更新软件源。</span><br><span class="hljs-built_in">sudo</span> apt install build-essential <span class="hljs-comment"># Build-essential 是一个包，包含了编译器、链接器等工具。</span><br></code></pre></td></tr></table></figure><p>然后我们可以查看安装是否成功：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">gcc --version<br></code></pre></td></tr></table></figure><p>如果安装成功，会显示类似如下的信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0<br>Copyright (C) 2021 Free Software Foundation, Inc.<br>This is free software; see the <span class="hljs-built_in">source</span> <span class="hljs-keyword">for</span> copying conditions.  There is NO<br>warranty; not even <span class="hljs-keyword">for</span> MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.<br></code></pre></td></tr></table></figure><h2 id="gcc-11-的安装"><a href="#gcc-11-的安装" class="headerlink" title="gcc-11 的安装"></a>gcc-11 的安装</h2><p>我们可以通过添加软件源的方式来安装 gcc-11：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-add-repository ppa:ubuntu-toolchain-r/test<br><span class="hljs-built_in">sudo</span> apt install gcc-11 g++-11<br></code></pre></td></tr></table></figure><h1 id="Compiler-On-Windows（MingW）"><a href="#Compiler-On-Windows（MingW）" class="headerlink" title="Compiler On Windows（MingW）"></a>Compiler On Windows（MingW）</h1><p>Windows 不能直接使用 gcc，但我们可以安装 MinGW（<strong>Min</strong>imalist <strong>G</strong>NU for <strong>W</strong>indows）来使用 gcc。</p><p>事实上，由于 MinGW 已经很久没有更新了，所以我们一般使用 MinGW-w64，它是 MinGW 的一个分支，支持 64 位系统。</p><h2 id="下载与解压"><a href="#下载与解压" class="headerlink" title="下载与解压"></a>下载与解压</h2><p>我们在 <a href="https://winlibs.com/">Winlibs</a> 中进行下载：</p><ul><li>在 <strong>Download</strong> 下选择 <strong>UCRT runtime</strong> 中标有 <strong>(LATEST)</strong> 的那个 release 里的 Win64 Zip archive（建议选带有 LLVM&#x2F;Clang 的）</li><li><a href="https://github.com/brechtsanders/winlibs_mingw/releases/download/12.2.0-15.0.7-10.0.0-ucrt-r4/winlibs-x86_64-posix-seh-gcc-12.2.0-llvm-15.0.7-mingw-w64ucrt-10.0.0-r4.zip">GCC 12.2.0 + Clang 15.0.7 + MinGW-w64 10.0.0 (UCRT) release 64, Win64 Zip</a></li><li>解压后将 <code>mingw64</code> 这个文件夹放在 C 盘或 D 盘，<strong>路径最好简单一点，不要给自己找麻烦</strong>，例如 <code>C:\mingw64</code> 或者 <code>D:\mingw64</code>。</li></ul><h2 id="环境变量的配置"><a href="#环境变量的配置" class="headerlink" title="环境变量的配置"></a>环境变量的配置</h2><ul><li><p>按 <code>Win</code> 键，输入 <code>env</code>（或者在 <code>此电脑</code> 上右键，选择 <code>属性</code>，然后选择 <code>高级系统设置</code>，再选择 <code>环境变量</code>），即可看到<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/env.png"></p><p>点击它，进入编辑界面</p></li><li><p>通过编辑 <code>Path</code>：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/env2.png"></p></li><li><p>新建一个环境变量，输入 <code>mingw64\bin</code> 的绝对路径（在文件管理器中复制路径，然后粘贴到这里），类似于：<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/env3.png"></p></li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在命令行中输入 <code>gcc --version</code>，如果出现类似的信息：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell">gcc.exe (MinGW<span class="hljs-literal">-W64</span> x86_64<span class="hljs-literal">-ucrt-posix-seh</span>，built by Brecht Sanders) <span class="hljs-number">12.2</span>.<span class="hljs-number">0</span><br>Copyright (C) <span class="hljs-number">2022</span> Free Software Foundation， Inc.<br>This is free software; see the source <span class="hljs-keyword">for</span> copying<br>conditions.There is NO<br>warranty; not even <span class="hljs-keyword">for</span> MERCHANTABILITY OP FITNESS <span class="hljs-keyword">FOR</span> A PARTICULAR PURPOSE<br></code></pre></td></tr></table></figure><h1 id="Compiler-On-Windows（Visual-Studio）"><a href="#Compiler-On-Windows（Visual-Studio）" class="headerlink" title="Compiler On Windows（Visual Studio）"></a>Compiler On Windows（Visual Studio）</h1><p>个人不推荐使用 Visual Studio：</p><ol><li>VS 在只需要写一些小程序的初学阶段并不好用，会掩盖程序编译执行的一些非常基础的细节</li><li>VS 的安装包非常大，而且安装过程非常繁琐</li></ol><p>如果你一定要使用 VS，这里贴个教程：<a href="https://zhuanlan.zhihu.com/p/71110525">VS On Windows的安装</a></p>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【环境配置】SSH 远程连接</title>
    <link href="/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/SSH/"/>
    <url>/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/SSH/</url>
    
    <content type="html"><![CDATA[<h1 id="Why-SSH？"><a href="#Why-SSH？" class="headerlink" title="Why SSH？"></a>Why SSH？</h1><p>刚开始学习编程的时候，我们都是在自己的电脑（对于大部分人来说，是一台小笔记本）上进行代码的编写、编译、运行等工作。这是非常自然的一种想法。但是，只在本机上运行会遇到这样一些问题：</p><ol><li>通常我们自己的笔记本是 Windows 系统，它在日常使用便利的同时，也带来很多问题。例如，没有原生 GCC 编译器，和 Bash 截然不同的 Terminal（终端）体验等。</li><li>笔记本性能有限，无法满足一些大型项目的编译、运行需求。<ul><li>例如，笔记本上编译大型项目需要很长时间</li><li>例如，笔记本上的显卡通常显存小，无法满足深度学习的需求</li><li>例如，笔记本上的内存有限，无法满足大型数据库的需求</li><li>例如，笔记本上的 CPU 核心数有限，无法满足大型并行计算的需求</li></ul></li></ol><p>总之，在这时候，我们需要考虑使用远程连接服务器的方式来满足我们的需求。SSH（Secure Shell）是一种非常常用的远程连接协议，它可以让我们在本地电脑上通过命令行的方式连接到远程服务器，进行文件传输、命令执行等操作。</p><h1 id="SSH-的基本使用"><a href="#SSH-的基本使用" class="headerlink" title="SSH 的基本使用"></a>SSH 的基本使用</h1><h2 id="Windows-系统的-SSH-使用"><a href="#Windows-系统的-SSH-使用" class="headerlink" title="Windows 系统的 SSH 使用"></a>Windows 系统的 SSH 使用</h2><h3 id="SSH-服务的开启"><a href="#SSH-服务的开启" class="headerlink" title="SSH 服务的开启"></a>SSH 服务的开启</h3><p>Windows 10 之后的系统自带了 OpenSSH 服务。我们可以通过 <code>Win</code> + <code>R</code>，输入 <code>powershell</code> 进入命令行，然后键入 <code>ssh</code>。如果出现：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240224154203.png"></p><p>则说明 SSH 服务已经开启。</p><h3 id="SSH-的使用"><a href="#SSH-的使用" class="headerlink" title="SSH 的使用"></a>SSH 的使用</h3><p>可以直接在上述命令行 Powershell 中通过：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs powershell">ssh &#123;USER_NAME&#125;<span class="hljs-selector-tag">@</span>&#123;IP_ADDRESS&#125;<br></code></pre></td></tr></table></figure><p>来连接到远程服务器。</p><h2 id="Mobaxterm"><a href="#Mobaxterm" class="headerlink" title="Mobaxterm"></a>Mobaxterm</h2><p>如果你不喜欢使用命令行，可以使用 Mobaxterm。它是一个功能强大的终端模拟器，支持 SSH、SFTP、X11、RDP、VNC、FTP、Mosh 等多种协议。</p><p>我们可以通过<a href="https://mobaxterm.mobatek.net/">Mobaxterm</a>下载官方版本，然后进行安装。</p><p>Mobaxterm 使用起来非常方便：</p><ol><li>点击 Session<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240224154611.png"></li><li>点击 SSH<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240224154618.png"></li><li>输入 IP 地址、用户名、密码<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240224154809.png"></li><li>点击 OK</li><li>输入服务器密码，可以点击 YES 保存密码。</li><li>连接成功</li></ol><h2 id="Linux-系统的-SSH-使用"><a href="#Linux-系统的-SSH-使用" class="headerlink" title="Linux 系统的 SSH 使用"></a>Linux 系统的 SSH 使用</h2><p>都使用 Linux 了，相信你已经可以自己配置 SSH 了。加油！</p>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>常用技术</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【环境配置】Python 环境与 Conda</title>
    <link href="/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Python/"/>
    <url>/2024/02/26/%E5%B8%B8%E7%94%A8%E6%8A%80%E6%9C%AF%E7%AC%94%E8%AE%B0/Python/</url>
    
    <content type="html"><![CDATA[<h1 id="Python-On-Windows"><a href="#Python-On-Windows" class="headerlink" title="Python On Windows"></a>Python On Windows</h1><h2 id="原生-Python-安装"><a href="#原生-Python-安装" class="headerlink" title="原生 Python 安装"></a>原生 Python 安装</h2><p>Windows 的 Python 安装可以直接使用微软应用商店：</p><ul><li><a href="https://apps.microsoft.com/detail/9nj46sx7x90p?activetab=pivot:overviewtab&rtc=1&hl=zh-cn&gl=CN">Python 的安装</a></li><li><a href="https://learn.microsoft.com/zh-cn/windows/python/beginners">Python 的使用</a></li></ul><p>如果无法访问微软应用商店，你可能需要使用一些科学上网的工具。</p><h2 id="Conda-的安装"><a href="#Conda-的安装" class="headerlink" title="Conda 的安装"></a>Conda 的安装</h2><p>在 <a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe">官网</a> 下载对应的安装包，然后执行安装包即可。</p><h1 id="Python-On-Linux（以-Ubuntu-为例）"><a href="#Python-On-Linux（以-Ubuntu-为例）" class="headerlink" title="Python On Linux（以 Ubuntu 为例）"></a>Python On Linux（以 Ubuntu 为例）</h1><h2 id="原生-Python-安装-1"><a href="#原生-Python-安装-1" class="headerlink" title="原生 Python 安装"></a>原生 Python 安装</h2><p>Ubuntu 22.04 应该已经安装了 Python 3，可以通过以下命令查看版本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python3 --version<br></code></pre></td></tr></table></figure><p>即可看到。</p><p>值得注意的是，直接输入 <code>python</code> 可能会找不到 Python 3，这是因为没有设置软链接的原因，这时候你需要输入 <code>python3</code>。</p><p>当然，我们经常会使用到虚拟环境，这时候使用 Conda 会更合适。</p><h2 id="Conda-的安装-1"><a href="#Conda-的安装-1" class="headerlink" title="Conda 的安装"></a>Conda 的安装</h2><p>我们不推荐使用 Anaconda，而是推荐使用 Miniconda，因为 Miniconda 更加轻量级，而且可以自定义安装。</p><p>在 <a href="https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh">官网</a> 下载对应的安装包，然后执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">bash Miniconda3-latest-Linux-x86_64.sh<br></code></pre></td></tr></table></figure><p>然后一路回车，只有两点可能需要注意：</p><ol><li>选择安装路径。默认安装在 <code>~/miniconda3</code>，你可以选择其他路径。</li><li>是否将 Conda 加入 PATH。如果你选择了不加入，那么你需要手动将 Conda 加入 PATH。建议选择加入。</li></ol><p>安装完成后，你需要重启终端，或者使用 <code>source ~/.bashrc</code> ，然后执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda --version<br></code></pre></td></tr></table></figure><p>如果看到版本号，那么说明安装成功。</p>]]></content>
    
    
    <categories>
      
      <category>常用技术笔记</category>
      
      <category>环境配置</category>
      
    </categories>
    
    
    <tags>
      
      <tag>环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【宋词导读 读书报告】宋词中的感性和理性</title>
    <link href="/2024/01/15/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%AE%8B%E8%AF%8D%E4%B8%AD%E7%9A%84%E6%84%9F%E6%80%A7%E5%92%8C%E7%90%86%E6%80%A7/"/>
    <url>/2024/01/15/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%AE%8B%E8%AF%8D%E4%B8%AD%E7%9A%84%E6%84%9F%E6%80%A7%E5%92%8C%E7%90%86%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h1 id="宋词中的感性与理性"><a href="#宋词中的感性与理性" class="headerlink" title="宋词中的感性与理性"></a>宋词中的感性与理性</h1><p>在中国韵文的文学体式中，有一个传统：“文以载道”。这个传统也蔓延到诗上：我们说“温柔敦厚乃诗之教也”，诗天生就被赋予了一种教化的力量。或许正是因此，随着时代的发展和变迁，诗变得越来越理性，越来越深刻，也越来越沉重。相比而言，词的组成里，就有了更多感性的成分。这样一种“要眇宜修”的文学体裁里，“感性”和“理性”是如何相互作用，如何碰撞出美妙的语言的？</p><p>在讨论任何概念的关系之前，我们都应该首先明确我们说的是什么——也就是概念的定义。</p><p>何谓感性？感性是对事物的敏锐体现，是一种“真情锐感”。具体到词的写作中，感性就体现在文字的安排上。感性的词作者，其词句的安排源于直觉，源于对周围事物的体会。而理性则与之不同：在写作中的理性，表现为一种反思，一种节制，乃至于在安排词句的时候，其核心脉络就变感受为“思力”，是根据自己的思索来写作的。</p><p>叶嘉莹先生的《唐宋词十七讲》中，曾经在讨论李后主和晏殊两位词人时着重提及了“感性词人”和“理性词人”的概念。她认为，李后主是一位“完全以感性为主的作者，连他掌握文字的能力，都不是理性的选择，是他自己感性的感受”。而谈论晏殊的时候，她说晏殊这样的理性词人是“对自己的感情有一种节制，有一种掌握”的，而这种词人的词，就能表现出思想性和理性。</p><p>但南宋词从写作技巧而言，其实是更加体现“理性”的。自周邦彦开始，长调慢词的写作逐渐盛行起来。写作长调、慢词的时候，如周邦彦这样的词人，事实上是“以赋笔为词”。赋笔，是铺张之笔，需要思索，也需要安排。原本我们谈论的理性词人，是在感情抒发时的节制，是对自身感受、经历的反省。而这里我们谈论的理性，是将理性深入到了写作技巧的层次，连文字的安排也由理性来决定了。这样的理性，体现在艺术技巧上，既包括曲调的创作，也包括词句的斟酌。</p><p>情感抒发的感性、情感抒发的理性；创作过程的直接感发和理性安排，这些不同的特质体现在不同的词人上，就形成了各自独特的艺术风格。接下来，我们试着通过不同词人书写“春天”的不同笔法，来体悟和探寻其中的区别和联系。</p><h1 id="李煜：纯粹感性的词人"><a href="#李煜：纯粹感性的词人" class="headerlink" title="李煜：纯粹感性的词人"></a>李煜：纯粹感性的词人</h1><p>王国维在《人间词话》曾评价李煜：尼采谓一切文学余爱以血书者。后主之词，真所谓以血书者也。</p><blockquote><p>帘外雨潺潺，春意阑珊。罗衾不耐五更寒。梦里不知身是客，一晌贪欢。</p><p>独自莫凭栏，无限江山，别时容易见时难。流水落花春去也，天上人间。</p></blockquote><p>“帘外雨潺潺，春意阑珊。”这里的潺潺是形容雨声，而且是不太大的小雨的声音。什么时候人能很清晰的听到雨声呢？是安静的时候，乃至于寂静的时候。开头五个字，就勾勒出一个帘内床上人枯坐，帘外小雨连绵的景象。随后“春意阑珊”，一句已经体现出来作者的感受：阑珊的不只是春意，还有自己的意兴。下一句仍是感受：“罗衾不耐五更寒”，真的只有罗衾不耐寒吗？看似写的是身体，实则又让人感受到心灰意冷的境味。那心灰意冷是为了什么呢？“梦里不知身是客，一晌贪欢”，是美梦里又忆及曾经，又仿佛忘却了眼前的惆怅。</p><p>接下来整个下阕都是感叹。“独自莫凭栏，无限江山，别时容易见时难”，仿佛能听到作者心中碎裂的声音。辽阔的江山里，自身便被衬托的格外渺小，想追寻的故人更是无从说起。这一切的悲哀，春雨、春寒、春意阑珊，最终都融于一句更深层的慨叹：“落花流水春去也，天上人间！”</p><p>李煜写的春愁是如此的明确和清晰，在他的笔下，仿佛要把自己的心脏挖出来，融入天下所有的事物里，让所有事物都沾染上他的感受。他能从一帘小雨中体会到“天上人间”的人生无常，这正是感性的敏锐之处。这种纯粹感性派的词，便显得有力度，力透纸背，真所谓“以血书者”。</p><h1 id="晏殊：用理性的反省，让感性的体悟拥有深度"><a href="#晏殊：用理性的反省，让感性的体悟拥有深度" class="headerlink" title="晏殊：用理性的反省，让感性的体悟拥有深度"></a>晏殊：用理性的反省，让感性的体悟拥有深度</h1><blockquote><p>一向年光有限身，等闲别离最销魂。酒筵歌席莫辞频。</p><p>满目山河空念远，落花风雨更伤春，不如怜取眼前人。</p></blockquote><p>这首《浣溪沙》并非是晏殊最为有名或最为出色的作品。但这首伤春之词，却能很好的体现晏殊的节制和反省。“满目山河空念远，落花风雨更伤春”，这句话所描摹的意境，和“独自莫凭栏，无限江山”“落花流水春去也”是何其相似！同样是登高凭栏，面对着辽阔的江山和郁郁绵绵的春雨，如果是某位花间词人，可能会补一句诸如“滴漏声中夜已深”；如果是李煜，想必会有更加惊人的泣血之句。但晏殊不一样，他对自己的伤情是有节制的，他说：“不如怜取眼前人”，他要通过眼前的欢好，来冲和春天的伤情。这就是他理性的体现，同样是抒发自己的感受，他的“感受”本身就是节制的，是有哲理有思索的。“无可奈何花落去，似曾相识燕归来”，这种淡淡的感情，仿佛早晨的轻烟飘荡在湖泊上，读来给人以悠长的回味。</p><h1 id="苏轼、辛弃疾：激昂感情和理性思索的结合"><a href="#苏轼、辛弃疾：激昂感情和理性思索的结合" class="headerlink" title="苏轼、辛弃疾：激昂感情和理性思索的结合"></a>苏轼、辛弃疾：激昂感情和理性思索的结合</h1><blockquote><p>花褪残红青杏小，燕子飞时，绿水人家绕。枝上柳绵吹又少。天涯何处无芳草。</p><p>墙里秋千墙外道，墙外行人，墙里佳人笑。笑渐不闻声渐悄。多情却被无情恼。</p></blockquote><blockquote><p>更能消、几番风雨，匆匆春又归去。惜春长怕花开早，何况落红无数。春且住，见说道、天涯芳草无归路。怨春不语。算只有殷勤，画檐蛛网，尽日惹飞絮。</p><p>长门事，准拟佳期又误。蛾眉曾有人妒。千金纵买相如赋，脉脉此情谁诉？君莫舞，君不见、玉环飞燕皆尘土！闲愁最苦！休去倚危栏，斜阳正在，烟柳断肠处。</p></blockquote><p>苏轼和辛弃疾是宋词创作的两座高峰。作为所谓“豪放派”的两位代表性词人，他们的词同样具备极其深刻的感染力，并且体现了理性和感性的深度结合。</p><p>苏轼的理性体现在他的旷达上。同样是伤春，苏轼的“画风”和晏殊那种淡淡的思索和哀愁又有所不同。他说：“枝上柳绵吹又少，天涯何处无芳草”，前面“花褪残红青杏小”的一点哀愁就消散于无形了。下阕更是以奇妙的视角来写春愁：“笑声不闻声渐消，多情却被无情恼”，明明是一点淡淡的愁绪，却平添了几分趣味。苏轼的理性是一种智慧，一种通透，他要用他这样的智慧去对抗人生的无常，命运的波折。</p><p>辛弃疾的理性则体现在，他的词句中传达出来的那种坚定而激烈的意志。这种意志并非是一时兴起的冲动，那种冲动是轻浮的；而是经过沉重的思索之后，仍然不后悔、不迟疑的一往无前的坚定。他这样的人，前路注定是孤独的，他的感性就在体会这种孤独：“几番风雨”“怨春不语”，这是他的惆怅和悲伤。但在这种悲伤和孤独里，他却没有迟疑过，仍然在激烈的坚定的寻找着出路。“君莫舞！君不见，玉环飞燕皆尘土！”这在辛弃疾以前的人的词作中绝对是少有的激言烈语。同样是抒发被排挤贬谪边缘化的慨叹，晏殊不过说“若有知音见采，不辞唱遍阳春”，两者在气势和决心上就已经分出了明显的区别。</p><p>这是苏轼和辛弃疾，在词之境界的扩大上，做出了最伟大贡献的两位词人。他们在敏锐的体悟之下，用理性的思索将感受变得深刻，是理性和感性的结合。他们用理性来应对感性，排遣也好，对抗也罢，这种内生的，对抗性的力量体现在他们的词里，让他们的词格外有深度和力量。可以说，这是理性和感性共同结合的最好表现形式之一。</p><h1 id="周邦彦：音乐匠人之词"><a href="#周邦彦：音乐匠人之词" class="headerlink" title="周邦彦：音乐匠人之词"></a>周邦彦：音乐匠人之词</h1><blockquote><p>柳阴直，烟里丝丝弄碧。隋堤上、曾见几番，拂水飘绵送行色。登临望故国，谁识京华倦客？长亭路，年去岁来，应折柔条过千尺。</p><p>闲寻旧踪迹，又酒趁哀弦，灯照离席。梨花榆火催寒食。愁一箭风快，半篙波暖，回头迢递便数驿，望人在天北。</p><p>凄恻，恨堆积！渐别浦萦回，津堠岑寂，斜阳冉冉春无极。念月榭携手，露桥闻笛。沉思前事，似梦里，泪暗滴。</p></blockquote><p>周邦彦的词，用王国维的话说，总有一点“隔”的感觉。事实上，虽然周邦彦也写一些小令词，但他艺术成就的高峰，却集中在这种所谓“隔”的长调中。<br>这首词的第一段几乎都是铺垫。“柳阴直，烟里丝丝弄碧。隋堤上、曾见几番，拂水飘绵送行色。”先刻画堤上景象，为下句“登临望故国”起兴。然后写到“长亭路”的时候，这句“应折柔条过千尺”写如一句总结，仿佛要将年年岁岁的折柳为别做一个总结，这是一个审视的、评论的角度。<br>而后写到“闲寻旧踪迹”的时候，词人又交代了很多场景和情感，给人以场景变换、目不暇接的感觉。但概括而言。此段不过写“催别离”之悲和“愁回望”之叹。直到第三段，作者的情感才明白的展现出来：“凄恻，恨堆积”。而后几句去用景色书写自己的情怀，别浦萦回，津堠岑寂，斜阳冉冉。最后“沉思前事，似梦里，泪暗滴”，颇有几分“收”的感受，用这样一个安静的，沉静的环境来收束前文里拗折的感情。<br>这样基于理性安排的词作同样是美的，但它的美需要理解和赏析才能被人所体会到。从正统的“词”文学来说，这样的匠人之词无疑是一种正道，对后来南宋格律词派的发展和相当一部分清代词人的写作产生了重大影响。可惜，从个人体会而言，这种理性多少是余了几分匠气，少了点真切和灵气。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>所以我们为什么要读词？因为我们也需要应对自己的感性。高中的时候我在考试中写过一篇作文，大谈“苦难给我们带来了什么”，被语文老师一顿乱批：伟大的从来都不是什么苦难，而是人在面对苦难的时候所展现出来的品质。其实在这里也是一样：感性从来未必是正确的，它是一种体悟、一种感发，我们也需要用我们的理性去排遣、对抗或者调度它。这种内生的，感性和理性的矛盾，存在于每个人心里。在词或清丽或拗折的语句里，我们一遍又一遍的体悟昔人曾经抒发的情感，不自觉的去思考，他们是以什么态度来面对这样一份情感的。是用血书般的文字吟诵，还是用圆融的观照去排遣？是直呼“杀贼数声”，还是慨叹“江海寄余生”？又或者，在谱曲填词后的某个深夜里，“沉思前事，似梦里，泪暗滴”？至少在某个孤独的瞬间，我们还能想起，还能吟诵，还能穿越千年的时光，和早已化为尘土的他们相逢，体会他们的悲欢。这时候，我们的感性和理性达成了某种和谐的共存，让我们变得强大，让我们有勇气去面对那些未知的明天。</p><h1 id="文件下载链接"><a href="#文件下载链接" class="headerlink" title="文件下载链接"></a>文件下载链接</h1><ul><li><a href="/files/%E5%AE%8B%E8%AF%8D%E4%B8%AD%E7%9A%84%E6%84%9F%E6%80%A7%E5%92%8C%E7%90%86%E6%80%A7.pdf">PDF</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【CS130】Final Review</title>
    <link href="/2024/01/08/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Final-Cheatsheet/"/>
    <url>/2024/01/08/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Final-Cheatsheet/</url>
    
    <content type="html"><![CDATA[<h1 id="Cheatsheet-Final"><a href="#Cheatsheet-Final" class="headerlink" title="Cheatsheet-Final"></a>Cheatsheet-Final</h1><h1 id="4-Scheduling"><a href="#4-Scheduling" class="headerlink" title="4. Scheduling"></a>4. Scheduling</h1><h2 id="4-0-Overview"><a href="#4-0-Overview" class="headerlink" title="4.0. Overview"></a>4.0. Overview</h2><h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p>Scheduling：Deciding which threads are given access to resources from moment to moment.</p><ul><li>Often, we think in terms of CPU time, but could also think about access to resources like network BW or disk access.</li></ul><h3 id="Scheduling-Assumptions"><a href="#Scheduling-Assumptions" class="headerlink" title="Scheduling Assumptions"></a>Scheduling Assumptions</h3><ul><li>One program per user</li><li>One thread per program</li><li>Programs are independent</li></ul><h3 id="Scheduling-Policy-Goals-Criteria（调度的主要目的）"><a href="#Scheduling-Policy-Goals-Criteria（调度的主要目的）" class="headerlink" title="Scheduling Policy Goals &#x2F; Criteria（调度的主要目的）"></a>Scheduling Policy Goals &#x2F; Criteria（调度的主要目的）</h3><ul><li>Minimize Response Time（最小化响应时间）<ul><li>Minimize elapsed time to do an operation &#x2F; job</li></ul></li><li>Maximize Throughput（最大化吞吐量）<ul><li>Throughput related to response time, but not identical:<ul><li>Minimizing response time will lead to more context switching than if you only maximized throughput</li></ul></li><li>Two parts to maximizing throughput<ul><li>Minimize overhead（最小化调度的开销）</li><li>Efficient use of resources（最大化利用资源）</li></ul></li></ul></li><li>Fairness<ul><li>Share CPU among users in some equitable way</li></ul></li><li>程序既使用CPU，也使用I&#x2F;O设备。操作系统通过调度算法决定下一个要在CPU上执行的作业。时间片轮转调度算法确保每个线程都能获得一定的CPU时间。某些I&#x2F;O活动可能会被视为计算，因为CPU仍在使用中。I&#x2F;O指的是进程进入阻塞状态，等待外部设备完成工作。</li></ul><h3 id="Scheduling-Algorithms"><a href="#Scheduling-Algorithms" class="headerlink" title="Scheduling Algorithms"></a>Scheduling Algorithms</h3><ul><li>First Come, First Served</li><li>Round Robin</li><li>Priority</li><li>Multi Level Queue</li><li>Real-Time Scheduling</li></ul><h2 id="4-1-FCFS-Scheduling"><a href="#4-1-FCFS-Scheduling" class="headerlink" title="4.1. FCFS Scheduling"></a>4.1. FCFS Scheduling</h2><h3 id="Ideas"><a href="#Ideas" class="headerlink" title="Ideas"></a>Ideas</h3><ul><li><strong>First-Come, First Served</strong></li><li><strong>Convoy Effort</strong>: short process behind long process</li></ul><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet0.png"><br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet1.png"></p><h2 id="4-2-Round-Robin-Scheduling"><a href="#4-2-Round-Robin-Scheduling" class="headerlink" title="4.2. Round Robin Scheduling"></a>4.2. Round Robin Scheduling</h2><h3 id="Ideas-1"><a href="#Ideas-1" class="headerlink" title="Ideas"></a>Ideas</h3><ul><li>Idea：Preemption<ul><li>Each process gets a small unit of CPU time quantum, usually 10-100ms</li><li>After quantum expires, the process is preempted and added to the end of the ready queue</li></ul></li><li>$n$ process in ready queue and time quantum is $q$<ul><li>Each process get $\frac{1}{n}$ of the CPU time</li><li>In chunks of at most $q$ time units</li><li><strong>No process waits more than $(n-1)\cdot q$ time units</strong></li></ul></li><li>Performance<ul><li>$q$ large → FCFS</li><li>$q$ small → Interleaved（交错调度）（Really small → HT，超线程）</li><li>$q$ must be large with respect to context switch, otherwise overhead is too high.</li></ul></li><li>How to choose time slices<ul><li>What if too big?<ul><li>Response time suffers</li></ul></li><li>What if infinite?<ul><li>Get back to FCFS</li></ul></li><li>What if too small?<ul><li>Through suffers</li></ul></li><li>Actually choices:<ul><li>In practice, need to balance short job performance and long job throughput</li><li>Typical time slice today is between 10 - 100 ms</li><li>Typical context-switching overhead is 0.1 - 1 ms</li><li>Roughly 1% overhead due to context-switching</li></ul></li></ul></li></ul><h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example"></a>Example</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet2.png"></p><h2 id="4-3-Priority-Scheduling"><a href="#4-3-Priority-Scheduling" class="headerlink" title="4.3. Priority Scheduling"></a>4.3. Priority Scheduling</h2><ul><li>A priority value (int.) is associated with eachprocess.</li><li>Based on:<ul><li>Cost to user</li><li>Importance to user</li><li>Aging</li><li>%CPU time used in last XX hours</li></ul></li><li>Execution Plan<ul><li>Always execute highest-priority runnable jobs to completion</li><li>Each queue can be processed in RR with some time quantum</li></ul></li><li>Problem<ul><li>Starvation</li><li>Deadlock</li></ul></li><li>How to fix problems<ul><li>Dynamic Properties<ul><li>Adjust base-level priority up or down based on heuristicsabout interactivity, locking, burst behavior, etc…</li></ul></li></ul></li><li>How to implement fairness?<ul><li>Give each queue some fraction of the CPU</li><li>Increase priority of jobs that don’t get service</li></ul></li></ul><h2 id="4-4-Lottery-Scheduling"><a href="#4-4-Lottery-Scheduling" class="headerlink" title="4.4. Lottery Scheduling"></a>4.4. Lottery Scheduling</h2><h3 id="Definition-1"><a href="#Definition-1" class="headerlink" title="Definition"></a>Definition</h3><ul><li>Give each job some number of lottery tickets</li><li>On each time slice, randomly pick a winning ticket</li><li>On average, CPU time is proportional to number of tickets given to each job</li></ul><h3 id="Tickets-Assignment"><a href="#Tickets-Assignment" class="headerlink" title="Tickets Assignment"></a>Tickets Assignment</h3><ul><li>SRTF: Short Running Jobs get more, long running jobs get fewer</li><li>to avoid starvation, every job gets at least one ticket</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet3.png"></p><h3 id="How-to-evaluate-a-scheduling-algorithm"><a href="#How-to-evaluate-a-scheduling-algorithm" class="headerlink" title="How to evaluate a scheduling algorithm?"></a>How to evaluate a scheduling algorithm?</h3><ul><li>Deterministic modeling</li><li>Queueing models</li><li>Implementation &#x2F; Simulation</li></ul><h2 id="4-6-What-if-We-Knew-the-Future"><a href="#4-6-What-if-We-Knew-the-Future" class="headerlink" title="4.6. What if We Knew the Future?"></a>4.6. What if We Knew the Future?</h2><h3 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h3><ul><li>Shortest Job First (SJF)</li><li>Shortest Remaining Time First (SRTF)<ul><li>Sometimes called “Shortest Remaining Time to Completion First” (SRTCF)</li></ul></li></ul><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>SJF &#x2F; SRTF are the best you can do at minimizing average response time</p><ul><li><p><strong>Provably optimal</strong> !</p></li><li><p>SRTF is always at least as good as SJF, we focus on it.</p></li><li><p>Comparison of SRTF with FCFS</p><ul><li>What if all jobs the same length?<ul><li>SRTF becomes the same as FCFS (i.e. FCFS is best can do if all jobs the same length)</li></ul></li><li>What if jobs have varying length?<ul><li>SRTF: short jobs not stuck behind long ones</li></ul></li></ul></li><li><p>Benefits of SRTF</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet4.png"></p></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet5.png"></p><ul><li>Starvation<ul><li><strong>SRTF can lead to starvation if many small jobs!</strong></li><li>Large jobs never run</li></ul></li><li>Somehow need to predict future<ul><li>Some systems ask the user</li></ul></li><li>SRTF Pros &amp; Cons<ul><li>Pros: Optimal (average response time)</li><li>Cons: Hard to predict future; unfair</li></ul></li></ul><h3 id="Predicting-the-length-of-the-next-CPU-burst"><a href="#Predicting-the-length-of-the-next-CPU-burst" class="headerlink" title="Predicting the length of the next CPU burst"></a>Predicting the length of the next CPU burst</h3><ul><li>Adaptive: Changing policy based on past behavior<ul><li>CPU scheduling, in virtual memory, in file systems, etc</li><li>Works because programs have predictable behavior<ul><li>If program was I&#x2F;O bound in past, likely in future</li><li>If computer behavior were random, wouldn’t help</li></ul></li></ul></li></ul><h2 id="4-7-Multi-level-Queue"><a href="#4-7-Multi-level-Queue" class="headerlink" title="4.7. Multi-level Queue"></a>4.7. Multi-level Queue</h2><ul><li>Ready queue partitioned into separate queues<ul><li>e.g. system processes. foreground(interactive), background(batch), student processes…</li></ul></li><li>Each queue has its own scheduling algorithm<ul><li>e.g. foreground(RR), background(FCFS)</li></ul></li><li>Processes assigned to one queue permanently</li><li>Scheduling must be done between the queues<ul><li>Fixed priority</li><li>Time slice: Each queue get some CPU time that it schedules</li></ul></li></ul><h3 id="Multilevel-Feedback-Queue"><a href="#Multilevel-Feedback-Queue" class="headerlink" title="Multilevel Feedback Queue"></a>Multilevel Feedback Queue</h3><ul><li><strong>Multilevel queue, each with different priorities</strong><ul><li>Higher priority queue ofter considered “foreground” tasks</li></ul></li><li><strong>Each queue has its own scheduling algorithm</strong><ul><li>e.g., Foreground - RR, background - FCFS</li></ul></li><li><strong>A process can move between the queues</strong><ul><li>Aging can be implemented this way</li></ul></li><li>Parameters for a multilevel feedback queue scheduler<ul><li>Number of queues</li><li>Scheduling algorithm for each queue</li><li>Method used to determine<ul><li>When to upgrade a process</li><li>When to demote a process</li><li>Which queue a process will enter when that process needs services</li></ul></li></ul></li><li><strong>Scheduling must be done between the queues</strong><ul><li>Fixed priority scheduling</li><li>Time slice</li><li>Countermeasure: user action that can ruin intent for the OS designers</li></ul></li></ul><h3 id="Linux-O-1-Scheduler"><a href="#Linux-O-1-Scheduler" class="headerlink" title="Linux O(1) Scheduler"></a>Linux O(1) Scheduler</h3><p>Priority-based scheduler: 140 priorities</p><ul><li>40 for User Tasks</li><li>100 for Real-time&#x2F;Kernel</li><li>Lower priority value → Higher priority</li><li>All algorithms $O(1)$: schedule n processes in constant time<ul><li>compute time-slices&#x2F;priorities&#x2F;interactivity credits when job finishes time slice</li><li>140-bit bit mask indicates presence or absence of job(s) at given priority level</li></ul></li></ul><p>Two separate priority queues (arrays)</p><ul><li>Active</li><li>Expired</li><li>All tasks in the active queue use up their time slices and get placed on the expired queue, after which queue swapped</li></ul><p>Time slice depends on priority - linearly mapped onto time slice range</p><ul><li>Like multi-level queue (one queue per priority) with different time slice at each level</li><li>Execution split into “Time slice Granularity” chunks — RR through priority</li></ul><p>Heuristics</p><ul><li>User-task priority adjusted ±5 based on heuristics<ul><li><code>p -&gt; sleep_avg = sleep_time - run_time</code></li><li>Higher <code>sleep_avg</code> → more I&#x2F;O bound the task, more reward</li></ul></li><li>Interactive Credit<ul><li>Earned when task sleeps for “long” time, Spend when task runs for “long” time</li><li>IC is used to provide hysteresis to avoid changing interactivity for temporary changes in behavior</li></ul></li><li>BUT, interactive tasks get special dispensation<ul><li>To try to maintain interactivity</li><li>Placed back into active queue, unless another track has starved for too long..</li></ul></li></ul><p>Real-Time tasks</p><ul><li>Always preempt non-RT tasks and no dynamic adjustment of priorities</li><li>Scheduling schemes<ul><li><code>SCHED_FIFO</code>: preempts other tasks, no timeslice limit</li><li><code>SCHED_RR</code>: preempts normal tasks, RR scheduling amongst tasks of same priority</li></ul></li></ul><h2 id="4-8-Real-Time-Scheduling"><a href="#4-8-Real-Time-Scheduling" class="headerlink" title="4.8. Real-Time Scheduling"></a>4.8. Real-Time Scheduling</h2><p>Efficiency is important but <strong>predictability</strong> is essential</p><ul><li>Hard real-time computing<ul><li>Attempt to meet all deadlines</li><li>EDF (earliest deadline first), LLF (least laxity first)</li><li>RMS (Rate-Monotonic Scheduling), DM (Deadline Monotonic Scheduling)</li></ul></li><li>Soft real-time computing<ul><li>Attempt to meed deadlines with high probability</li><li>Minimize miss ratio &#x2F; Maximize completion ratio</li><li>CBS (Constant Bandwidth Server)</li></ul></li></ul><h3 id="Issues-in-Real-Time-Scheduling"><a href="#Issues-in-Real-Time-Scheduling" class="headerlink" title="Issues in Real-Time Scheduling"></a>Issues in Real-Time Scheduling</h3><ul><li>Dispatch Latency</li><li>Priority Inversion and Inheritance<ul><li>priority inversion: Higher priority process needs kernel resource currently being used by another lower priority process, thus Higher priority process must wait</li><li>Priority inheritance (Solution of Priority inversion): Low priority process now inherits high priority until it has completed use of the resource in question.</li></ul></li></ul><h2 id="4-9-EDF-Earliest-Deadline-FIrst"><a href="#4-9-EDF-Earliest-Deadline-FIrst" class="headerlink" title="4.9. EDF (Earliest Deadline FIrst)"></a>4.9. EDF (Earliest Deadline FIrst)</h2><ul><li><p>Tasks <strong>periodic</strong> with period $P$ and computation $C$ in each period: $(P_i, C_i)$ for each task $i$</p></li><li><p>Preemptive priority-based dynamic scheduling:</p><ul><li>Each task is assigned a (current) priority based on how close the absolute deadline is (i.e. $D^{t+1} &#x3D; D_i^t + P_i$ for each task!)</li><li><strong>The scheduler always schedules the active task with the closest absolute deadline</strong></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet6.png"></p><ul><li>Schedulable when $\sum_{i&#x3D;1}^n(\frac{C_i}{P_i})\leq 1$</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet7.png"></p><h1 id="5-Address-Translation"><a href="#5-Address-Translation" class="headerlink" title="5. Address Translation"></a>5. Address Translation</h1><h2 id="5-1-Address-Address-Space"><a href="#5-1-Address-Address-Space" class="headerlink" title="5.1. Address &amp; Address Space"></a>5.1. Address &amp; Address Space</h2><p>Definition: Set of accessible addresses and the state associated with them.</p><p>What happens when processor reads or writes to an address?</p><ul><li>Perhaps acts like regular memory</li><li>Perhaps causes I&#x2F;O operation (Memory-mapped I&#x2F;O)</li><li>Causes program to abort (segfault)?</li><li>Communicate with another program</li></ul><p>Virtualizing Resources：Why worry about Resources？</p><p>为什么要担心内存共享？</p><ul><li>进程和&#x2F;或内核的完整工作状态由其在内存（和寄存器）中的数据定义。</li><li>因此，不能让不同的控制线程使用相同的内存。<ul><li>物理上：两个不同的数据不能占用内存中的同一个位置。</li></ul></li><li>保护机制。<ul><li>不希望不同的线程访问彼此的内存。</li></ul></li></ul><h2 id="5-2-Important-Aspects-of-Memory-Multiplexing"><a href="#5-2-Important-Aspects-of-Memory-Multiplexing" class="headerlink" title="5.2. Important Aspects of Memory Multiplexing"></a>5.2. Important Aspects of Memory Multiplexing</h2><h3 id="Protection"><a href="#Protection" class="headerlink" title="Protection"></a>Protection</h3><ul><li>Prevent access to private memory of other processes<ul><li>Different pages of memory can be given special behavior (e.g., Read Only, Invisible to user programs, etc.)</li><li>Kernel data protected from user programs</li><li>Programs protected from themselves</li></ul></li></ul><h3 id="Controlled-Overlap"><a href="#Controlled-Overlap" class="headerlink" title="Controlled Overlap"></a>Controlled Overlap</h3><ul><li>Separate state of threads should not collide in physical memory. Obviously, unexpected overlap<br>causes chaos!</li><li>Conversely, would like the ability to overlap when desired (for communication)</li></ul><h3 id="Translation"><a href="#Translation" class="headerlink" title="Translation"></a>Translation</h3><ul><li>Ability to translate accesses from one address space (virtual) to a different one (physical)</li><li>When translation exists, processor uses virtual addresses, physical memory uses physical<br>addresses</li><li>Side effects:<ul><li>Can be used to avoid overlap</li><li>Can be used to give uniform view of memory to programs</li></ul></li></ul><p>Addresses is bounded to final valuesanywhere in this path</p><ul><li>Depends on HW support</li><li>Also depends on OS</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet8.png"></p><h2 id="5-3-Simple-B-B-Method"><a href="#5-3-Simple-B-B-Method" class="headerlink" title="5.3. Simple B&amp;B Method"></a>5.3. Simple B&amp;B Method</h2><h3 id="Multi-programming-Version-w-Protection-——Base-Bound"><a href="#Multi-programming-Version-w-Protection-——Base-Bound" class="headerlink" title="Multi-programming (Version w&#x2F; Protection)——Base &amp; Bound"></a>Multi-programming (Version w&#x2F; Protection)——Base &amp; Bound</h3><p>Can we protect programs from each other without translation?</p><ul><li>Yes: use two special registers BaseAddr and LimitAddr to prevent user from straying outside designated area<ul><li>Cause error if user tries to access an illegal address</li></ul></li><li>During switch, kernel loads new base&#x2F;limit from PCB (Process Control Block)</li><li>User not allowed to change base&#x2F;limit registers</li></ul><h3 id="Issue-with-simble-B-B-Method"><a href="#Issue-with-simble-B-B-Method" class="headerlink" title="Issue with simble B&amp;B Method"></a>Issue with simble B&amp;B Method</h3><ul><li>Fragmentation problem over time<ul><li>Not every process is same size → memory becomes fragmented over time</li></ul></li><li>Missing support for sparse address space<ul><li>Would like to have multiple chunks&#x2F;program (Code, Data, Stack, Heap, etc)</li></ul></li><li>Hard to do inter-process sharing<ul><li>Want to share code segments when possible</li><li>Want to share memory between processes</li><li>Helped by providing multiple segments per process</li></ul></li></ul><h2 id="5-4-Multi-Segment-Model"><a href="#5-4-Multi-Segment-Model" class="headerlink" title="5.4. Multi Segment Model"></a>5.4. Multi Segment Model</h2><ul><li>Segment map resides in processor<ul><li><strong>Segment number</strong> mapped into <strong>base&#x2F;limit pair</strong></li><li>Base added to offset to generate physical address</li><li>Error check catches offset out of range</li></ul></li><li>As many chunks of physical memory as entries<ul><li>Segment addressed by portion of virtual address</li><li>However, could be included in instruction instead:<ul><li>x86 Example: mov [es:bx],ax</li></ul></li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet9.png"></p><h3 id="Observations-about-Segmentation"><a href="#Observations-about-Segmentation" class="headerlink" title="Observations about Segmentation"></a>Observations about Segmentation</h3><ul><li>Virtual address space has holes<ul><li>Segmentation efficient for <strong>sparse address spaces</strong></li><li>A correct program should never address gaps (except as mentioned in moment)<ul><li>If it does, trap to kernel and dump core</li></ul></li></ul></li><li>When it is OK to address outside valid range?<ul><li>This is how the stack and heap are allowed to grow</li><li>For instance, stack takes fault, system automatically increases size of stack</li></ul></li><li>Need protection mode in segment table<ul><li>For example, code segment would be read-only</li><li><strong>Data and stack</strong> would be <strong>read-write</strong> (stores allowed)</li><li>Shared segment could be read-only or read-write</li></ul></li><li>What must be saved&#x2F;restored on context switch?<ul><li>Segment table stored in CPU, not in memory (small)</li><li>Might store all of process’ memory onto disk when switched (called “<strong>swapping</strong>”)</li></ul></li></ul><h3 id="Problems-with-Segmantation"><a href="#Problems-with-Segmantation" class="headerlink" title="Problems with Segmantation"></a>Problems with Segmantation</h3><ul><li>Must fit variable-sized chunks into physical memory</li><li>May move processes multiple times to fit everything</li><li>Limited options for swapping to disk</li><li><strong>Fragmentation</strong>: wasted space<ul><li>External: free gaps between allocated chunks</li><li>Internal: don’t need all memory within allocated chunks</li></ul></li></ul><h2 id="5-5-Paging"><a href="#5-5-Paging" class="headerlink" title="5.5. Paging"></a>5.5. Paging</h2><ul><li>Physical Memory in <strong>Fixed Size Chunks</strong></li><li>Can use simple vector of bits to handle allocation: 00110001110001101 … 110010（BitMap）<ul><li>Each bit represents page of physical memory：1 → allocated, 0 → free</li></ul></li><li>Typically have <strong>small pages</strong> (1K-16K)<ul><li>Consequently: need multiple pages&#x2F;segment</li></ul></li></ul><h3 id="How-to-implement-Simple-Paging"><a href="#How-to-implement-Simple-Paging" class="headerlink" title="How to implement Simple Paging"></a>How to implement Simple Paging</h3><ul><li>Page Table (One per process)<ul><li>Resides in physical memory</li><li>Contains physical page and permission for each virtual page<ul><li>Permissions include: Valid bits, Read, Write, etc</li></ul></li></ul></li><li>Virtual address mapping<ul><li>Offset from Virtual address copied to Physical Address<ul><li>Example: 10 bit offset fi 1024-byte pages</li></ul></li><li>Virtual page # is all remaining bits<ul><li>Example for 32-bits: 32-10 &#x3D; 22 bits, i.e. 4 million entries</li><li>Physical page # copied from table into physical address</li></ul></li></ul></li><li>Check Page Table bounds and permissions</li></ul><h3 id="Where-is-page-sharing-used"><a href="#Where-is-page-sharing-used" class="headerlink" title="Where is page sharing used ?"></a>Where is page sharing used ?</h3><ul><li>The “kernel region” of every process has the same page table entries</li><li>Different processes running same binary!</li><li>User-level system libraries (execute only)</li><li>Shared-memory segments between different processes</li></ul><h3 id="Some-Simple-Security-Measures"><a href="#Some-Simple-Security-Measures" class="headerlink" title="Some Simple Security Measures"></a>Some Simple Security Measures</h3><ul><li>Address Space Randomization</li><li>Kernel address space isolation</li></ul><h2 id="5-6-Multi-Level-Translation"><a href="#5-6-Multi-Level-Translation" class="headerlink" title="5.6. Multi-Level Translation"></a>5.6. Multi-Level Translation</h2><p>Motivation：单层 Page Table 太大了，全部放在memory里很不方便。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet10.png"></p><h1 id="6-Caching-TLB"><a href="#6-Caching-TLB" class="headerlink" title="6. Caching, TLB"></a>6. Caching, TLB</h1><h2 id="6-1-Page-Table-Page-Table-Entry"><a href="#6-1-Page-Table-Page-Table-Entry" class="headerlink" title="6.1. Page Table &amp; Page Table Entry"></a>6.1. Page Table &amp; Page Table Entry</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet11.png"></p><h3 id="Two-level-page-table"><a href="#Two-level-page-table" class="headerlink" title="Two-level page table"></a>Two-level page table</h3><ul><li>Tree Of Page Tables: 10b-10b-12b pattern</li><li>Table Fixed Size（1024 Entries）<ul><li>On Context-Switch: Save single PageTablePtr Register</li></ul></li><li>Valid bits on Page Table Entries<ul><li>Don’t need every 2nd-level table</li><li>Even when exist, 2nd-level tables <strong>can reside on disk</strong> if not in use</li></ul></li></ul><h3 id="Page-Table-Entry（PTE）"><a href="#Page-Table-Entry（PTE）" class="headerlink" title="Page Table Entry（PTE）"></a>Page Table Entry（PTE）</h3><p>Example：x86 PTE</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet12.png"></p><ul><li>P: Present (same as “valid” bit in other architectures)</li><li>W: Writeable</li><li>U: User accessible</li><li>PWT: Page write transparent: external cache write-through</li><li>PCD: Page cache disabled (page cannot be cached)</li><li>A: Accessed: page has been accessed recently</li><li>D: Dirty (PTE only): page has been modified recently</li><li>PS: Page Size: PS&#x3D;1 → 4MB page (directory only).</li><li>Bottom 22 bits of virtual address serve as offset</li></ul><h3 id="How-to-use-PTE"><a href="#How-to-use-PTE" class="headerlink" title="How to use PTE?"></a>How to use PTE?</h3><ol><li>Demand Paging<ul><li>Keep only active pages in memory</li><li>Place others on disk and mark their PTEs invalid</li></ul></li><li>Copy on Write<ul><li>UNIX fork gives copy of parent address space to child<ul><li>Address spaces disconnected after child created</li></ul></li><li>How to do this cheaply?<ul><li>Make copy of parent’s page tables (point at same memory)</li><li><strong>Mark entries in both sets of page tables as read-only</strong></li><li><strong>Page fault on write creates two copies（只在需要 Write 的时候，再创建新的页面）</strong></li></ul></li></ul></li><li>Zero Fill On Demand<ul><li>New data pages must carry no information (say be zeroed)</li><li>Mark PTEs as invalid; page fault on use gets zeroed page</li><li>Often, OS creates zeroed pages in background</li></ul></li></ol><h3 id="Multi-level-Translation-Segments-Pages"><a href="#Multi-level-Translation-Segments-Pages" class="headerlink" title="Multi-level Translation: Segments + Pages"></a>Multi-level Translation: Segments + Pages</h3><p>What about a tree of tables?</p><ul><li>Lowest level page table fi memory still allocated with bitmap</li><li>Higher levels often segmented</li></ul><h2 id="6-2-Inverted-Page-Table"><a href="#6-2-Inverted-Page-Table" class="headerlink" title="6.2. Inverted Page Table"></a>6.2. Inverted Page Table</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet13.png"></p><p>IA64: 64bit addresses: Six-level page table?</p><ul><li>No! Too slow! Too Many Almost-Empty Tables</li><li>核心问题：Physical memory may be much less than Virtual Memory allocated</li></ul><h3 id="Inverted-Page-Table"><a href="#Inverted-Page-Table" class="headerlink" title="Inverted Page Table"></a>Inverted Page Table</h3><p>Using a hash table</p><ul><li>Called an “<strong>Inverted Page Table</strong>”</li><li>Size is <strong>independent of virtual address space</strong></li><li>Directly related to amount of physical memory</li><li>Very attractive option for 64-bit address spaces<ul><li>PowerPC, UltraSPARC, IA64</li></ul></li></ul><h2 id="6-3-Address-Translation-Comparison"><a href="#6-3-Address-Translation-Comparison" class="headerlink" title="6.3. Address Translation Comparison"></a>6.3. Address Translation Comparison</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet14.png"></p><p>MMU（内存管理单元）的位置和功能。</p><p>MMU是位于处理器和内存系统之间的一个组件。当处理器发出读取虚拟地址的请求时，请求会通过MMU转发到缓存（再传递到内存）。一段时间后，内存系统会以物理地址的形式回复存储在该物理地址上的数据（这是通过虚拟地址到物理地址的转换得到的结果）。这个过程在缓存命中时非常快速，但在缓存未命中时会比较慢。</p><p>那么MMU具体在做什么呢？在每次引用（指令获取、加载、存储）时，MMU会读取（多层级的）页表项，以获取物理帧或发生错误（FAULT）。这个过程会经过缓存再传递到内存，并且最终会读取或写入到物理位置上。</p><p>简而言之，MMU的主要功能是实现虚拟地址到物理地址的转换。它通过查找页表来确定虚拟地址对应的物理地址，并将数据从物理地址读取或写入。这个过程中会使用缓存来提高访问速度，但如果在缓存中未找到对应的数据，则需要从内存中读取，这会比较慢。</p><p>总结一下，MMU的作用是管理虚拟地址和物理地址之间的转换，并通过读取和写入物理位置来实现对内存的访问。它是处理器和内存系统之间的重要桥梁，对于实现高效的内存管理至关重要。</p><h2 id="6-4-TLB-Translation-Look-Aside-Buffer"><a href="#6-4-TLB-Translation-Look-Aside-Buffer" class="headerlink" title="6.4. TLB: Translation Look-Aside Buffer"></a>6.4. TLB: Translation Look-Aside Buffer</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet15.png"></p><h3 id="What-TLB-Organization-Makes-Sense"><a href="#What-TLB-Organization-Makes-Sense" class="headerlink" title="What TLB Organization Makes Sense?"></a>What TLB Organization Makes Sense?</h3><ul><li>Needs to be really fast<ul><li><strong>Critical path of memory access</strong><ul><li>In simplest view: before the cache</li><li>Thus, this adds to access time (reducing cache speed)</li></ul></li><li>Seems to argue for Direct Mapped or Low Associativity</li></ul></li><li>However, needs to have very few conflicts!<ul><li>With TLB, the Miss Time extremely high! (PT traversal)</li><li>Cost of Conflict (Miss Time) is high</li><li>Hit Time – dictated by clock cycle</li></ul></li><li>Thrashing: continuous conflicts between accesses</li></ul><h3 id="Current-Example-Memory-Hierarchy"><a href="#Current-Example-Memory-Hierarchy" class="headerlink" title="Current Example: Memory Hierarchy"></a>Current Example: Memory Hierarchy</h3><p>Caches (all 64 B line size)</p><ul><li>L1 I-Cache: 32 KiB&#x2F;core, 8-way set assoc.</li><li>L1 D Cache: 32 KiB&#x2F;core, 8-way set assoc., 4-5 cycles load-to-use, Writeback policy</li><li>L2 Cache: 1 MiB&#x2F;core, 16-way set assoc., Inclusive, Write-back policy, 14 cycles latency</li><li>L3 Cache: 1.375 MiB&#x2F;core, 11-way set assoc., shared across cores, Noninclusive victim cache, Write-back policy, 50-70 cycles latency</li></ul><p>TLB</p><ul><li>L1 ITLB, 128 entries; 8-way set assoc. for 4 KB pages<ul><li>8 entries per thread; fully associative, for 2 MiB &#x2F; 4 MiB page</li></ul></li><li>L1 DTLB 64 entries; 4-way set associative for 4 KB pages<ul><li>32 entries; 4-way set associative, 2 MiB &#x2F; 4 MiB page translations:</li><li>4 entries; 4-way associative, 1G page translations:</li></ul></li><li>L2 STLB: 1536 entries; 12-way set assoc. 4 KiB + 2 MiB pages<ul><li>16 entries; 4-way set associative, 1 GiB page translations:</li></ul></li></ul><h3 id="What-Happens-on-a-Context-Switch"><a href="#What-Happens-on-a-Context-Switch" class="headerlink" title="What Happens on a Context Switch?"></a>What Happens on a Context Switch?</h3><ul><li>Invalidate TLB: simple but might be expensive<ul><li>What if switching frequently between processes</li></ul></li><li>Include ProcessID in TLB<ul><li>This is an architectural solution: needs <strong>hardware</strong></li></ul></li></ul><p>What if translation tables change?</p><ul><li>For example, to move page from memory to disk or vice versa…<ul><li>Must invalidate TLB entry!</li><li>Otherwise, might think that page is still in memory!</li></ul></li><li>Called “<strong>TLB Consistency</strong>”</li></ul><h1 id="7-Demand-Paging"><a href="#7-Demand-Paging" class="headerlink" title="7. Demand Paging"></a>7. Demand Paging</h1><h2 id="7-1-Page-Fault"><a href="#7-1-Page-Fault" class="headerlink" title="7.1. Page Fault"></a>7.1. Page Fault</h2><h3 id="Definition-2"><a href="#Definition-2" class="headerlink" title="Definition"></a>Definition</h3><p>The Virtual-to-Physical Translation fails</p><ul><li>PTE marked invalid, Priv. Level Violation, Access violation, or does not exist<ul><li>Causes an Fault &#x2F; Trap</li></ul></li><li><strong>Not an interrupt</strong> because synchronous to instruction execution<ul><li>May occur on instruction fetch or data access</li><li>Protection violations typically terminate the instruction</li></ul></li></ul><h3 id="Page-Fault-→-Demand-Paging"><a href="#Page-Fault-→-Demand-Paging" class="headerlink" title="Page Fault → Demand Paging"></a>Page Fault → Demand Paging</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet16.png"></p><h3 id="Inversion-of-HW-SW-Boundary"><a href="#Inversion-of-HW-SW-Boundary" class="headerlink" title="Inversion of HW&#x2F;SW Boundary"></a>Inversion of HW&#x2F;SW Boundary</h3><p>硬件和软件边界的反转现象：在执行指令时，如果发生页面错误（Page Fault），操作系统的软件会介入并采取相应的措施来解决问题。这可能包括加载页面、创建页面、写时复制等操作，并更新页表项以确保后续的地址转换成功。然后，操作系统会重新启动或恢复指令的执行。这种反转现象在RISC（精简指令集计算机）指令集中是一个巨大的简化，但在x86指令集等复杂指令集中可能会更加复杂，因为指令可能会修改状态。</p><h2 id="7-2-Demand-Paging"><a href="#7-2-Demand-Paging" class="headerlink" title="7.2. Demand Paging"></a>7.2. Demand Paging</h2><ul><li>What “block size”? - 1 page (e.g, 4 KB)</li><li>What “organization” ie. direct-mapped, set-assoc., fullyassociative?<ul><li>Any page in any frame of memory,</li><li>i.e., fully associative: arbitrary virtual → physical mapping</li></ul></li><li>How do we locate a page?<ul><li>First check TLB, then page-table traversal</li></ul></li><li>What is page replacement policy? (i.e. LRU, Random…)<ul><li>This requires more explanation… (kinda LRU)</li></ul></li><li>What happens on a miss?<ul><li>Go to lower level to fill miss (i.e. disk)</li></ul></li><li>What happens on a write? (write-through, write back)<ul><li>Definitely write-back – need dirty bit!</li></ul></li></ul><p><img src="/Cheatsheet-Final%20a3ede0b2d25945df9dd63986f8a9b2fb/Untitled%2017.png" alt="Use main memory as “cache” for disk"></p><p>Use main memory as “cache” for disk</p><h2 id="7-3-Illusion-of-Infinite-Memory"><a href="#7-3-Illusion-of-Infinite-Memory" class="headerlink" title="7.3. Illusion of Infinite Memory"></a>7.3. Illusion of Infinite Memory</h2><p>Transparent Level of Indirection (page table)</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet18.png"></p><h2 id="7-4-Demand-Paging-Mechanisms"><a href="#7-4-Demand-Paging-Mechanisms" class="headerlink" title="7.4. Demand Paging Mechanisms"></a>7.4. Demand Paging Mechanisms</h2><p>PTE makes demand paging implementatable</p><ul><li>Valid → Page in memory, PTE points at physical page</li><li>Not Valid → Page not in memory; use info in PTE to find it on disk when necessary</li></ul><h3 id="What-does-OS-do-on-a-Page-Fault"><a href="#What-does-OS-do-on-a-Page-Fault" class="headerlink" title="What does OS do on a Page Fault"></a>What does OS do on a Page Fault</h3><p>Choose an old page to replace</p><ul><li>If old page modified (“D&#x3D;1”), write contents back to disk</li><li>Change its PTE and any cached TLB to be invalid</li><li>Load new page into memory from disk</li><li>Update page table entry, invalidate TLB for new entry</li><li>Continue thread from original faulting location</li></ul><p>TLB for new page will be loaded when thread continued!</p><h3 id="Some-Questions"><a href="#Some-Questions" class="headerlink" title="Some Questions"></a>Some Questions</h3><p>During a page fault, where does the OS get a free frame?</p><ul><li>Keeps a free list<ul><li>Unix runs a “reaper” if memory gets too full<ul><li>Schedule dirty pages to be written back on disk</li><li>Zero (clean) pages which haven’t been accessed in a while</li></ul></li><li>As a last resort, evict a dirty page first</li></ul></li><li>How can we organize these mechanisms?<ul><li>Work on the replacement policy</li></ul></li><li>How many page frames&#x2F;process?<ul><li>Like thread scheduling, need to “schedule” memory resources:<ul><li>Utilization? fairness? priority?</li></ul></li><li>Allocation of disk paging bandwidth</li></ul></li></ul><p>操作系统通过维护一个空闲列表来管理可用的物理页帧。当内存空间不足时，Unix系统会运行一个“回收器”，将脏页面写回磁盘，并清除一段时间内未被访问的干净页面。作为最后的手段，如果没有空闲的干净页面，操作系统将优先驱逐一个脏页面。为了组织和管理这些机制，需要制定合适的替换策略。</p><p>另外，还讨论了每个进程应分配多少个页帧的问题。类似于线程调度，需要对内存资源进行“调度”，考虑利用率、公平性和优先级等因素。此外，还需要合理分配磁盘分页带宽，以满足不同进程的需求。</p><h2 id="7-5-Cost-Model"><a href="#7-5-Cost-Model" class="headerlink" title="7.5. Cost Model"></a>7.5. Cost Model</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet19.png"></p><h1 id="8-General-I-O"><a href="#8-General-I-O" class="headerlink" title="8. General I&#x2F;O"></a>8. General I&#x2F;O</h1><h2 id="8-1-What-about-I-O"><a href="#8-1-What-about-I-O" class="headerlink" title="8.1. What about I&#x2F;O?"></a>8.1. What about I&#x2F;O?</h2><ul><li>Without I&#x2F;O, computers are useless (disembodied brains?)</li><li>But… thousands of devices, each slightly different<ul><li>How can we <strong>standardize the interfaces to these devices</strong>?</li></ul></li><li>Devices unreliable: media failures and transmission errors<ul><li>How can we <strong>make them reliable</strong>?</li></ul></li><li>Devices unpredictable and&#x2F;or slow<ul><li>How can we manage them if we don’t know what they will do or how they will perform?</li></ul></li></ul><h2 id="8-2-Visualize-IO"><a href="#8-2-Visualize-IO" class="headerlink" title="8.2. Visualize IO"></a>8.2. Visualize IO</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet20.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet21.png"></p><h2 id="8-3-I-O-Design"><a href="#8-3-I-O-Design" class="headerlink" title="8.3. I&#x2F;O Design"></a>8.3. I&#x2F;O Design</h2><h3 id="Operational-Parameters-for-I-O"><a href="#Operational-Parameters-for-I-O" class="headerlink" title="Operational Parameters for I&#x2F;O"></a>Operational Parameters for I&#x2F;O</h3><ul><li>Data granularity: Byte vs. Block<ul><li>Some devices provide single byte at a time (e.g., keyboard)</li><li>Others provide whole blocks (e.g., disks, networks, etc.)</li></ul></li><li>Access pattern: Sequential vs. Random<ul><li>Some devices must be accessed sequentially (e.g., tape)</li><li>Others can be accessed “randomly” (e.g., disk, cd, etc.)<ul><li>Fixed overhead to start transfers</li></ul></li><li>Some devices require continual monitoring</li><li>Others generate interrupts when they need service</li></ul></li><li>Transfer Mechanism: Programmed IO and DMA</li></ul><h3 id="The-goal-of-the-I-O-Subsystem"><a href="#The-goal-of-the-I-O-Subsystem" class="headerlink" title="The goal of the I&#x2F;O Subsystem"></a>The goal of the I&#x2F;O Subsystem</h3><p>Provide Uniform Interfaces, Despite Wide Range of Different Devices</p><h3 id="Standard-Interfaces-to-Devices"><a href="#Standard-Interfaces-to-Devices" class="headerlink" title="Standard Interfaces to Devices"></a>Standard Interfaces to Devices</h3><ul><li><strong>Block Devices</strong>: e.g. disk drives, tape drives, DVD-ROM<ul><li>Access <strong>blocks of data</strong></li><li>Commands include <code>open()</code>, <code>read()</code>, <code>write()</code>, <code>seek()</code></li><li>Raw I&#x2F;O or file-system access</li><li>Memory-mapped file access possible</li></ul></li><li><strong>Character Devices</strong>: e.g. keyboards, mice, serial ports, some USB devices<ul><li><strong>Single characters at a time</strong></li><li>Commands include <code>get()</code>, <code>put()</code></li><li>Libraries layered on top allow line editing</li></ul></li><li><strong>Network Devices</strong>: e.g. Ethernet, Wireless, Bluetooth<ul><li>Different enough from block&#x2F;character to have own interface</li><li>Unix and Windows include socket interface<ul><li>Separates network protocol from network operation</li><li>Includes select() functionality</li></ul></li><li>Usage: pipes, FIFOs, streams, queues, mailboxes</li></ul></li></ul><h3 id="How-does-User-Deal-with-Timing"><a href="#How-does-User-Deal-with-Timing" class="headerlink" title="How does User Deal with Timing"></a>How does User Deal with Timing</h3><ul><li><strong>Blocking Interface</strong>: “Wait”<ul><li>When request data (e.g. <code>read()</code> system call), put process to sleep until data is ready</li><li>When write data (e.g. <code>write()</code> system call), put process to sleep until device is ready for data</li></ul></li><li><strong>Non-blocking Interface</strong>: “Don’t Wait”<ul><li>Returns quickly from read or write request with count of bytes successfully transferred</li><li>Read may return nothing, write may write nothing</li></ul></li><li><strong>Asynchronous Interface</strong>: “Tell Me Later”<ul><li>When request data, take pointer to user’s buffer, return immediately; later kernel fills buffer and notifies user</li><li>When send data, take pointer to user’s buffer, return immediately; later kernel takes data and notifies user</li></ul></li></ul><h3 id="Transferring-Data-to-from-Controller"><a href="#Transferring-Data-to-from-Controller" class="headerlink" title="Transferring Data to&#x2F;from Controller"></a>Transferring Data to&#x2F;from Controller</h3><ul><li>Programmed I&#x2F;O:<ul><li>Each byte transferred via processor in&#x2F;out or load&#x2F;store</li><li>Pro: Simple hardware, easy to program</li><li>Con: Consumes processor cycles proportional to data size</li></ul></li><li><strong>Direct Memory Access</strong>:<ul><li>Give controller access to memory bus</li><li>Ask it to transfer data blocks to&#x2F;from memory directly</li></ul></li><li>Sample interaction with DMA controller (from OSC book):</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet22.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet23.png"></p><h3 id="I-O-Device-Notifying-the-OS"><a href="#I-O-Device-Notifying-the-OS" class="headerlink" title="I&#x2F;O Device Notifying the OS"></a>I&#x2F;O Device Notifying the OS</h3><ul><li>The OS needs to know when:<ul><li>The I&#x2F;O device has completed an operation</li><li>The I&#x2F;O operation has encountered an error</li></ul></li><li><strong>I&#x2F;O Interrupt</strong>:<ul><li>Device generates an interrupt whenever it needs service</li><li>Pro: handles unpredictable events well</li><li>Con: interrupts relatively high overhead</li></ul></li><li><strong>Polling</strong>:<ul><li>OS periodically checks a device-specific status register<ul><li>I&#x2F;O device puts completion information in status register</li></ul></li><li>Pro: low overhead</li><li>Con: may waste many cycles on polling if infrequent or unpredictable I&#x2F;O operations</li></ul></li><li>Actual devices combine both polling and interrupts<ul><li>For instance – High-bandwidth network adapter:<ul><li>Interrupt for first incoming packet</li><li>Poll for following packets until hardware queues are empty</li></ul></li></ul></li></ul><h3 id="Device-Drivers"><a href="#Device-Drivers" class="headerlink" title="Device Drivers"></a>Device Drivers</h3><ul><li><strong>Device Driver</strong>: Device-specific code in the kernel that interacts directly with the device hardware<ul><li>Supports a standard, internal interface</li><li>Same kernel I&#x2F;O system can interact easily with different device drivers</li><li>Special device-specific configuration supported with the ioctl() system call</li></ul></li><li>Device Drivers typically divided into two pieces:<ul><li><strong>Top half</strong>: accessed in call path from system calls<ul><li>implements a set of <strong>standard, cross-device calls</strong> like open(), close(), read(), write(), ioctl(), strategy()</li><li>This is the kernel’s interface to the device driver</li><li>Top half will start I&#x2F;O to device, may put thread to sleep until finished</li></ul></li></ul></li><li><strong>Bottom half</strong>: run as interrupt routine<ul><li>Gets input or transfers next block of output</li><li>May wake sleeping threads if I&#x2F;O now complete</li></ul></li></ul><h1 id="9-File-System"><a href="#9-File-System" class="headerlink" title="9. File System"></a>9. File System</h1><h2 id="9-1-File"><a href="#9-1-File" class="headerlink" title="9.1. File"></a>9.1. File</h2><h3 id="File-Concept"><a href="#File-Concept" class="headerlink" title="File Concept"></a>File Concept</h3><p>Contiguous logical address space</p><ul><li>OS abstracts from the physical properties of its storage device to define a logical storage unit called file</li><li>Persistent</li><li>OS maps files to physical devices</li></ul><p>Types: Data, Program, Documents</p><h3 id="File-Structure"><a href="#File-Structure" class="headerlink" title="File Structure"></a>File Structure</h3><ul><li>None - sequence of words&#x2F;bytes</li><li>Simple record structure</li><li>Complex structures</li><li>Can simulate last two with first method by inserting appropriate control<br>characters</li><li>Who decides? OS &#x2F; Programs</li></ul><h3 id="File-Attibutes"><a href="#File-Attibutes" class="headerlink" title="File Attibutes"></a>File Attibutes</h3><ul><li>Name</li><li>Identifier</li><li>Type</li><li>Location</li><li>Size</li><li>Protection</li><li>Time, Date, User Identification</li><li>Information about files are kept in the directory structure, maintained on disk</li></ul><h3 id="File-Operations"><a href="#File-Operations" class="headerlink" title="File Operations"></a>File Operations</h3><ul><li>Create</li><li>Write</li><li>Read</li><li>Reposition within file - file seek</li><li>Delete</li><li>Truncate</li><li>Open&#x2F;Close</li></ul><h2 id="9-2-Directory"><a href="#9-2-Directory" class="headerlink" title="9.2. Directory"></a>9.2. Directory</h2><h3 id="Information-in-a-Device-Directory"><a href="#Information-in-a-Device-Directory" class="headerlink" title="Information in a Device Directory"></a>Information in a Device Directory</h3><ul><li>File name</li><li>File type</li><li>Address or location</li><li>Current length</li><li>Maximum length</li><li>Date created, last accessed, last updated</li><li>Owner ID, Protection Information</li></ul><h3 id="Operations-Performed-on-Directory"><a href="#Operations-Performed-on-Directory" class="headerlink" title="Operations Performed on Directory"></a>Operations Performed on Directory</h3><ul><li>Search for a file</li><li>Create a file</li><li>Delete a file</li><li>List a directory</li><li>Rename a file</li><li>Traverse the file system</li></ul><h3 id="Directory-Organization"><a href="#Directory-Organization" class="headerlink" title="Directory Organization"></a>Directory Organization</h3><p>Goals: <strong>Efficiency</strong>, <strong>Naming</strong>, <strong>Grouping</strong></p><h2 id="9-3-File-System"><a href="#9-3-File-System" class="headerlink" title="9.3. File System"></a>9.3. File System</h2><h3 id="Components-of-a-File-System"><a href="#Components-of-a-File-System" class="headerlink" title="Components of a File System"></a>Components of a File System</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet24.png"></p><pre><code class=" mermaid">graph LR  File_Name_Offset --Directory--&gt; File_Number_Offset --Index_Structure--&gt; Storage_Block</code></pre><ul><li>Open performs <strong>Name Resolution</strong><ul><li><strong>Translates pathname into a “file number”</strong></li><li>Used as an “index” to locate the blocks<ul><li>Creates a file descriptor in PCB within kernel</li><li>Returns a “handle” (another integer) to user process</li></ul></li></ul></li></ul><h3 id="Directory"><a href="#Directory" class="headerlink" title="Directory"></a>Directory</h3><ul><li>Basically a hierarchical structure</li><li>Each directory entry is a collection of Files &#x2F; Directories(A link to another entries)</li><li>Each has a name and attributes<ul><li>Files have data</li></ul></li><li>Links (hard links) make it a <strong>DAG</strong>, not just a tree<ul><li>Softlinks (aliases) are another name for an entry</li></ul></li></ul><aside>💡 **Example**: How many disk accesses to resolve “/my/book/count”?<ul><li><p>Read in file header for root (fixed spot on disk)</p></li><li><p>Read in first data block for root</p><ul><li>Table of file name&#x2F;index pairs. Search linearly – ok since directories typically very small</li></ul></li><li><p>Read in file header for “my”</p></li><li><p>Read in first data block for “my”; search for “book”</p></li><li><p>Read in file header for “book”</p></li><li><p>Read in first data block for “book”; search for “count”</p></li><li><p>Read in file header for “count”</p></aside></li><li><p><strong>Current working directory</strong>: Per-address-space pointer to a directory (inode) used for resolving file names</p></li></ul><h3 id="File"><a href="#File" class="headerlink" title="File"></a>File</h3><ul><li>Named permanent storage</li><li>Contains:<ul><li>Data<ul><li>Blocks on disk somewhere</li></ul></li><li>Metadata (Attributes)<ul><li>Owner, size, last opened, …</li><li>Access rights<ul><li>R, W, X</li><li>Owner, Group, Other (in Unix systems)</li><li>Access control list in Windows system</li></ul></li></ul></li></ul></li></ul><h3 id="In-Memory-File-System-Structures"><a href="#In-Memory-File-System-Structures" class="headerlink" title="In-Memory File System Structures"></a>In-Memory File System Structures</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet25.png"></p><ul><li>Open system call:<ul><li>Resolves file name, finds <strong>file control block (inode)</strong></li><li>Makes entries in per-process and system-wide tables</li><li>Returns index (called “file handle”) in open-file table</li></ul></li><li>Read&#x2F;write system calls:<ul><li>Use file handle to locate <strong>inode</strong></li><li>Perform appropriate reads or writes</li></ul></li></ul><h2 id="9-4-Our-First-FileSystem-FAT"><a href="#9-4-Our-First-FileSystem-FAT" class="headerlink" title="9.4. Our First FileSystem: FAT"></a>9.4. Our First FileSystem: FAT</h2><h3 id="FAT-File-Allication-Table"><a href="#FAT-File-Allication-Table" class="headerlink" title="FAT: File Allication Table"></a>FAT: File Allication Table</h3><ul><li>Assume (for now) we have a way to translate a path to a “file number”<ul><li>i.e., a directory structure</li></ul></li><li>Disk Storage is a collection of Blocks<ul><li>Just hold file data:</li><li>offset <code>o = &lt; B, x &gt;</code></li></ul></li><li>E.g.,: <code>file_read 31, &lt; 2, x &gt;</code><ul><li>Index into FAT with file number</li><li>Follow linked list to block</li><li>Read the block from disk into memory</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet26.png"></p><h3 id="FAT-Properties"><a href="#FAT-Properties" class="headerlink" title="FAT Properties"></a>FAT Properties</h3><ul><li>File is collection of disk blocks</li><li>FAT is linked list 1-1 with blocks</li><li>File Number is index of root of block list for the file</li><li>File offset (<code>o = &lt; B, x &gt;</code>)</li><li>Follow list to get block #</li><li>Unused blocks → Marked free (no ordering, must scan to find)</li><li>E.g. <code>file_write(31, &lt; 3, y &gt;)</code><ul><li>Grab free block</li><li>Linking them into file</li></ul></li><li>Grow file by allocating free blocks and linking them in</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet27.png"></p><h3 id="FAT-Assessment"><a href="#FAT-Assessment" class="headerlink" title="FAT Assessment"></a>FAT Assessment</h3><p>FAT32 (32 instead of 12 bits) used in Windows, USB drives, SD…</p><ul><li>Where is FAT stored?<ul><li>On Disk, on boot cache in memory, second (backup) copy on disk</li></ul></li><li>What happens when you format a disk?<ul><li>Zero the blocks, Mark FAT entries “free”</li></ul></li><li>What happens when you quick format a disk?<ul><li>Mark all entries in FAT as free</li></ul></li><li>Simple<ul><li>Can implement in device firmware</li></ul></li></ul><h3 id="FAT-Directories"><a href="#FAT-Directories" class="headerlink" title="FAT Directories"></a>FAT Directories</h3><p>Directory is a file containing <code>&lt;file_name: file_number&gt;</code> mappings</p><ul><li>Free space for new&#x2F;deleted entries</li><li>In FAT: file attributes are kept in directory (!!!)</li><li>Each directory is a linked list of entries</li></ul><p>Where do you find root directory ( “&#x2F;” )?</p><ul><li><strong>At well-defined place on disk</strong></li><li>For FAT, this is at block 2 (there are no blocks 0 or 1)</li><li>Remaining directories are accessed via their file_number</li></ul><h3 id="FAT-Security-Holes"><a href="#FAT-Security-Holes" class="headerlink" title="FAT Security Holes"></a>FAT Security Holes</h3><ul><li>FAT has no access rights</li><li>FAT has no header in the file blocks</li><li>Just gives an index into the FAT to read data</li></ul><h2 id="9-5-Unix-File-System"><a href="#9-5-Unix-File-System" class="headerlink" title="9.5. Unix File System"></a>9.5. Unix File System</h2><h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><ul><li>Original inode format appeared in BSD 4.1<ul><li>Berkeley Standard Distribution Unix</li><li>Similar structure for Linux Ext2&#x2F;3</li></ul></li><li>File Number is index into inode arrays</li><li>Multi-level index structure<ul><li>Great for little and large files</li><li>Asymmetric tree with fixed sized blocks</li></ul></li><li>Metadata associated with the file<ul><li>Rather than in the directory that points to it</li></ul></li><li>UNIX Fast File System (FFS) BSD 4.2 Locality Heuristics:<ul><li>Block group placement</li><li>Reserve space</li></ul></li><li>Scalable directory structure</li></ul><h3 id="Inode-Structure"><a href="#Inode-Structure" class="headerlink" title="Inode Structure"></a>Inode Structure</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet28.png"></p><h3 id="UNIX-BSD-4-2-Problem-1"><a href="#UNIX-BSD-4-2-Problem-1" class="headerlink" title="UNIX BSD 4.2 Problem 1"></a>UNIX BSD 4.2 Problem 1</h3><p>When create a file, don’t know how big it will become (in UNIX, most writes are by appending)</p><ul><li>How much contiguous space do you allocate for a file?</li><li>In BSD 4.2, just find some range of free blocks</li><li>Put each new file at the front of different range</li><li>To expand a file, you first try successive blocks in bitmap, then choose new range of blocks<ul><li>Also in BSD 4.2: store files from same directory near each other</li></ul></li></ul><h3 id="UNIX-BSD-4-2-Problem-2"><a href="#UNIX-BSD-4-2-Problem-2" class="headerlink" title="UNIX BSD 4.2 Problem 2"></a>UNIX BSD 4.2 Problem 2</h3><p>Missing blocks due to rotational delay</p><blockquote><p>Issue: Read one block, do processing, and read next block. In meantime, disk has continued turning: missed next block! Need 1 revolution&#x2F;block!</p></blockquote><ul><li>Solution1: Skip sector positioning (“interleaving”)<ul><li>Place the blocks from one file on every other block of a track: give time for processing to overlap rotation</li><li>Can be done by OS or in modern drives by the disk controller</li></ul></li><li>Solution 2: Read ahead: read next block right after first, even if application hasn’t asked for it yet<ul><li>This can be done either by OS (read ahead)</li><li>By disk itself (track buffers) - many disk controllers have internal RAM that allows them to read a complete track</li></ul></li></ul><h2 id="9-6-Links"><a href="#9-6-Links" class="headerlink" title="9.6. Links"></a>9.6. Links</h2><h3 id="Hard-link"><a href="#Hard-link" class="headerlink" title="Hard link"></a>Hard link</h3><ul><li>Sets another directory entry to contain the file number for the file</li><li>Creates another name (path) for the file</li><li>Each is “first class”</li></ul><h3 id="Soft-link-or-Symbolic-Link-or-Shortcut"><a href="#Soft-link-or-Symbolic-Link-or-Shortcut" class="headerlink" title="Soft link (or Symbolic Link or Shortcut)"></a>Soft link (or Symbolic Link or Shortcut)</h3><ul><li>Directory entry contains the path and name of the file</li><li>Map one name to another name</li></ul><h2 id="9-7-NTFS"><a href="#9-7-NTFS" class="headerlink" title="9.7. NTFS"></a>9.7. NTFS</h2><ul><li>New Technology File System (NTFS)<ul><li>Default on Microsoft Windows systems</li></ul></li><li><strong>Variable length extents</strong><ul><li>Rather than fixed blocks</li></ul></li><li>Everything (almost) is a sequence of <code>attribute:value</code> pairs<ul><li>Meta-data and data</li></ul></li><li>Mix direct and indirect freely</li><li>Directories organized in <strong>B-tree structure</strong> by default</li><li>Master File Table<ul><li>Database with Flexible 1KB entries for metadata&#x2F;data</li><li>Variable-sized attribute records (data or metadata)</li><li>Extend with variable depth tree (non-resident)</li></ul></li><li>Extents – variable length contiguous regions<ul><li>Block pointers cover runs of blocks</li><li>Similar approach in Linux (ext4)</li><li>File create can provide hint as to size of file</li></ul></li><li>journaling for reliability</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet29.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet30.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet31.png"></p><h2 id="9-8-Memory-Mapped-Files"><a href="#9-8-Memory-Mapped-Files" class="headerlink" title="9.8. Memory Mapped Files"></a>9.8. Memory Mapped Files</h2><ul><li>Traditional I&#x2F;O involves explicit transfers between buffers in process address space to&#x2F; from regions of a file<ul><li>This involves multiple copies into caches in memory, plus system calls</li></ul></li><li>What if we could “map” the file directly into an empty region of our address space<ul><li>Implicitly “page it in” when we read it</li><li>Write it and “eventually” page it out</li></ul></li><li>Executable files are treated this way when we exec the process!!</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/OS_Final_Cheatsheet32.png"></p><h2 id="9-9-File-System-Caching"><a href="#9-9-File-System-Caching" class="headerlink" title="9.9. File System Caching"></a>9.9. File System Caching</h2><ul><li>Key Idea: Exploit locality by caching data in memory<ul><li>Name translations: Mapping from paths → inodes</li><li>Disk blocks: Mapping from block address → disk content</li></ul></li><li><strong>Buffer Cache</strong>: Memory used to cache kernel resources, including disk blocks and name translations<ul><li>Can contain “dirty” blocks (blocks yet on disk)</li></ul></li><li>Replacement policy? LRU<ul><li>Can afford overhead of timestamps for each disk block</li><li>Advantages:<ul><li>Works very well for name translation</li><li>Works well in general as long as memory is big enough to accommodate a host’s working set of files.</li></ul></li><li>Disadvantages:<ul><li>Fails when some application scans through file system, thereby flushing the cache with data used only once</li><li>E.g., : <code>find . –exec grep foo &#123;&#125; \;</code></li></ul></li></ul></li><li>Other Replacement Policies?<ul><li>Some systems allow applications to request other policies</li><li>E.g., ‘Use Once’:<ul><li>File system can discard blocks as soon as they are used</li></ul></li></ul></li><li>Cache Size: How much memory should the OS allocate to the buffer cache vs virtual memory?<ul><li>Too much memory to the file system cache → won’t be able to run many applications at once</li><li>Too little memory to file system cache → many applications may run slowly (disk caching not effective)</li><li>Solution: <strong>adjust boundary dynamically</strong> so that the disk access rates for paging and file access are balanced</li></ul></li><li>Read Ahead Prefetching: <strong>fetch sequential blocks early</strong><ul><li>Key Idea: exploit fact that most common file access is sequential by prefetching subsequent disk blocks ahead of current read request (if they are not already in memory)</li><li>Elevator algorithm can efficiently interleave groups of prefetches from<br>concurrent applications</li><li>How much to prefetch?<ul><li>Too many imposes delays on requests by other applications</li><li>Too few causes many seeks (and rotational delays) among concurrent file requests</li></ul></li></ul></li><li>Delayed Writes: <strong>Writes to files not immediately</strong> sent out to disk<ul><li>Instead, <code>write()</code> copies data from user space buffer to kernel buffer (in<br>cache)<ul><li>Enabled by presence of buffer cache: can leave written file blocks in cache<br>for a while</li><li>If some other application tries to read data before written to disk, file system<br>will read from cache</li></ul></li></ul></li><li>Flushed to disk periodically (e.g. in UNIX, every 30 sec)</li><li>Advantages:<ul><li>Disk scheduler can efficiently order lots of requests</li><li>Disk allocation algorithm can be run with correct size value for a file</li><li>Some files need never get written to disk! (e..g temporary scratch files written<br><code>/tmp</code> often don’t exist for 30 sec)</li></ul></li><li>Disadvantages<ul><li>What if system crashes before file has been written out?</li><li>Worse yet, what if system crashes before a directory file has been written<br>out? (lose pointer to inode!)</li></ul></li></ul><h2 id="9-10-Important-Ilities"><a href="#9-10-Important-Ilities" class="headerlink" title="9.10. Important Ilities"></a>9.10. Important Ilities</h2><ul><li><strong>Availability</strong>: the probability that the system can accept and process requests<ul><li>Often measured in “nines” of probability. So, a 99.9% probability is considered “3-nines of availability”</li><li>Key idea here is independence of failures</li></ul></li><li><strong>Durability</strong>: the ability of a system to recover data despite faults<ul><li>This idea is fault tolerance applied to data</li><li>Doesn’t necessarily imply availability: information on pyramids was very durable, but could not be accessed until discovery of Rosetta Stone</li></ul></li><li><strong>Reliability</strong>: the ability of a system or component to perform its required functions under stated conditions for a specified period of time (IEEE definition)<ul><li>Usually stronger than simply availability: means that the system is not only “up”, but also working correctly</li><li>Includes availability, security, fault tolerance&#x2F;durability</li><li>Must make sure data survives system crashes, disk crashes, other problems</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>本科课程</category>
      
      <category>CS130</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CourseReview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2023 年诗词创作</title>
    <link href="/2023/12/31/2023%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/"/>
    <url>/2023/12/31/2023%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="序言"><a href="#序言" class="headerlink" title="序言"></a>序言</h1><p>2023 年我并没有机会去写太多的内容。一方面是因为这一年真的很忙，另一方面是因为，在缺乏阅读的情况下，我总觉得没有文字回荡在自己的脑海里。所幸在年底上了宋词导读课，终于有时间去看一些高质量的诗词作品。</p><p>总体而言，我觉得今年写的虽然不多，但质量还是相当不错的。相比于小时候的作品而言，至少做到了言之有物言之有情，也有了一些我觉得称得上有意思有味道的句子。</p><p>希望 2024 年能写出更好的作品。</p><h1 id="诗词创作"><a href="#诗词创作" class="headerlink" title="诗词创作"></a>诗词创作</h1><h2 id="扬州游"><a href="#扬州游" class="headerlink" title="扬州游"></a>扬州游</h2><p>垂柳寂寂水波青，烟雨秋声入邗城。<br>二十四桥人如水，谁见桥边红药生？</p><h2 id="鹧鸪天-·-病中有感"><a href="#鹧鸪天-·-病中有感" class="headerlink" title="鹧鸪天 · 病中有感"></a>鹧鸪天 · 病中有感</h2><p>寒月已照老病身，谩说思绪更销魂。<br>心事故事何曾问，已非旧地旧时分。</p><p>风猎猎，夜沉沉，无花无酒无故人。<br>不敢凭眺西南望，灯火楼间万点尘。</p><h2 id="临江仙"><a href="#临江仙" class="headerlink" title="临江仙"></a>临江仙</h2><p>半夜杯中温水，十篇纸上新诗。<br>轻描淡写寄谁知？<br>笔停还怅望，不是少年时。</p><p>多少故园心事，朝朝暮暮相思。<br>一溪风月入陈词。<br>柳垂江上影，梅谢雪中枝。</p><h2 id="鹧鸪天-·-读稼轩《代人赋》有感"><a href="#鹧鸪天-·-读稼轩《代人赋》有感" class="headerlink" title="鹧鸪天 · 读稼轩《代人赋》有感"></a>鹧鸪天 · 读稼轩《代人赋》有感</h2><p>细数分明日落迟，随风寒露竟铺石。<br>若非昨夜白头梦，不信人间有相思。</p><p>云摇荡，月参差，尽似催我作新诗。<br>莫问何物无尽处，须知天地有穷时。</p><h2 id="风尘途中有感"><a href="#风尘途中有感" class="headerlink" title="风尘途中有感"></a>风尘途中有感</h2><p>自古人生常轻别，相逢去来一念空。<br>一瞥惊鸿如旧梦，散入流水落花中。</p><h2 id="踏莎行"><a href="#踏莎行" class="headerlink" title="踏莎行"></a>踏莎行</h2><p>骤雨将息，微风渐暖。日高初醒人犹懒。<br>浮生常道愁处多，朦胧又恨欢时短。</p><p>旧梦香消，故人影散。凭栏不是当时晚。<br>也曾举手欲摘星，今夜清尊空又满。</p><h2 id="鹧鸪天-·-海南游"><a href="#鹧鸪天-·-海南游" class="headerlink" title="鹧鸪天 · 海南游"></a>鹧鸪天 · 海南游</h2><p>茶暖楼高与笑谈，棕榈叶里望晴滩。<br>云生风起潮将退，日落沙明月已残。</p><p>听旧事，更经年，青天碧海未桑田。<br>人生易老天难老，多少悲欢一梦间。</p>]]></content>
    
    
    <categories>
      
      <category>诗与词</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【宋词导读 拍照配词】没有人记得，就没有人忘记</title>
    <link href="/2023/12/06/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%AE%8B%E8%AF%8D%E5%AF%BC%E8%AF%BB%E6%8B%8D%E7%85%A7%E9%85%8D%E8%AF%8D/"/>
    <url>/2023/12/06/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%AE%8B%E8%AF%8D%E5%AF%BC%E8%AF%BB%E6%8B%8D%E7%85%A7%E9%85%8D%E8%AF%8D/</url>
    
    <content type="html"><![CDATA[<blockquote><p>欲买桂花同载酒，终不似，少年游。</p></blockquote><p><img src="/imgs/PZPC01.png"></p><p><img src="/imgs/PZPC02.png"></p><p>2021年6月23日的晚上，我在手机的便签中写下：</p><p>只有离开或消逝的事物才被冠以“故”字，因此，久别者才叫“故人”，离开后方为“故乡”。</p><p>直到和好朋友们都分别，我才意识到，这是最后一次以学生的身份坐在那个教室里——这是真正意义上的最后一次。以后我们还会回来很多次，大抵是在功成名就衣锦还乡的时候，可以面带微笑侃侃而谈，可以从容不迫应对自如。那时候老师再也不会对我们的表现挑剔，好朋友们也不必再为彼此的下一次考试而担心。我当时以为，我们会走出曾经的桎梏，走入新的天地，而对“故人”“故乡”的怀念，不过是繁华锦簇中一抹淡淡的、充满深意的忧伤。</p><p>但我错了。2023年8月23日，我和同样的朋友们一起，回到了同样的校园，不一样的只有时间。当并肩爬楼梯的时候，原本已经没那么熟稔的我们又如当年一样嬉笑打闹。见到老师的时候，听到的仍然是熟悉的对彼此的调侃和吹捧，以及一如既往的拘谨。最后行将分别的时候，一种莫大的哀伤萦绕在我心头。我操纵着无人机，留下我们一起微笑的模样，大家一如当年，又不似当年。</p><p>没有什么东西再将我们绑在一起了，我们都有各自的人生；北京、上海、西安……大家已经是天各一方，都有各自新的经历和新的人生了。分别之后我一个人路过学校门口的文具店，习惯性的步入其中，像当年一般挑选了几本不同的笔记本。提着它们，又路过学校门口的时候，我听到了下午上课的铃声，脚步不自觉的快了几分。就在那恍惚的几秒里，我感觉上大学的两年从来没有发生过，我还留在那里，穿着校服，做一个普普通通的学生。可这一切毕竟是幻觉，即使买了一样的东西，走在一样的道路上，可我无法再次踏入同一条河流。</p><p>欲买桂花同载酒——我想，很多年之后，如果我们都老了，又聚在一起，大家都忘了这些年经过了什么，于是我们打闹嬉笑，喊起当年的外号，嘲笑彼此的衰老。这时候，桂花载酒的我们，是否又似故人重游呢？在盛夏的金色阳光里，思绪在不断飘散着，飘散在风中，飘散回昔日的校园里。<strong>没有人记得，也就没有人忘记。</strong></p>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>我的“中国芯”：中国芯片的前世今生</title>
    <link href="/2023/11/27/%E7%A7%91%E7%A0%94%E6%80%9D%E8%80%83/%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/"/>
    <url>/2023/11/27/%E7%A7%91%E7%A0%94%E6%80%9D%E8%80%83/%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F/</url>
    
    <content type="html"><![CDATA[<p><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_00.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_01.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_02.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_03.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_04.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_05.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_06.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_07.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_08.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_09.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_10.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_11.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_12.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_13.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_14.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_15.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_16.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_17.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_18.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_19.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_20.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_21.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_22.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_23.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_24.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_25.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_26.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_27.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_28.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_29.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_30.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_31.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_32.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_33.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_34.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_35.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_36.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_37.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_38.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_39.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_40.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_41.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_42.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_43.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_44.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_45.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_46.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_47.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_48.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_49.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_50.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_51.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_52.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_53.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_54.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_55.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_56.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_57.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_58.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_59.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_60.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_61.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_62.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_63.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_64.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_65.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_66.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_67.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_68.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_69.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_70.png"><br><img src="/files/MG-PPT-IMG/%E6%AF%9B%E6%A6%82%EF%BC%9A%E4%B8%AD%E5%9B%BD%E8%8A%AF%E7%89%87%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F_71.png"></p>]]></content>
    
    
    <categories>
      
      <category>本科课程</category>
      
      <category>毛概</category>
      
    </categories>
    
    
    <tags>
      
      <tag>芯片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【CS130】Midterm Review</title>
    <link href="/2023/11/22/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Midterm-Cheatsheet/"/>
    <url>/2023/11/22/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS130/Midterm-Cheatsheet/</url>
    
    <content type="html"><![CDATA[<h1 id="0-Overview"><a href="#0-Overview" class="headerlink" title="0. Overview"></a>0. Overview</h1><h2 id="0-0-What-is-OS"><a href="#0-0-What-is-OS" class="headerlink" title="0.0. What is OS?"></a>0.0. What is OS?</h2><p><strong>OS is an special layer of Software.</strong></p><ul><li>Provides application SW access to HW resources</li><li>Convenient abstraction of complex HW devices</li><li>Protected access to shared resources</li><li>Security and authentication</li><li>Communication amongst logical entities</li></ul><h2 id="0-1-OS’s-Basic-Behaviors"><a href="#0-1-OS’s-Basic-Behaviors" class="headerlink" title="0.1. OS’s Basic Behaviors"></a>0.1. OS’s Basic Behaviors</h2><ul><li>Translate programs to processes</li><li>Deals with context switch</li><li>Scheduling, Protection</li><li>I&#x2F;O</li><li>Loading</li></ul><h2 id="0-2-OS-Boot"><a href="#0-2-OS-Boot" class="headerlink" title="0.2. OS Boot"></a>0.2. OS Boot</h2><ol><li>Initialization at a fixed memory location</li><li>Bootstrap Loader</li><li>Loads Kernel</li></ol><h2 id="0-3-Three-Roles-Of-OS"><a href="#0-3-Three-Roles-Of-OS" class="headerlink" title="0.3. Three Roles Of OS"></a>0.3. Three Roles Of OS</h2><h3 id="OS-is-an-illusionist"><a href="#OS-is-an-illusionist" class="headerlink" title="OS is an illusionist"></a>OS is an illusionist</h3><ul><li>Provide clean, easy-to-use abstractions of physical resources<ul><li>Infinite memory, dedicated（专心的，一致的） machine</li><li>Higher level objects: FIles, users, messages……</li><li>Masking Limitations, Virtualization</li></ul></li></ul><h3 id="OS-is-a-Referee"><a href="#OS-is-a-Referee" class="headerlink" title="OS is a Referee"></a>OS is a Referee</h3><ul><li>Manage protection, isolation, and sharing of resources</li></ul><h3 id="OS-is-a-glue"><a href="#OS-is-a-glue" class="headerlink" title="OS is a glue"></a>OS is a glue</h3><ul><li>Storage, Networking</li><li>Sharing, authorization</li></ul><h1 id="1-Four-Basic-OS-Concepts"><a href="#1-Four-Basic-OS-Concepts" class="headerlink" title="1. Four Basic OS Concepts"></a>1. Four Basic OS Concepts</h1><h2 id="1-0-Overview"><a href="#1-0-Overview" class="headerlink" title="1.0. Overview"></a>1.0. Overview</h2><h3 id="Abstractions-of-Underlying-HW"><a href="#Abstractions-of-Underlying-HW" class="headerlink" title="Abstractions of Underlying HW"></a>Abstractions of Underlying HW</h3><ul><li>Processor → Thread</li><li>Memory → Address Space</li><li>Disks, SSDs,… → Files</li><li>Networks → Sockets</li><li>Machines → Processes</li></ul><h3 id="Basic-OS-Concepts"><a href="#Basic-OS-Concepts" class="headerlink" title="Basic OS Concepts"></a>Basic OS Concepts</h3><ol><li>Thread<ul><li>Execution Context</li><li>Fully Describes Program State</li><li>PC, Regs, Execution Flags, Stack…</li></ul></li><li>Address Space<ul><li>Set of memory address accessible to program</li><li>May be distinct from memory space of physical machine ( in which case programs operate in a virtual machine )</li></ul></li><li>Process<ul><li>An instance of Running Program</li><li>Protected Address Space + One &#x2F; More Threads</li></ul></li><li>Dual-Mode Operation &#x2F; Protection<ul><li>Only the “System” can access certain resources</li><li>Combined with translation, isolates programs from each other, and isolates OS from programs.</li></ul></li></ol><h2 id="1-1-Thread"><a href="#1-1-Thread" class="headerlink" title="1.1. Thread"></a>1.1. Thread</h2><p>Thread is <strong>single unique execution context.</strong></p><ul><li>A thread is suspended（挂起，即不执行）when its state is not loaded (resident，常驻 ) into the processor.<ul><li>Resident: Register hold the root state of the thread. Include the PC Regs and currently executing instruction.</li></ul></li><li>Illusion of Multiple Processors<ul><li><strong>Threads are virtual cores!</strong></li></ul></li></ul><h3 id="Thread-Control-Block（TCB）"><a href="#Thread-Control-Block（TCB）" class="headerlink" title="Thread Control Block（TCB）"></a>Thread Control Block（TCB）</h3><ul><li>Holds contents of registers when thread is not running</li><li>Contains:<ul><li>Execution State: CPU Registers, Pprogram Counter (PC), Pointer to Stack (SP)</li><li>Scheduling info: State, Priority, CPU time</li><li>Various Pointers (for implementing scheduling queues)</li><li>Pointer to Enclosing Process (PCB)</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled.png"></p><h3 id="Super-scalar-and-Hyper-threading"><a href="#Super-scalar-and-Hyper-threading" class="headerlink" title="Super scalar and Hyper threading"></a>Super scalar and Hyper threading</h3><ul><li>Super scalar processors can execute multiple instructions that are independent.</li><li>Hyper threading duplicates register state to make a second “thread”, allowing more instructions to run.（本质上是通过寄存器的复制来创建额外线程）</li></ul><h2 id="1-2-Address-Space"><a href="#1-2-Address-Space" class="headerlink" title="1.2. Address Space"></a>1.2. Address Space</h2><p>Address space is <strong>the set of accessible addresses</strong> + <strong>state associated with them</strong>.</p><ul><li><p>Space Size?</p><ul><li>For 32 Bit: $2^{32} &#x3D; 4\text{GB}$</li><li>For 64 Bit: $2^{64}\approx 10^{18}\text{Bytes}$</li></ul></li><li><p>Four Segment:</p><ul><li>Stack</li><li>Heap</li><li>Static Data</li><li>Code.</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%201.png"></p><h3 id="OS-Protection"><a href="#OS-Protection" class="headerlink" title="OS Protection?"></a>OS Protection?</h3><ul><li>OS must protect itself from user programs<ul><li>Reliability, Security, Privacy, Fairness</li></ul></li><li>OS must protect user programs from one another</li></ul><p><strong>Simple Protection: Base &amp; Bound</strong></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%202.png"></p><h2 id="1-3-Process"><a href="#1-3-Process" class="headerlink" title="1.3. Process"></a>1.3. Process</h2><p><strong>Execution environment with Restricted Rights</strong>.</p><blockquote><p>Fundamental tradeoff between protection and efficiency</p></blockquote><ul><li>(Protected) Address Space with One or More Threads</li><li>Owns memory ( Address Space )</li><li>Owns file descriptors, file system context, …</li><li>Encapsulate（封装） one or more threads sharing processes resources</li></ul><h3 id="Why-Processes"><a href="#Why-Processes" class="headerlink" title="Why Processes ?"></a>Why Processes ?</h3><ul><li><strong>Protected from each other</strong></li><li><strong>OS protected from them</strong></li></ul><h3 id="Multi-Threaded-Processes"><a href="#Multi-Threaded-Processes" class="headerlink" title="Multi-Threaded Processes"></a>Multi-Threaded Processes</h3><ul><li><strong>Threads encapsulate Concurrency</strong><ul><li>“Active” component（主动的组件，推动程序向前）</li></ul></li><li><strong>Address Spaces encapsulate Protection</strong><ul><li>“Passive ” part（被动的部分，存储机制的提供者）</li><li>Keeps buggy program from trashing the system</li></ul></li></ul><h2 id="1-4-Dual-Mode-Operation"><a href="#1-4-Dual-Mode-Operation" class="headerlink" title="1.4. Dual Mode Operation"></a>1.4. Dual Mode Operation</h2><ul><li>Only the “system” has the ability to access certain resources</li><li>OS and HW protected from user programs</li><li>User programs isolated from one another</li><li>Hardware provides at least two modes ( Kernel Mode and User Mode )<ul><li>Need: A bit of state, Certain operations only permitted in system &#x2F; kernel.</li><li>User → Kernel Transition: Set System Mode, Saves User PC</li><li>Kernel → User Transition: Clear System Mode, Restores Appropriate User PC.</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%203.png"></p><h1 id="2-Process-Management"><a href="#2-Process-Management" class="headerlink" title="2. Process Management"></a>2. Process Management</h1><p>Process: OS abstraction of what is needed to run a single program.</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%204.png"></p><h2 id="2-0-Process-Control-Block-Compare-with-TCB"><a href="#2-0-Process-Control-Block-Compare-with-TCB" class="headerlink" title="2.0. Process Control Block ( Compare with TCB! )"></a>2.0. Process Control Block ( Compare with TCB! )</h2><aside>💡 POSIX: Portable Operation System Interfaces in UNIX.It’s the **Interface for application programmers**</aside><ul><li>Process Status (running, ready, blocked, …)</li><li>Register state (when not ready)</li><li>Process ID (PID), User, Executable, Priority, …</li><li>Execution time, …</li><li>Memory space, translation, …</li><li>Kernel Scheduler maintains a data structure containing the PCBs</li></ul><p>In Context switch, we save the current process’s state to it’s PCB, and reload another process’s state. </p><h2 id="2-1-System-Call"><a href="#2-1-System-Call" class="headerlink" title="2.1. System Call"></a>2.1. System Call</h2><ul><li><strong>Vector through well-defined syscall entry points</strong><ul><li>“定义良好的 System Call 入口“</li><li>Table mapping system call number to handle</li></ul></li><li>Locate argunments<ul><li>In registers or on user stack</li></ul></li><li>Copy arguments<ul><li>From user memory into kernel memory</li><li>Protect kernel from malicious code evading checked</li></ul></li><li>Validate arguments<ul><li>Protect kernel from errors in user code</li></ul></li><li>Copy results back<ul><li>Into user memory</li></ul></li></ul><p>There are also <strong>Hardware Support</strong> for Interrupt Control !</p><ul><li>Not be visible to the user process</li></ul><h2 id="2-2-Web-Server"><a href="#2-2-Web-Server" class="headerlink" title="2.2. Web Server"></a>2.2. Web Server</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%205.png"></p><h2 id="2-3-Process-Creation"><a href="#2-3-Process-Creation" class="headerlink" title="2.3. Process Creation"></a>2.3. Process Creation</h2><h3 id="Fork"><a href="#Fork" class="headerlink" title="Fork"></a>Fork</h3><ul><li>Return &gt; 0<ul><li>Running in <strong>Parent Process</strong></li><li>Return value is PID of new child!</li></ul></li><li>Return &#x3D; 0<ul><li>Running in new <strong>Child Process</strong></li></ul></li><li>Return &lt; 0<ul><li>Error</li></ul></li></ul><p><strong>All state of original process</strong> is <strong>duplicated</strong> in both Parent and Child process</p><blockquote><p>值得注意的是，<code>fork()</code> 后面的所有代码都会被子线程执行<br>考点经常结合逻辑运算符的短路特性。<br>e.g.1. <code>if(fork() || fork()) fork();</code> 就会产生 5 个子线程。<br>e.g.2. <code>fork() &amp;&amp; fork() || fork()</code> 会产生 4 个子线程</p></blockquote><h3 id="Unix-Process-Management"><a href="#Unix-Process-Management" class="headerlink" title="Unix Process Management"></a>Unix Process Management</h3><ul><li><p><code>fork</code></p><ul><li>Create a copy of current process, and start it running</li></ul></li><li><p><code>exec</code></p><ul><li>Change the program being run by the current process</li><li>在 Fork 之后使用，替换 Process 的 Memory Space</li></ul></li><li><p><code>wait</code></p><ul><li>Wait for a process to finish</li><li>Return status information and the pid of terminated process: <code>pid = wait(&amp;status);</code></li></ul></li><li><p><code>kill</code></p><ul><li>Send a signal to another process</li></ul></li><li><p><code>exit</code></p><ul><li>Process asks OS to delete it</li><li>return status data from child to parent</li></ul></li><li><p><code>abort</code></p><ul><li>Process terminate the execution of children process</li></ul></li></ul><h2 id="2-4-Threads"><a href="#2-4-Threads" class="headerlink" title="2.4. Threads"></a>2.4. Threads</h2><p>Motivation: <strong>OS need to be able to handle multiple things at once.</strong></p><h3 id="Thread-States"><a href="#Thread-States" class="headerlink" title="Thread States"></a>Thread States</h3><ul><li>State shared by all thread in process &#x2F; address space<ul><li>Content of memory ( Global Variables, Heap )</li><li>I &#x2F; O State ( File Descriptors, Network connection, … )</li></ul></li><li>State “Private” to each thread<ul><li>Kept in TCB</li><li>CPU Registers ( Include PC! )</li><li>Execution stack<ul><li>Parameters, Temporary Variables</li><li>Return PCs are kept while called procedures are executing.</li></ul></li></ul></li></ul><h3 id="Actual-Thread-Operations"><a href="#Actual-Thread-Operations" class="headerlink" title="Actual Thread Operations"></a>Actual Thread Operations</h3><ul><li><code>thread_fork(func, args)</code><ul><li>Create a new thread to run <code>func(args)</code>.</li></ul></li><li><code>thread_yield()</code><ul><li>Relinquish processor voluntarily.（自愿放弃处理器的使用权或控制权。）</li></ul></li><li><code>thread_join(thread)</code><ul><li>In parent, wait for forked thread to exit, then return</li></ul></li><li><code>thread_exit()</code><ul><li>Quit thread and clean up, wake up joiner if any.</li></ul></li><li>pThreads</li></ul><h3 id="The-core-of-Concurrency"><a href="#The-core-of-Concurrency" class="headerlink" title="The core of Concurrency"></a>The core of Concurrency</h3><p>That’s the Dispatch（调度程序、调度器） Loop!</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">Loop &#123;<br>RunThread();<br>ChooseNextThread();<br>SaveSyayeOfCPU(CurrentTCB);<br>LoadStateOfCPU(NextTCB);<br>&#125;<br></code></pre></td></tr></table></figure><p>Running the thread:</p><ul><li>Load it’s state (Reg, PC, Stack pt) into CPU.</li><li>Load enviroment (VM,…)</li><li>Jump to the PC</li></ul><h3 id="Events-Let-Dispatcherget-control-back"><a href="#Events-Let-Dispatcherget-control-back" class="headerlink" title="Events: Let Dispatcherget control back"></a>Events: Let Dispatcherget control back</h3><ul><li>Internal event: Thread returns control voluntarily<ul><li>Blocking on I&#x2F;O</li><li>Waiting on a “signal” frin itger thread</li><li>Thread executes a <code>yield()</code></li></ul></li><li>External Events: Thread get preempted<ul><li>Interrupts: signals from HW or SW that stop the running code and jump to kernel</li><li>Timer: like an alarm clock that goes off every some may milliseconds</li></ul></li></ul><h2 id="2-5-Comparison"><a href="#2-5-Comparison" class="headerlink" title="2.5. Comparison"></a>2.5. Comparison</h2><table><thead><tr><th></th><th>Same Process</th><th>Diff. Process</th></tr></thead><tbody><tr><td>Switch Overhead</td><td>Low</td><td>High</td></tr><tr><td>Protection Overhead</td><td>Low</td><td>High</td></tr><tr><td>Sharing Overhead</td><td>Low</td><td>High</td></tr></tbody></table><table><thead><tr><th></th><th>Same core</th><th>Diff. Core</th></tr></thead><tbody><tr><td>Switch Overhead</td><td>Low</td><td>High</td></tr><tr><td>Protection Overhead</td><td>Low</td><td>High</td></tr><tr><td>Sharing Overhead</td><td>Low</td><td>High</td></tr></tbody></table><h2 id="2-6-Multi-Thread-Processes"><a href="#2-6-Multi-Thread-Processes" class="headerlink" title="2.6. Multi-Thread Processes"></a>2.6. Multi-Thread Processes</h2><ul><li>PCB points to multiple TCBs</li></ul><h3 id="Multi-Threading-Models"><a href="#Multi-Threading-Models" class="headerlink" title="Multi-Threading Models"></a>Multi-Threading Models</h3><ul><li>Many-to-One<ul><li>User-level threads mapped to single kernel thread</li><li>One thread blocking causes all to block</li></ul></li><li>One-to-One<ul><li>Each User-level thread maps to kernel thread</li><li>Creating a user-level thread creates a kernel thread</li><li>More concurrency, more overhead</li></ul></li><li>Many-to-Many<ul><li>Allows many user-level threads to be mapped to many kernel threads</li><li>Allow OS to create a sufficient number of kernel threads.</li></ul></li></ul><h1 id="3-Synchronization"><a href="#3-Synchronization" class="headerlink" title="3. Synchronization"></a>3. Synchronization</h1><h2 id="3-1-Definitions"><a href="#3-1-Definitions" class="headerlink" title="3.1. Definitions"></a>3.1. Definitions</h2><h3 id="Atomic-Operations"><a href="#Atomic-Operations" class="headerlink" title="Atomic Operations"></a>Atomic Operations</h3><p>An operation that always run to completion or not at all</p><ul><li><strong>Indivisible</strong>: Cannot be stopped in the middle and state cannot bemodified by someone else in the middle.</li><li><strong>Fundamental building block</strong>: If no atomic operations, then have no way for threads to work together.</li></ul><h3 id="Synchronization"><a href="#Synchronization" class="headerlink" title="Synchronization"></a>Synchronization</h3><p>Using atomic operations to ensure cooperation between threads</p><h3 id="Mutual-Exclusion"><a href="#Mutual-Exclusion" class="headerlink" title="Mutual Exclusion"></a>Mutual Exclusion</h3><p>Ensuring that only one thread does a particular thing at a time.</p><h3 id="Critical-Section"><a href="#Critical-Section" class="headerlink" title="Critical Section"></a>Critical Section</h3><p>Piece of code that only one thread can execute at once.</p><h3 id="Lock"><a href="#Lock" class="headerlink" title="Lock"></a>Lock</h3><p>Prevents someone from doing something.</p><ul><li><strong>Lock</strong> before <strong>entering critical section</strong> and before <strong>accessing shared data</strong></li><li><strong>Unlock</strong> when leaving, after accessing shared data</li><li>Wait if locked<ul><li><strong>Important idea: all synchronization involves waiting</strong></li></ul></li></ul><h2 id="3-2-“Too-Much-Milk”"><a href="#3-2-“Too-Much-Milk”" class="headerlink" title="3.2. “Too Much Milk”"></a>3.2. “Too Much Milk”</h2><p>Solved with lock:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">milkLock.Acquire();<br><span class="hljs-keyword">if</span> (noMilk) buy milk;<br>milkLock.Release();<br></code></pre></td></tr></table></figure><blockquote><p>Section of code between <code>Acquire()</code> and <code>Release()</code> called a “Critical Section”</p></blockquote><p>Use lock, the <strong>critical section is very short</strong> !</p><h2 id="3-3-Lock"><a href="#3-3-Lock" class="headerlink" title="3.3. Lock"></a>3.3. Lock</h2><h3 id="Basic-Inplementation"><a href="#Basic-Inplementation" class="headerlink" title="Basic Inplementation"></a>Basic Inplementation</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> value = FREE;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c">Acquire() &#123;<br>disable interrupts;<br><span class="hljs-keyword">if</span> (value == BUSY) &#123;<br>put thread on wait <span class="hljs-built_in">queue</span>;<br>Go to <span class="hljs-title function_">sleep</span><span class="hljs-params">()</span>;<br><span class="hljs-comment">// Enable?</span><br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>value = BUSY;<br>&#125;<br>enable interrupts;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c">Release() &#123;<br>disable interrupts;<br><span class="hljs-keyword">if</span> (anyone on wait <span class="hljs-built_in">queue</span>) &#123;<br>take thread off wait <span class="hljs-built_in">queue</span>;<br>Place on ready <span class="hljs-built_in">queue</span>;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>value = FREE;<br>&#125;<br>enable interrupts;<br>&#125;<br></code></pre></td></tr></table></figure><p>Why do we need to disable interrupts?</p><ul><li>Avoid interruption between checking and setting lock value</li><li>Otherwise two threads could think that they both have lock</li></ul><p>When we enable interrupt?</p><ul><li><p>Before <code>put thread on wait queue;</code> ?</p><ul><li>Release can check the queue and not wakeup thread</li></ul></li><li><p>Between <code>put...</code> and <code>Go to sleep();</code> ?</p><ul><li>Release puts the thread on the ready queue, but the thread still think it needs to go to sleep</li><li>Misses wakeup and still holds lock ( Calls Deadlock! )</li></ul></li><li><p>How to solve?</p></li><li><p>When the sleeping thread wakes up, returns to acquire and re-enable interrupts.</p></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%206.png"></p><h3 id="Atomic-Read-Modify-Write-Instructions"><a href="#Atomic-Read-Modify-Write-Instructions" class="headerlink" title="Atomic Read Modify Write Instructions"></a>Atomic Read Modify Write Instructions</h3><p>These instructions read a value and write a new value atomically</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c">test&amp;<span class="hljs-title function_">set</span><span class="hljs-params">(&amp;address)</span>&#123;<br>result = Mem[address];<br>Mem[address] = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">return</span> result;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-function">compare&amp;<span class="hljs-title">swap</span><span class="hljs-params">(&amp;address, reg1, reg2)</span> </span>&#123;<br><span class="hljs-keyword">if</span> (reg1 == Mem[address]) &#123;<br>Mem[address] = reg2;<br><span class="hljs-keyword">return</span> success;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">return</span> failure;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Impelment-Lock-with-test-set"><a href="#Impelment-Lock-with-test-set" class="headerlink" title="Impelment Lock with test&amp;set"></a>Impelment Lock with test&amp;set</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> value = <span class="hljs-number">0</span>; <span class="hljs-comment">// FREE</span><br>Acquire() &#123;<br><span class="hljs-keyword">while</span>(test&amp;<span class="hljs-built_in">set</span>(value));<br>&#125;<br><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-built_in">Release</span>() &#123;<br>value = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>Busy-Waiting: thread consumes cycles while waiting!</strong></p><ul><li>For multi-processors: every test&amp;set is a write, which makes value ping-pong around in cache (using lots of network BW)</li><li>It will cause Priority Inversion!</li></ul><h3 id="Solution-test-test-set-Multi-Processor-Spin-Locks"><a href="#Solution-test-test-set-Multi-Processor-Spin-Locks" class="headerlink" title="Solution: test&amp;test&amp;set (Multi-Processor: Spin Locks)"></a>Solution: test&amp;test&amp;set (Multi-Processor: Spin Locks)</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> mylock = <span class="hljs-number">0</span>; <span class="hljs-comment">// Free</span><br>Acquire() &#123;<br><span class="hljs-keyword">do</span> &#123;<br><span class="hljs-keyword">while</span>(mylock); <span class="hljs-comment">// Wait until might be free</span><br>&#125; <span class="hljs-keyword">while</span>(test&amp;<span class="hljs-built_in">set</span>(&amp;mylock)); <span class="hljs-comment">// exit if get lock</span><br>&#125;<br>Release() &#123;<br>mylock = <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>Solve Multi-processors Problem.</li><li>Still Busy Waiting!</li></ul><h3 id="Better-Locks-with-test-set"><a href="#Better-Locks-with-test-set" class="headerlink" title="Better Locks with test&amp;set"></a>Better Locks with test&amp;set</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> guard = <span class="hljs-number">0</span>;<br><span class="hljs-type">int</span> value = FREE;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c">Acquire() &#123;<br><span class="hljs-keyword">while</span>(test&amp;<span class="hljs-built_in">set</span>(guard));<br><span class="hljs-keyword">if</span> (value == BUSY) &#123;<br>Put thread on wait <span class="hljs-built_in">queue</span>;<br>Go to <span class="hljs-title function_">sleep</span><span class="hljs-params">()</span> &amp; guard = <span class="hljs-number">0</span>;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>value = BUSY;<br>guard = <span class="hljs-number">0</span>;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c">Release() &#123;<br><span class="hljs-keyword">while</span>(test&amp;<span class="hljs-built_in">set</span>(guard));<br><span class="hljs-keyword">if</span> anyone on wait <span class="hljs-built_in">queue</span> &#123;<br>Take thread off wait <span class="hljs-built_in">queue</span>;<br>Place on ready <span class="hljs-built_in">queue</span>;<br>&#125;<br><span class="hljs-keyword">else</span> &#123;<br>value = FREE;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="3-4-Semaphore"><a href="#3-4-Semaphore" class="headerlink" title="3.4. Semaphore"></a>3.4. Semaphore</h2><p>Semaphore has a non-negative integer value and supports the following two atomic operations:</p><ul><li><p><code>P()</code> : Waits for semaphore to become positive, then decrements it by 1.</p><ul><li>Also called <code>wait()</code></li></ul></li><li><p><code>V()</code> : Increments the semaphore by 1, waking up a waiting P if any.</p><ul><li>Also called <code>signal()</code></li></ul></li></ul><h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">while</span>(S) &#123;<br><span class="hljs-keyword">while</span>(S &lt;= <span class="hljs-number">0</span>);<br>S--;<br>&#125;<br></code></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">signal(S) &#123;<br>S++;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><ul><li>Binary Semaphore (Block&#x2F;Resume Semaphore)<ul><li>Int range only between 0 and 1 (with initial value &#x3D; 1)</li><li>Same as a Mutex Lock.</li></ul></li><li>Counring Semaphore, for scheduling constrainrs ( with initial value &#x3D; 0)<ul><li>Allow thread 1 to wait for thread 2</li></ul></li></ul><h3 id="Lock-vs-Semaphore"><a href="#Lock-vs-Semaphore" class="headerlink" title="Lock vs Semaphore"></a>Lock vs Semaphore</h3><table><thead><tr><th></th><th>Advantage</th><th>Disadvantage</th><th>Use Case</th></tr></thead><tbody><tr><td>Locks</td><td>A lock allows only one thread to enter the section or resource that’s locked at a time, simple to use.</td><td>Locks can lead to problems like deadlocks if not used carefully.</td><td>Locks are more suitable when you need to ensure that only one thread can access a resource at a time, such as writing to a shared source. (Other reasonable answers are acceptable.)</td></tr><tr><td>Semaphores</td><td>Semaphores can control access of multiple threads to one or more resources</td><td>Semaphores can be more complex to use correctly compared to locks, and misuse can lead to problems such as deadlocks and starvation.</td><td>Semaphores are suitable for Producer and Consumer case where there exists threads producing data and threads consuming data. (Other reasonable answers are acceptable.)</td></tr></tbody></table><h2 id="3-5-Monitors"><a href="#3-5-Monitors" class="headerlink" title="3.5. Monitors"></a>3.5. Monitors</h2><p>A lock and zero or more condition variables for managing concurrent access to shared data.</p><ul><li>Lock: Provides Mutual Exclusion to shared data</li><li>Condition Variable: A queue of threads waiting for something inside a critical section</li></ul><h3 id="Condition-Variables"><a href="#Condition-Variables" class="headerlink" title="Condition Variables"></a>Condition Variables</h3><p>Allow <code>wait(&amp;lock)</code> , <code>signal()</code> and <code>broadcast()</code> operations.</p><ul><li><strong>Rule: Must hold lock when doing condition variable ops</strong></li></ul><h2 id="3-6-Deadlock-and-Starvation"><a href="#3-6-Deadlock-and-Starvation" class="headerlink" title="3.6. Deadlock and Starvation"></a>3.6. Deadlock and Starvation</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><ul><li><p>Resources</p><ul><li>Serially reusable resources (CPU cycles, memory space, I&#x2F;O devices, files); Consumable resources (message, buffer of information, interrupts)</li></ul></li><li><p>Comparision</p><ul><li>Deadlock → Starvation</li><li>Starvation can and, Deadlock can’t end without external intervention</li></ul></li><li><p>Deadlock</p><ul><li>Two or more processes are waiting indefinitely for an event that can be caused by only of the waiting processes</li></ul></li><li><p>Starvation</p><ul><li>Indefinite blocking</li><li>A process may never be removed from the semaphore queue in which it’s suspended</li></ul></li></ul><h3 id="Deadlock"><a href="#Deadlock" class="headerlink" title="Deadlock"></a>Deadlock</h3><ul><li>Definitions<ul><li>A process is deadlocked if it’s waiting for an event that will never occur</li></ul></li><li>Conditions:<ul><li>Mutual exclusion</li><li>Hold and wait</li><li>No preemption</li><li>Circular wait</li></ul></li><li>Deadlock Management<ul><li>死锁预防是在<strong>系统设计和资源分配阶段</strong>采取措施防止死锁的发生，而死锁避免是<strong>在运行时</strong>动态地检测和避免可能导致死锁的状态。</li></ul><ol><li>Prevention（预防）<ul><li>Ensure that at least one of the necessary conditions for deadlock cannot hold.</li><li>Mutual Exclusion<ul><li>No issue for sharable resources</li><li>Can not deny this for non-sharable resources</li></ul></li><li>Hold and wait（确保当一个进程请求资源时，它不持有其他资源。）<ul><li>Guarantee that when a process requests a resource, it does not hold other resources</li></ul></li><li>No Preemption（如果一个持有某些资源的进程请求无法立即分配的另一个资源，该进程将释放当前持有的资源，并将被抢占的资源添加到等待列表中。只有当该进程能够重新获取其原有的资源以及请求的新资源时，才会重新启动。）<ul><li>If a process that is holding some resources requests another resource that cannot be immediately allocated to it, the process releases the resources currently being held.</li><li>Preempted resources are added to the list of resources for which the process is waiting</li><li>Process will be restarted only when it can regain its old resources as well as the new<br>  ones that is requesting.</li></ul></li><li>Circular wait（避免无限的资源申请：对所有资源类型进行全局排序，并要求进程按照递增的枚举顺序请求资源。如果持有类型为N的资源，进程只能请求类型大于N的资源。）<ul><li>Impose a total ordering of all resource types</li><li>Require that processes request resources in increasing order of enumeration</li><li>If a resource of type N is held, process can only request resources of types &gt; N</li></ul></li></ul></li><li>Avoidance（避免）<ul><li><p>Require additional Apriori information</p><ul><li>Simplest and Most useful Mode<ul><li>Maximum number of resources</li></ul></li><li>Deadlock-Avoidance algorithm<ul><li>Resource-Allocation state to ensure that there can never be a circular-wait condition</li><li>Resource-Allocation State<ul><li>the number of available and allocated resources</li><li>the maximum demands of the processes</li></ul></li></ul></li></ul></li><li><p>Safe state</p><p>  <img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%207.png"></p><ul><li>When a process requests an available resource, must decide if immediate allocation leaves the system in a safe state</li><li>System in safe sate → there exists a safe sequence of all processes</li><li>Banker’s Algorithm</li></ul></li></ul></li><li>Detection<ul><li>Allow deadlocks to occur but then rely on the operating system to detect the deadlock and deal with it</li></ul></li><li>Recovery<ul><li>Process Termination</li><li>Resource Preemption</li></ul></li></ol></li></ul><h3 id="Bank-Algorithm"><a href="#Bank-Algorithm" class="headerlink" title="Bank Algorithm"></a>Bank Algorithm</h3><p>银行家算法的实质就是<strong>要设法保证系统动态分配资源后不进入不安全状态，以避免可能产生的死锁。</strong>即没当进程提出资源请求且系统的资源能够满足该请求时，系统将判断满足此次资源请求后系统状态是否安全，如果判断结果为安全，则给该进程分配资源，否则不分配资源，申请资源的进程将阻塞。</p><p>银行家算法的执行有个前提条件，即要求进程预先提出自己的最大资源请求，并假设系统拥有固定的资源总量。下面介绍银行家算法所用的主要的数据结构。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%208.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%208.png"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Untitled%209.png"></p>]]></content>
    
    
    <categories>
      
      <category>本科课程</category>
      
      <category>CS130</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CourseReview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【PaperReading】3D Gaussian Splattting</title>
    <link href="/2023/07/20/PaperReading/Paper-3DGaussian/"/>
    <url>/2023/07/20/PaperReading/Paper-3DGaussian/</url>
    
    <content type="html"><![CDATA[<h1 id="3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="3D Gaussian Splatting for Real-Time Radiance Field Rendering"></a>3D Gaussian Splatting for Real-Time Radiance Field Rendering</h1><hr><h2 id="Backgrounds"><a href="#Backgrounds" class="headerlink" title="Backgrounds"></a>Backgrounds</h2><ol><li>Anisotropic（各向异性的） 3D Gaussians</li><li>Splatting Method（抛雪球法）</li><li>Tiling（数据分块）</li></ol><h3 id="Background-01-Anisotropic（各向异性的）-3D-Gaussians"><a href="#Background-01-Anisotropic（各向异性的）-3D-Gaussians" class="headerlink" title="Background 01: Anisotropic（各向异性的） 3D Gaussians"></a>Background 01: Anisotropic（各向异性的） 3D Gaussians</h3><p>$$G(\mathbf x)&#x3D;\exp\big(-\frac{1}{2}(\mathbf x)^T\Sigma^{-1}(\mathbf x)\big)$$</p><ul><li>“位置”用均值 $\mathbf \mu$ 来刻画</li><li>“形状”用 3D 协方差矩阵 $\Sigma$ 来刻画</li></ul><h3 id="Background-02：-Splatting-Method（抛雪球法）"><a href="#Background-02：-Splatting-Method（抛雪球法）" class="headerlink" title="Background 02： Splatting Method（抛雪球法）"></a>Background 02： Splatting Method（抛雪球法）</h3><ul><li>把 Fields 中每个 Voxel（Point）看作一个“能量源“</li><li>每个 Voxel 向图像平面投影</li><li>用以 Voxel 的投影点为中心的重建核将体素的“能量”“扩散”到图像像素上。<ul><li>在这篇论文里，其“重建核”是 3D Gaussian Function</li></ul></li></ul><h3 id="Background-03：-Tiling（数据分块）"><a href="#Background-03：-Tiling（数据分块）" class="headerlink" title="Background 03： Tiling（数据分块）"></a>Background 03： Tiling（数据分块）</h3><ul><li>GPU 上各种内存的访问速度为： <ul><li>$\text{Global memory} &lt;&lt; \text{Shared memory} &lt; \text{Register}$</li></ul></li><li>Global memory 大而慢， Shared memory 小而快</li><li>减少内存访问延迟的一个重要方向就是要<strong>尽量减少 Global memory 的访问</strong></li><li>常见的策略：Tiling —— 将数据分片，然后将每个小分片缓存到 Shared Memory 中。</li></ul><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul><li>NeRFs: Implicit scene representation<ul><li>MLP + Volumetric ray-marching</li><li>“is <strong>costly</strong> and can result in <strong>noise</strong>“</li></ul></li><li>传统的 Explicit Representation<ul><li>优点：适合 GPU&#x2F;CUDA-based rasterization</li><li>缺点：传统重建方法（MVS）在场景的恢复上具有局限性（这是 Neural Rendering 的优势所在）</li></ul></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/overview.png"></p><ul><li>Input: Images + Sparse Point Clouds（Generated by SFM）</li><li>Initialize：Generate 3D Gaussian for every point</li><li>Training：Optimization + Adaptive Density Control</li><li>Rendering：Tile-based Rasterizer</li></ul><h2 id="3D-Gaussian-and-it’s-Projection"><a href="#3D-Gaussian-and-it’s-Projection" class="headerlink" title="3D Gaussian and it’s Projection"></a>3D Gaussian and it’s Projection</h2><p>3D Gaussian 使用 $\mu$ 和 $\Sigma$ 表征：<br>$$G(\mathbf x)&#x3D;\exp\big(-\frac{1}{2}(\mathbf x)^T\Sigma^{-1}(\mathbf x)\big)$$</p><p>其投影变换使用一个 相机矩阵 $W$ 和其 Jacobian $J$：<br>$$\Sigma’ &#x3D; JW\Sigma W^TJ^T$$</p><h2 id="3D-Gaussian’s-Optimization"><a href="#3D-Gaussian’s-Optimization" class="headerlink" title="3D Gaussian’s Optimization"></a>3D Gaussian’s Optimization</h2><ul><li>直接优化协方差矩阵？<ul><li>协方差矩阵只在半正定时才有物理意义</li><li>梯度下降很难确保其有效性</li></ul></li><li>将 $\Sigma$ 分解为 Scale Matrix $S$ 和 Rotation Matrix $R$：<br>$$\Sigma &#x3D; RSS^TR^T$$</li></ul><div style="display: grid; grid-template-columns: 1fr 1fr;">    <div><h3 id="优化对象"><a href="#优化对象" class="headerlink" title="优化对象"></a>优化对象</h3><ul><li><p>Position $\mathbf p$</p></li><li><p>不透明度 $\alpha$</p></li><li><p>协方差 $\Sigma$</p></li><li><p>表征颜色的球谐函数系数 $\text{SH}$</p></div><div></li></ul><h3 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h3><ul><li><p>随机梯度下降</p></li><li><p>对于 $\alpha$ 使用 Sigmoid 激活函数</p></li><li><p>对于 $\Sigma$ 的 Scale 部分，使用指数激活函数</p></li><li><p>Loss 表示为 L1 和 D-SSIM 的组合：</p><ul><li><p>$\mathcal{L} &#x3D; (1-\lambda)\mathcal{L} + \lambda\mathcal{L}_{\text{D-SSIM}}$</p></div></div></li></ul></li></ul><h2 id="Adaptive-Control-of-Gaussians"><a href="#Adaptive-Control-of-Gaussians" class="headerlink" title="Adaptive Control of Gaussians"></a>Adaptive Control of Gaussians</h2><ul><li>每 100 个 iter 进行一次密集化（Densify）</li><li>密集化的同时，移除 $\alpha &lt;\epsilon_\alpha$ 的 Gauss Function</li></ul><h2 id="Densification-Overview"><a href="#Densification-Overview" class="headerlink" title="Densification Overview"></a>Densification Overview</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Densify.png"></p><h2 id="Object-of-Densification"><a href="#Object-of-Densification" class="headerlink" title="Object of Densification"></a>Object of Densification</h2><ul><li>缺失几何特征的区域（”under-reconstruction”）</li><li>Gaussian 覆盖场景中大面积区域的情况（通常对应于”over-reconstruction”</li></ul><p>这两种情况都具有较大的 View-space Positional Gradients。<br>—— 对于**梯度大于 $\tau_{\text{pos}}$ 的 Gaussian **进行密集化！</p><h2 id="Process-of-Densification"><a href="#Process-of-Densification" class="headerlink" title="Process of Densification"></a>Process of Densification</h2><ul><li>对于 Scale 比较小的 Gaussian：<ul><li>Clone 一份，并向梯度方向移动</li></ul></li><li>对于 Scale 比较大的 Gaussian：<ul><li>分割成两个 $\text{Scale}<em>{\text{New}} &#x3D; \text{Scale}</em>{\text{Old}}&#x2F;1.6$ 的小 Gaussian </li><li>小 Gaussian 的位置通过采样确定</li></ul></li></ul><h2 id="Fast-Differentiable-Rasterizer-Overview"><a href="#Fast-Differentiable-Rasterizer-Overview" class="headerlink" title="Fast Differentiable Rasterizer Overview"></a>Fast Differentiable Rasterizer Overview</h2><ul><li>将屏幕分成 $16×16$ 个 tile</li><li>针对 view-frustum 和每个 tile 对 3D Gaussian 进行裁剪。<ul><li>只保留与 view-frustum 相交的置信区间为99%的 Gaussian </li><li>拒绝在极端位置（均值接近 near plane 和远离 view-frustrum）上的 Gaussian</li></ul></li><li>Instantiate each Gaussian<ul><li>每个 Gaussian 分配一个 Key</li><li>Key 由其 View space depth 和 tile ID 组成</li></ul></li><li>Do GPU Radix sort，generate List for each tile</li><li>Rasterization</li></ul><h2 id="GPU-Radix-sort"><a href="#GPU-Radix-sort" class="headerlink" title="GPU Radix sort"></a>GPU Radix sort</h2><ul><li>一种非比较型<strong>整数排序</strong>算法，时间复杂度为 $O(n)$</li><li>在 GPU 中具有成熟的实现</li><li>NVIDIA&#x2F;CUB 库即有现成的实现方式</li></ul><h2 id="Radix-Sort-原理"><a href="#Radix-Sort-原理" class="headerlink" title="Radix Sort 原理"></a>Radix Sort 原理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">RadixSort</span>(<span class="hljs-params">arr: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>):<br>    length = <span class="hljs-built_in">len</span>(<span class="hljs-built_in">str</span>(<span class="hljs-built_in">max</span>(arr)))<br>    <br>    <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(length):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        一共需要进行 length 轮排序</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 每一轮排序内部：用桶 Bucket 装对应第 k 位为 0~9 的数</span><br>        <span class="hljs-comment">## GPU Radix Sort 应该是 二进制长度</span><br>        buckets = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)]<br>        <span class="hljs-keyword">for</span> number <span class="hljs-keyword">in</span> arr:<br>            key = number // (<span class="hljs-number">10</span> ** k) % <span class="hljs-number">10</span><br>            buckets[key].append(number)<br>        <span class="hljs-comment"># 重排 arr</span><br>        arr.clear()<br>        arr = [number <span class="hljs-keyword">for</span> bucket <span class="hljs-keyword">in</span> buckets <span class="hljs-keyword">for</span> number <span class="hljs-keyword">in</span> bucket]<br>    <span class="hljs-keyword">return</span> arr<br></code></pre></td></tr></table></figure><h2 id="Detail-of-Rasterization"><a href="#Detail-of-Rasterization" class="headerlink" title="Detail of Rasterization"></a>Detail of Rasterization</h2><ul><li>Input：每个 tile 拥有一个 list，包含其对应的所有 Gaussian<ul><li>这里的 Gaussian 已经排序完成，可以直接进行 Rasterization</li></ul></li><li>启动一个 thread block<ul><li>首先把数据 Load 到 Shared Memory 中</li><li>对每个像素，按顺序遍历 List 来对 Color 和 $\alpha$ 进行 Integration</li><li>如果像素的 $\alpha &#x3D; 1$ ，终止这个线程</li></ul></li></ul><h2 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h2><ul><li>质量：充分训练后超过 MipNeRF-360</li><li>Inference 速度：130+FPS</li><li>Memory Usage：NeRF Synthetic-Lego：81.7 MB（ Explicit Representation，和场景大小相关）</li></ul><hr><h1 id="My-Discussion"><a href="#My-Discussion" class="headerlink" title="My Discussion"></a>My Discussion</h1><h2 id="Memory-bound-vs-Compute-bound"><a href="#Memory-bound-vs-Compute-bound" class="headerlink" title="Memory bound vs. Compute bound?"></a>Memory bound vs. Compute bound?</h2><blockquote><p>The most compact representations (such as the MLP network in Mildenhall et al. [2020] or the low-rank decomposition in Chen et al. [2022b]) require many FLOPS to query, and the fastest representations (such as the sparse 3D data structures used in Yu et al. [2021] and Hedman et al. [2021]) consume large amounts of graphics memory —— MERF</p></blockquote><ul><li>3D Gaussian 把计算量转化为内存占用，但是在这个 Trade Off 中在其他参数中表现非常优秀</li><li>是一种 Based on GPU 的优化，充分利用了 GPU 的结构特性</li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neural Rendering, Architiecture, Hardware-Software Co-Design</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【PaperReading】NeuRex</title>
    <link href="/2023/06/21/PaperReading/Paper-NeuRex/"/>
    <url>/2023/06/21/PaperReading/Paper-NeuRex/</url>
    
    <content type="html"><![CDATA[<h1 id="NeuRex-A-Case-for-Neural-Rendering-Acceleration"><a href="#NeuRex-A-Case-for-Neural-Rendering-Acceleration" class="headerlink" title="NeuRex: A Case for Neural Rendering Acceleration"></a>NeuRex: A Case for Neural Rendering Acceleration</h1><blockquote><p>Seoul National University 首尔大学</p></blockquote><hr><h1 id="Modern-Neural-Rendering"><a href="#Modern-Neural-Rendering" class="headerlink" title="Modern Neural Rendering"></a>Modern Neural Rendering</h1><h2 id="目前神经渲染中的典型模型"><a href="#目前神经渲染中的典型模型" class="headerlink" title="目前神经渲染中的典型模型"></a>目前神经渲染中的典型模型</h2><ul><li>NeRF: Neural Radiance Field</li><li>NSDF: Neural Signed Distance Field</li><li>GIA: Gigapixel Image Approximation</li><li>NVR: Neural Volume Rendering</li></ul><h2 id="Modern-Neural-Rendering-Pipeline"><a href="#Modern-Neural-Rendering-Pipeline" class="headerlink" title="Modern Neural Rendering Pipeline"></a>Modern Neural Rendering Pipeline</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Pipeline.png"></p><h2 id="Input-Encoding-Multi-Resolution-Hash-Encoding"><a href="#Input-Encoding-Multi-Resolution-Hash-Encoding" class="headerlink" title="Input Encoding: Multi-Resolution Hash Encoding"></a>Input Encoding: Multi-Resolution Hash Encoding</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/NeRFWithNGP.png" alt="h:500"></p><h2 id="Computations-Of-Multi-Resolution-Hash-Encoding"><a href="#Computations-Of-Multi-Resolution-Hash-Encoding" class="headerlink" title="Computations Of Multi-Resolution Hash Encoding"></a>Computations Of Multi-Resolution Hash Encoding</h2><h3 id="Default-Parameters-Of-NGP"><a href="#Default-Parameters-Of-NGP" class="headerlink" title="Default Parameters Of NGP"></a>Default Parameters Of NGP</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/NGPPara.png" alt="h:350"></p><hr><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/NGPFeaturePipeline.png"></p><ul><li>$N_\text{point}$ 个 Input Position</li><li>通过十六个 Hash Table，每个 Table 取 $F&#x3D;2$ 个 Feature<ul><li>形成 $N_\text{Point}\times 32$ 大小的 Input Feature Matrix</li></ul></li><li>以上 Input Feature Matrix 输入 The Density MLP<ul><li>得到 $N_\text{Point}\times 16$ 大小的 Position Feature</li></ul></li><li>Direction 被 （SH）Encoding 成 $N_\text{Point}\times 16$ 大小的 Direction Feature</li><li>以上两个 Feature 被拼成 $N_\text{Point}\times 32$ 大小的 Feature 输入 Color MLP中，输出最终预测的颜色。</li></ul><hr><h1 id="Motivation-Latency-Breakdown"><a href="#Motivation-Latency-Breakdown" class="headerlink" title="Motivation: Latency Breakdown"></a>Motivation: Latency Breakdown</h1><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/LatencyBreakdown.png"></p><p>瓶颈：</p><ul><li>ENC：Hash Encoding</li><li>MLP：Feature Computation</li></ul><hr><h1 id="Observations"><a href="#Observations" class="headerlink" title="Observations"></a>Observations</h1><h2 id="Performance-portability-of-multi-resolution-hash-encodings"><a href="#Performance-portability-of-multi-resolution-hash-encodings" class="headerlink" title="Performance portability of multi-resolution hash encodings"></a>Performance portability of multi-resolution hash encodings</h2><ul><li>尽管哈希表查找的时间复杂度是 $𝑂(1)$，但<strong>这不是一种适合硬件的操作</strong>。<ul><li>理想的 Hash Function 输出 随机的 Index，<strong>没有 Locality</strong><ul><li>会频繁发生 <strong>Off-Chip Memory Access</strong></li></ul></li><li>每次的 Access 仅使用 4 Byte 数据（For $F&#x3D;2$），<strong>带宽大量浪费</strong></li></ul></li></ul><h2 id="一种目前的解决方案"><a href="#一种目前的解决方案" class="headerlink" title="一种目前的解决方案"></a>一种目前的解决方案</h2><ul><li>按层次加载 Hash Table</li><li>每次先遍历所有的点，把这层 Hash Table 对应的 Feature 取出来</li><li>再 Load 下一层 Hash Table</li><li>仍然很慢</li></ul><h2 id="Serialized-execution-of-rendering-pipeline"><a href="#Serialized-execution-of-rendering-pipeline" class="headerlink" title="Serialized execution of rendering pipeline"></a>Serialized execution of rendering pipeline</h2><ul><li>目前花费渲染时间最多的两个主要操作是哈希编码（ENC）和特征计算（MLP）</li><li>这两个主要操作会串行执行<ul><li>ENC对存储带宽要求较高，而MLP需要更多的计算资源</li></ul></li><li>在完成所有 Hash Table 查找之前，MLP 无法进行</li></ul><h2 id="Difference-in-access-characteristics-across-different-levels-of-hash-tables"><a href="#Difference-in-access-characteristics-across-different-levels-of-hash-tables" class="headerlink" title="Difference in access characteristics across different levels of hash tables."></a>Difference in access characteristics across different levels of hash tables.</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/HashTableAccess.png" alt="h:350"></p><ul><li>对于没有哈希冲突的分辨率级别（例如， $𝐿&#x3D;1$ ）<ul><li>哈希表条目仅被分配给体素网格的单个顶点</li><li>一个体素中有大量的采样位置共享相同的顶点</li><li>访问在几个条目上有一定的局部化，并且每个条目的访问次数很高</li></ul></li><li>对于更细的分辨率级别（例如，$𝐿&#x3D;13$ ）<ul><li>访问更均匀（且随机）地分布在哈希表条目之间</li><li>每个条目的访问次数非常低。</li></ul></li></ul><hr><h1 id="NeuRex-Neural-Graphics-Engine"><a href="#NeuRex-Neural-Graphics-Engine" class="headerlink" title="NeuRex: Neural Graphics Engine"></a>NeuRex: Neural Graphics Engine</h1><h2 id="Execution-FLow"><a href="#Execution-FLow" class="headerlink" title="Execution FLow"></a>Execution FLow</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/Exeflow.png"></p><h2 id="Restricted-Hashing"><a href="#Restricted-Hashing" class="headerlink" title="Restricted Hashing"></a>Restricted Hashing</h2><ul><li>将 Input Coordinate Grid 划分为若干 Subgrids <ul><li>每个 Subgrid 都拥有每个层级的大型哈希表的一部分</li></ul></li><li>在处理另一个子网格之前，先完成所有分辨率下的一个子网格的处理。</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/rh.png" alt="h:400"></p><hr><h2 id="Architecture-Overview"><a href="#Architecture-Overview" class="headerlink" title="Architecture Overview"></a>Architecture Overview</h2><div style="display: grid; grid-template-columns: 1fr 1fr;">  <div><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/arc.png"></p>  </div>  <div><p>两个主要模块：</p><ul><li><p>Encoding Engine（EE）</p><ul><li>主要负责 Hash Table Lookups 和 Interpola</li></ul></li><li><p>Tensor Compute Engine（TCE）</p><ul><li>脉动阵列实现 MLP 计算</li></ul></div></div></li></ul><hr><h1 id="Experiment-Evaluation"><a href="#Experiment-Evaluation" class="headerlink" title="Experiment &amp; Evaluation"></a>Experiment &amp; Evaluation</h1><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/SpeedOnGPU.png"></p><h2 id="NeuRex-Performance"><a href="#NeuRex-Performance" class="headerlink" title="NeuRex Performance"></a>NeuRex Performance</h2><ul><li>NeuRex-Server: $2.88\times$</li><li>NeuRex-Edge: $9.17\times$<ul><li>On-Chip Cache 比较小的时候，对 Hash Table 的 Random Access 成为性能瓶颈</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/SpeedUpPart.png" alt="h:450"></p><ul><li>与GPU相比，NeuRex的峰值计算吞吐量较低</li><li>但它执行MLP计算的速度更快<ul><li>全连接层层较小，GPU Tensor Core 的利用率较低，而 NeuRex 中的 TCE 实现了更高的计算利用率</li></ul></li><li>NeuRex 的整体加速度（图13）高于对 ENC 和 MLP 的单独加速度<ul><li>这两个操作在原始执行流中是串行的，而 NeuRex 通过受限制的哈希使它们可以重叠执行。</li></ul></li></ul><hr><h2 id="Rendering-Quality"><a href="#Rendering-Quality" class="headerlink" title="Rendering Quality"></a>Rendering Quality</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/RenderQuality.png" alt="h:420"></p><ul><li>Restricted Hashing 限制了每个 Batch 只能访问单个 Subgrid Buffer 内的输入编码。</li><li>增加哈希表大小对性能影响较小，因为每次只需加载部分 Entries 到芯片上。<ul><li>配置了一个 4 倍大的哈希表（ Ours-LT ；每个级别 8MB ），以进一步提高 PSNR 而不影响性能</li><li>结果显示，Ours-LT在最坏情况下仅导致PSNR轻微下降 $1.1%$ ，在其他几个场景中，甚至产生比 Org-Hash 更高的 PSNR 值。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/ResImages.png" alt="h:350"></p><blockquote><p>DT: Default Table Size</p></blockquote><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/SourceOfGain.png" alt="h:400"></p><ul><li>GC: Grid Cache</li><li>RH: Restricted Hashing</li></ul><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/bachgrid.png"></p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neural Rendering, Architiecture, Hardware-Software Co-Design</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【CS182】Final Review</title>
    <link href="/2023/05/27/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS182/Cheatsheet/"/>
    <url>/2023/05/27/%E6%9C%AC%E7%A7%91%E8%AF%BE%E7%A8%8B/CS182/Cheatsheet/</url>
    
    <content type="html"><![CDATA[<h1 id="CS182-Final-Review"><a href="#CS182-Final-Review" class="headerlink" title="CS182 Final Review"></a>CS182 Final Review</h1><h1 id="Overview-to-Superviced-Learninng"><a href="#Overview-to-Superviced-Learninng" class="headerlink" title="Overview to Superviced Learninng"></a><strong>Overview to Superviced Learninng</strong></h1><h2 id="Statistical-Decision-Theory"><a href="#Statistical-Decision-Theory" class="headerlink" title="Statistical Decision Theory"></a><strong>Statistical Decision Theory</strong></h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet0.png" alt="Untitled"></p><ul><li>Squared error loss: $L(Y, f(X)) &#x3D; (Y-f(X))^2$</li><li>Expected Prediction Error (EPE): $EPE(f) &#x3D; E(Y-f(X))^2 &#x3D; \int(Y-f(x))^2Pr(dx, dy)$<ul><li>Noticed that $Pr(dx, dy) &#x3D; Pr(Y|X)Pr(X)$ , we have $EPE(f) &#x3D; E_XE_Y([Y-f(x)]^2 | X)$</li></ul></li></ul><h2 id="Local-Methods-in-High-Dimensions"><a href="#Local-Methods-in-High-Dimensions" class="headerlink" title="Local Methods in High Dimensions"></a><strong>Local Methods in High Dimensions</strong></h2><h3 id="Curse-of-Dimensionality-维度的诅咒"><a href="#Curse-of-Dimensionality-维度的诅咒" class="headerlink" title="Curse of Dimensionality (维度的诅咒)"></a><strong>Curse of Dimensionality</strong> (维度的诅咒)</h3><ol><li>Local neighborhoods become <strong>increasingly global,</strong> as the number of dimension increases</li><li>In high dimensions, all samples are <strong>close to the edge</strong> of the sample </li><li>Samples <strong>sparsely populate</strong> the input space</li></ol><h3 id="The-Bias-Variance-Decomposition"><a href="#The-Bias-Variance-Decomposition" class="headerlink" title="The Bias-Variance Decomposition:"></a>The Bias-Variance Decomposition:</h3><ol><li><p>Deterministic Case: $\text{MSE}(x_0) &#x3D; \text{Var}(\hat{y_0})+\text{Bias}^2(\hat{y_0})$</p><p>$\begin{aligned}\text{MSE}(x_0) &amp;&#x3D; E[f(x_0)-\hat{y}_0]^2\<br>&amp;&#x3D; E[\hat{y}_0 - E(\hat{y}_0)+E(\hat{y}_0)-f(x_0)]^2\<br>&amp;&#x3D; E\big[(\hat{y}_0-E(\hat{y}_0))^2 + 2(\hat{y}_0-E(\hat{y}_0))(E(\hat{y}_0)-f(x_0))+(E(\hat{y}_0)-f(x_0))^2\big]\<br>&amp;&#x3D;E\big[(\hat{y}_0-E(\hat{y}_0))^2\big]+(E(\hat{y}_0)-f(x_0))^2\<br>&amp;&#x3D;\text{Var}(\hat{y}_0)+\text{Bias}^2(\hat{y}_0)<br>\end{aligned}$</p></li><li><p>Non-deterministic Case</p><p>$$<br>\begin{aligned}\text{EPE}(x_0) &amp;&#x3D; \text{MSE}(x_0)+\sigma^2\<br>&amp;&#x3D; \text{Var}(\hat{y}_0)+\text{Bias}^2(\hat y_0)+\sigma^2\end{aligned}<br>$$</p></li></ol><h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><h2 id="Simple-Multiple-Linear-Regression"><a href="#Simple-Multiple-Linear-Regression" class="headerlink" title="Simple-Multiple Linear Regression"></a>Simple-Multiple Linear Regression</h2><p>For $\hat{\mathbf{y}} &#x3D; \mathbf{X}\beta$, Minimize $\text{RSS}(\beta) &#x3D; (\mathbf{y}-\mathbf{X}\beta)^T(\mathbf{y}-\mathbf{X}\beta)$</p><ul><li>$\displaystyle\frac{\partial\text{RSS}}{\partial\beta} &#x3D; -2\mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta) &#x3D; 0 \Rightarrow \mathbf{X}^T(\mathbf{y}-\mathbf{X}\beta) &#x3D; 0$</li></ul><p>So we have $\hat\beta &#x3D; (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$</p><h2 id="Gauss-Markov-Theorem"><a href="#Gauss-Markov-Theorem" class="headerlink" title="Gauss-Markov Theorem"></a>Gauss-Markov Theorem</h2><p>The least squares estimator has the lowest sampling variance within the class of linear unbiased estimators.</p><blockquote><p>最小二乘估计器在线性无偏估计器类中具有最低的抽样方差。</p></blockquote><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet1.png" alt="Untitled"></p><h2 id="Ridge-Regression"><a href="#Ridge-Regression" class="headerlink" title="Ridge Regression"></a>Ridge Regression</h2><p>对 Regression Coefficients 进行收缩（Shrink）：</p><p>$$<br>\hat{\beta}^{\text{ridge}} &#x3D; \text{argmin}<em>\beta<br>\left\lbrace\sum</em>{i&#x3D;1}^N(y_i-\beta_0-\sum_{j&#x3D;1}^p x_{ij}\beta_j)^2 + \lambda\sum_{j&#x3D;1}^p\beta_j^2\right\rbrace<br>$$</p><p>另一个等价的表述是：</p><p>$$<br>\argmin_\beta\sum_{i&#x3D;1}^N\left(y_i-\beta_0-\sum_{i&#x3D;1}^px_{ij}\beta_j\right)^2\quad\text{subject to }\sum_{j&#x3D;1}^p\beta_j\leq t<br>$$</p><p>其中的损失项变为：</p><p>$$<br> ⁍<br>$$</p><p>求导令之为 0，得到： $\beta^{\text{ridge}} &#x3D; (\mathbf X^T\mathbf X + \lambda\mathbf{I}_p)^{-1}\mathbf X^T\mathbf y$</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet2.png" alt="Untitled"></p><h2 id="The-Lasso"><a href="#The-Lasso" class="headerlink" title="The Lasso"></a>The Lasso</h2><p>岭回归的 L2-Loss $\displaystyle ||\beta||<em>2 &#x3D; \sum</em>{j&#x3D;1}^p|\beta_j|^2$ 变为 L1-Loss $\displaystyle||\beta||<em>1 &#x3D; \sum</em>{j&#x3D;1}^p |\beta_j|$</p><h1 id="Linear-Classification"><a href="#Linear-Classification" class="headerlink" title="Linear Classification"></a>Linear Classification</h1><h2 id="Linear-regression-of-an-indicator-matrix"><a href="#Linear-regression-of-an-indicator-matrix" class="headerlink" title="Linear regression of an indicator matrix"></a><strong>Linear regression of an indicator matrix</strong></h2><p><strong>Categorical output variable</strong> $𝐺$ <strong>with values from</strong> $\mathcal G &#x3D; \lbrace1, … ,𝐾\rbrace$ <strong>.</strong></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet3.png" alt="Untitled"></p><ul><li><p>The zero-one loss $L(k, l) &#x3D; \begin{cases}1,&amp;k\neq l\0,&amp;k&#x3D;l\end{cases}$</p></li><li><p>EPE with $Pr(G, X)$: $\text{EPE} &#x3D; E[L(G,\hat G(X))]$</p></li><li><p>Pointwise minimize leads to:</p><p>$$<br>\hat G(x) &#x3D; \argmin_{k\in\mathcal G}\sum_{l&#x3D;1}^KL(K,l)Pr(G&#x3D;l|X&#x3D;x) &#x3D; \argmax_{k\in\mathcal G}Pr(G&#x3D;k|X&#x3D;x)<br>$$</p></li></ul><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>Model the posterior $Pr(G&#x3D;k|X&#x3D;x)$ based on Bayes Theorem</p><p>The Posterior:</p><p>$$<br>Pr(G&#x3D;k|X&#x3D;x) &#x3D; \frac{Pr(X&#x3D;x|G&#x3D;k)Pr(G&#x3D;k)}{Pr(X&#x3D;x)}&#x3D;\frac{Pr(X&#x3D;x|G&#x3D;k)Pr(G&#x3D;k)}{\sum_{l&#x3D;1}^K Pr(X&#x3D;x|G&#x3D;l)Pr(G&#x3D;l)}<br>$$</p><p>其中， $G&#x3D;k$ 时候 $X$ 的密度为 $f_k(x) &#x3D; Pr(X&#x3D;x|G&#x3D;k)$，而先验有 $\pi_k &#x3D; Pr(G&#x3D;k)$</p><p>$$<br>Pr(G&#x3D;k|X&#x3D;x)&#x3D;\frac{f_k(x)\pi_k}{\sum_{l&#x3D;1}^K f_l(x)\pi_l}<br>$$</p><p>****It produces LDA, QDA (quadratic DA), MDA (mixture DA), kernel DA and naive Bayes, under various assumptions on $f_k(x)$</p><h2 id="LDA-Linear-Discriminant-Analysis"><a href="#LDA-Linear-Discriminant-Analysis" class="headerlink" title="LDA: Linear Discriminant Analysis"></a>LDA: Linear Discriminant Analysis</h2><h3 id="Assumptions-in-LDA"><a href="#Assumptions-in-LDA" class="headerlink" title="Assumptions in LDA"></a>Assumptions in LDA</h3><ul><li><p>Model each class density as <strong>Multivariate Gaussian</strong></p><p>$$<br>f_k(x)&#x3D;\frac{1}{(2\pi)^{p&#x2F;2}|\Sigma_k|^{1&#x2F;2}}\exp\left(-\frac{1}{2}(x-\mu_k)^T\Sigma_l^{-1}(x-\mu_k)\right)<br>$$</p></li><li><p>Assume the classes share a common covariance $\Sigma_k &#x3D; \Sigma, \forall k$</p></li></ul><h3 id="Compare-two-classes-k-and-l"><a href="#Compare-two-classes-k-and-l" class="headerlink" title="Compare two classes $k$ and $l$"></a>Compare two classes $k$ and $l$</h3><p>$$<br>\begin{aligned}\log\frac{Pr(G&#x3D;k|X&#x3D;x)}{Pr(G&#x3D;l|X&#x3D;x)} &amp;&#x3D; \log\frac{f_k(x)}{f_l(x)}+\log\frac{\pi_k}{\pi_l}\<br>&amp;&#x3D;\log\frac{\pi_k}{\pi_l}-\frac{1}{2}(\mu_k+\mu_l)^T\Sigma^{-1}(\mu_k-\mu_l)+x^T\Sigma^{-1}(\mu_k-\mu_l)\end{aligned}<br>$$</p><blockquote><p>二次项由于共同的协方差而消失</p></blockquote><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet4.png" alt="Untitled"></p><h2 id="QDA-Quadratic-Discriminant-Analysis"><a href="#QDA-Quadratic-Discriminant-Analysis" class="headerlink" title="QDA: Quadratic Discriminant Analysis"></a>QDA: Quadratic Discriminant Analysis</h2><p>Assume that each class has a specific covariance $\Sigma_k$</p><p>Discriminant Functions:</p><p>$$<br>\delta_k(x)&#x3D;-\frac{1}{2}\log|\Sigma_k|-\frac{1}{2}(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)+\log\pi_k<br>$$</p><h1 id="Probability-and-Estimator"><a href="#Probability-and-Estimator" class="headerlink" title="Probability and Estimator"></a>Probability and Estimator</h1><h2 id="MLE-Maximum-Likelihood-Estimate"><a href="#MLE-Maximum-Likelihood-Estimate" class="headerlink" title="MLE: Maximum Likelihood Estimate"></a>MLE: Maximum Likelihood Estimate</h2><p>Choose $\theta$ that maximizes probability of observed data $\mathcal D$</p><p>$$<br>\hat{\theta} &#x3D; \argmax_\theta P(\mathcal D|\theta)<br>$$</p><h2 id="MAP-Maximum-a-Posterior"><a href="#MAP-Maximum-a-Posterior" class="headerlink" title="MAP: Maximum a Posterior"></a>MAP: Maximum a Posterior</h2><p>Choose $\theta$ that is most probable given prior probability and the data </p><p>$$<br>\begin{align}<br>\hat{\theta} &amp;&#x3D; \argmax_\theta P(\theta|\mathcal D)\<br>&amp;&#x3D; \argmax_\theta \frac{P(\mathcal D|\theta)P(\theta)}{P(\mathcal D)}<br>\end{align}<br>$$</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet5.png" alt="Untitled"></p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet6.png" alt="Untitled"></p><h2 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h2><ul><li>Train Naive Bayes:<ul><li>for each value $y_k$<ul><li>estimate $\pi_k \equiv P(Y&#x3D;y_k)$</li><li>for each value $x_{ij}$ of each attribute $X_i$<ul><li>estimate $\theta_{ijk}\equiv P(X_i &#x3D; x_{ij}|Y&#x3D;y_k)$</li></ul></li></ul></li></ul></li><li>Classify<ul><li>$Y^{\text{new}} \leftarrow \argmax_{y_k}P(Y&#x3D;y_k)\prod_iP(X_i^{\text{new}}|Y&#x3D;y_k)$</li><li>$Y^{\text{new}}\leftarrow \argmax_{y_k} \pi_k\prod_i\theta_{ijk}$</li></ul></li></ul><h2 id="Estimate-Parameters"><a href="#Estimate-Parameters" class="headerlink" title="Estimate Parameters"></a>Estimate Parameters</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet7.png" alt="Untitled"></p><h2 id="Continuous-X-i-Gaussian-Naive-Bayes"><a href="#Continuous-X-i-Gaussian-Naive-Bayes" class="headerlink" title="Continuous $X_i$ (Gaussian Naive Bayes)"></a>Continuous $X_i$ (Gaussian Naive Bayes)</h2><p>Assume:</p><p>$$<br>P(X_i&#x3D;x|Y&#x3D;y_k)&#x3D;\frac{1}{\sigma_{ik}\sqrt{2\pi}}\exp\left(\frac{-(x-\mu_{ik})^2}{2\sigma_{ik}^2}\right)<br>$$</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet8.png" alt="Untitled"></p><h1 id="Kernel-Method-SVM"><a href="#Kernel-Method-SVM" class="headerlink" title="Kernel Method &amp; SVM"></a>Kernel Method &amp; SVM</h1><h2 id="The-online-Learning-Model-Perceptron"><a href="#The-online-Learning-Model-Perceptron" class="headerlink" title="The online Learning Model: Perceptron"></a>The online Learning Model: Perceptron</h2><h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><ul><li>Set $t&#x3D;1$, start with all zero vector $w_1$</li><li>Given example 𝑥, predict positive iff $w_t\cdot x\geq 0$</li><li>On a mistake, update:<ul><li>Mistake on positive, then update $w_{t+1}\leftarrow w_t+x$</li><li>Mistake on negative, then update $w_{t+1}\leftarrow w_t-x$</li></ul></li><li>Note: $w_t &#x3D; a_{i1}x_{i1}+\cdots + a_{ik}x_{ik}$</li></ul><h2 id="Geometric-Margin"><a href="#Geometric-Margin" class="headerlink" title="Geometric Margin"></a>Geometric Margin</h2><ul><li>Definition: The <strong>margin</strong> of example $𝑥$ w.r.t. a linear sep. $𝑤$ is the distance from $𝑥$ to the plane $w\cdot x&#x3D;0$</li><li>The <strong>margin $\gamma_w$</strong> of a set of examples $𝑆$ w.r.t. a linear separator $𝑤$ is the smallest margin over points $𝑥∈𝑆$.</li><li>The margin $\gamma$ of a examples $S$ is the <strong>maximum</strong> $\gamma_w$ over all linear seps $w$</li></ul><h2 id="Mistake-Bound"><a href="#Mistake-Bound" class="headerlink" title="Mistake Bound"></a>Mistake Bound</h2><p>Theorem: If data linearly separable by margin $\gamma$ and points inside a ball of radius $𝑅$, then Perceptron makes $≤ 𝑅&#x2F;\gamma^2$ mistakes.</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet9.png" alt="Untitled"></p><h2 id="SVMs"><a href="#SVMs" class="headerlink" title="SVMs"></a>SVMs</h2><p>Directly optimize for the maximum margin separator:</p><ul><li>Input: $S&#x3D;\lbrace(x_1,y_1),\dots,(x_m,y_m)\rbrace$</li><li>Maximize $\gamma$ under:<ul><li>$||w||^2 &#x3D; 1$</li><li>$\forall i, y_iw\cdot x_i\geq \gamma$</li></ul></li></ul><p>让 $w’ &#x3D; \frac{w}{\gamma}$，把优化问题转化成凸问题：</p><ul><li>Maximize $||w’||^2$ under $\forall i, y_iw’\cdot x_i\geq 1$</li><li>If data isn’t perfectly linearly separable?<ul><li>Replace “# mistakes” with upper bound called “hinge loss”</li><li>Minimize $||w||^2+C\sum_i\xi_i$ s.t. $\forall i, y_iw\cdot x_i\geq 1-\xi_i, \xi_i \geq 0$</li></ul></li></ul><h3 id="Lagrangian-Dual-of-SVMs"><a href="#Lagrangian-Dual-of-SVMs" class="headerlink" title="Lagrangian Dual of SVMs"></a>Lagrangian Dual of SVMs</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet10.png" alt="Untitled"></p><h2 id="Kernels"><a href="#Kernels" class="headerlink" title="Kernels"></a>Kernels</h2><p>$K(⋅,⋅)$ is a kernel if it can be viewed as a legal definition of inner product:</p><p>$$<br>\exists \phi:X\rightarrow \mathbb R^N,\text{ s.t. }K(x,z)&#x3D;\phi(x)\cdot\phi(z)<br>$$</p><h3 id="Theorem-Mercer"><a href="#Theorem-Mercer" class="headerlink" title="Theorem (Mercer)"></a><strong>Theorem (Mercer)</strong></h3><p>K is a kernel if and only if:</p><ul><li>K is symmetric</li><li>For any set of training points $𝑥_1, 𝑥_2, … , 𝑥_𝑚$ and for any $𝑎_1, 𝑎_2, … , 𝑎_𝑚 ∈ \mathbb R$, we have:</li></ul><p>$$<br>\sum_{i,j}a_ia_jK(x_i,x_j)\geq 0\<br>a^TKa\geq 0<br>$$</p><p>I.e., $K&#x3D;(K(x_i,x_j))_{i,j &#x3D; 1,…,n}$ is positive semi-definite</p><h3 id="Kernels-1"><a href="#Kernels-1" class="headerlink" title="Kernels"></a>Kernels</h3><ul><li>Linear: $K(x,z)&#x3D;x\cdot z$</li><li>Polynomial: $K(x,z)&#x3D;(x\cdot z)^2$ or $K(x,z)&#x3D;(1+x\cdot z)^d$</li><li>Gaussian: $K(x,z)&#x3D;\exp\left[-\frac{||x-z||^2}{2\sigma^2}\right]$</li><li>Laplace: $K(x,z)&#x3D;\exp\left[-\frac{||x-z||}{2\sigma^2}\right]$</li></ul><h1 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h1><h2 id="反向传播四公式"><a href="#反向传播四公式" class="headerlink" title="反向传播四公式"></a>反向传播四公式</h2><h3 id="BP1"><a href="#BP1" class="headerlink" title="BP1"></a>BP1</h3><p>If $Y&#x3D;\sigma(X)$, then:</p><p>$$<br>\frac{\partial L}{\partial X}&#x3D;\frac{\partial L}{\partial Y}\odot \sigma’(x)<br>$$</p><p>Where $\odot$ means element-wise product</p><h3 id="BP2-3-4"><a href="#BP2-3-4" class="headerlink" title="BP2 &amp; 3 &amp; 4"></a>BP2 &amp; 3 &amp; 4</h3><p>If $Y&#x3D;W\cdot X+B$</p><p>$$<br>\frac{\partial L}{\partial X}&#x3D;W^T\cdot \frac{\partial L}{\partial Y}<br>$$</p><p>$$<br>\frac{\partial L}{\partial B}&#x3D;\frac{\partial L}{\partial Y}<br>$$</p><p>$$<br>\frac{\partial L}{\partial W}&#x3D;\frac{\partial L}{\partial Y}\cdot X^T<br>$$</p><h3 id="推导的核心"><a href="#推导的核心" class="headerlink" title="推导的核心"></a>推导的核心</h3><p>考虑： $y_i &#x3D; w_{i1}x_1+w_{i2}x_2+\cdots+w_{in}x_n + b_i$</p><p>$$<br>\frac{\partial y_i}{\partial w_{ij}}&#x3D;x_j,\quad \frac{\partial y_i}{\partial x_j}&#x3D;w_{ij},\quad \frac{\partial y_i}{\partial b_i} &#x3D; 1<br>$$</p><h2 id="常用损失函数的导数"><a href="#常用损失函数的导数" class="headerlink" title="常用损失函数的导数"></a>常用损失函数的导数</h2><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>If $X&#x3D;[x_1,\cdots, x_n], Y&#x3D;\text{SoftMax}(X)&#x3D;[y_1,\cdots, y_n]$</p><p>Thus $\displaystyle y_i &#x3D; \frac{e^{x_i}}{\sum_{j&#x3D;1}^ne^{x_i}}$ and obviously $\displaystyle \sum_{i&#x3D;1}^n y_i &#x3D; 1$</p><p>Thus we have:</p><p>$$<br>\frac{\partial y_i}{\partial x_j}&#x3D;\begin{cases}y_i(1-y_i),&amp;i&#x3D;j\-y_iy_j,&amp;u\neq j\end{cases}<br>$$</p><p>It’s equal to:</p><p>$$<br>\frac{\partial Y}{\partial X}&#x3D;\text{diag}(Y)-Y^TY<br>$$</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>We have $\sigma(x)&#x3D;\text{sigmoid}(x)&#x3D;\frac{1}{1+e^{-x}}$</p><p>$$<br>\sigma’(x)&#x3D;\sigma(x)(1-\sigma(x))<br>$$</p><h3 id="Softmax-with-交叉熵："><a href="#Softmax-with-交叉熵：" class="headerlink" title="Softmax with 交叉熵："></a>Softmax with 交叉熵：</h3><p>$$<br>L&#x3D;-\sum_k \hat y_k\log y_k<br>$$</p><p>We have:</p><p>$$<br>\frac{\partial L}{\partial X} &#x3D; Y-\hat Y<br>$$</p><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>We have $\displaystyle\tau(x)&#x3D;\tanh(x)&#x3D;\frac{e^x-e^{-x}}{e^x+e^{-x}}$</p><p>$$<br>\tau’(x)&#x3D;1-\tau^2(x)<br>$$</p><h1 id="Dimension-Reduction-PCA"><a href="#Dimension-Reduction-PCA" class="headerlink" title="Dimension Reduction: PCA"></a>Dimension Reduction: PCA</h1><p>Denoted that $v_1,\dots, v_d$ are the d principal components, $v_i\cdot v_j &#x3D; \begin{cases}1,&amp;i&#x3D;j\0,&amp;i\neq j\end{cases}$</p><p>Let $X&#x3D;[x_1,\dots,x_n]$ (Columns are the datapoints)</p><p>Maximizes sample variance of projected data</p><p>$$<br>\frac{1}{n}\sum_{i&#x3D;1}^n(\mathbf v^Tx_i)^2&#x3D;\mathbf v^T\mathbf X\mathbf X^T\mathbf v\text{ s.t. }\mathbf v^T\mathbf v &#x3D; 1<br>$$</p><p>Lagrangian: $\argmax_{\mathbf v}\mathbf v^T \mathbf X\mathbf X^T\mathbf v-\lambda \mathbf v^T\mathbf v$</p><p>We finally have $(\mathbf X\mathbf X^T -\lambda\mathbf I)\mathbf v&#x3D;0$, $(\mathbf X \mathbf X^T)\mathbf v &#x3D; \lambda \mathbf v$</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet11.png" alt="Untitled"></p><aside>💡 这里的 $\mathbf v^T\mathbf X$ 是投影，再乘上 $\mathbf v$ 就是 在投影上的向量。</aside><ul><li>The eigenvalue $\lambda$ denotes the amount of variability captured along that dimension (aka amount of energy along that dimension).</li><li>Zero eigenvalues indicate no variability along those directions $\Rightarrow$ data lies exactly on a linear subspace</li><li>Only keep data projections onto principal components with non-zero eigenvalues, say $v_1, … , v_k$, where $k&#x3D;\text{rank}(\mathbf X\mathbf X^T)$</li></ul><h1 id="Clustering-KMeans"><a href="#Clustering-KMeans" class="headerlink" title="Clustering: KMeans"></a>Clustering: KMeans</h1><h2 id="Denotions"><a href="#Denotions" class="headerlink" title="Denotions"></a>Denotions</h2><ul><li>Given a sample $\mathcal X&#x3D;\lbrace\mathbf x^t\rbrace_{t&#x3D;1}^N$</li><li>Find $k$ reference vectors $\mathbf m_j$ which best represent the data</li></ul><h2 id="Encoding-Decoding"><a href="#Encoding-Decoding" class="headerlink" title="Encoding&#x2F;Decoding"></a>Encoding&#x2F;Decoding</h2><p>Each data point $\mathbf x^t$ is represented by the index $i$ **of the nearest reference vector $i&#x3D;\argmin_j||\mathbf x^t-\mathbf m_j||$</p><p>We can use labels $\mathbf b^t$ for $\mathbf x^t$ as:</p><p>$$<br>b_i^t&#x3D;\begin{cases}1&amp;\text{if }i&#x3D;\argmin_j||\mathbf x^t-\mathbf m_j||\<br>0&amp;\text{otherwise}\end{cases}<br>$$</p><p>The Total Reconstruction Error:</p><p>$$<br>E(\lbrace\mathbf n_i\rbrace_{i&#x3D;1}^k|\mathcal X)&#x3D;\sum_t\sum_ib_i^t||\mathbf x^t-\mathbf m_i||^t<br>$$</p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><p>$$\argmin_{\lbrace\mathbf{m}<em>i\rbrace</em>{i&#x3D;1}^k,\lbrace\mathbf{b}^t\rbrace_{t&#x3D;1}^N}\sum_t\sum_i b_{i}^{t}||\mathbf{x}^t-\mathbf{m}_i||^2\quad$$</p><p>However, since $b_i$ also depends on $\mathbf m_i$ , the optimization problem cannot be solved analytically, but <strong>iteratively</strong></p><h3 id="Algorithm-1"><a href="#Algorithm-1" class="headerlink" title="Algorithm"></a>Algorithm</h3><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet12.png" alt="Untitled"></p><h1 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h1><h2 id="Basic-Problem"><a href="#Basic-Problem" class="headerlink" title="Basic Problem"></a>Basic Problem</h2><p>$$<br>\argmin_{x\in\mathbb R^n}f(x)<br>$$</p><p>Iteration: $x^{r+1}&#x3D;x^r-\gamma_r\cdot\nabla f(x^r)$</p><h2 id="Convexity"><a href="#Convexity" class="headerlink" title="Convexity"></a>Convexity</h2><p>$$<br>f(\lambda(x)+(1-\lambda)y)\leq \lambda f(x)+(1-\lambda)f(y)\<br>f(x)\geq f(y)+\nabla f(y)^T(x-y)\<br>\nabla^2f(x)\geq 0<br>$$</p><h2 id="L-smooth"><a href="#L-smooth" class="headerlink" title="L-smooth"></a>L-smooth</h2><p>$$<br>||\nabla f(x)-\nabla f(y)||\leq  L||x-y||<br>$$</p><h2 id="Descemdent-Lemma"><a href="#Descemdent-Lemma" class="headerlink" title="Descemdent Lemma"></a>Descemdent Lemma</h2><p>$$<br>|f(x)-f(y)-\nabla f(y)^T(x-y)|\leq \frac{L}{2}||x-y||^2<br>$$</p><p>If $f$ twice-differentiable, L-smooth $\Leftrightarrow$ $\nabla^2f(x)\leq LI, \quad\mathbf d^T\nabla^2 f(x)\mathbf d\preceq L||\mathbf d||^2,\forall \mathbf d$</p><h2 id="Convergence-Analysis"><a href="#Convergence-Analysis" class="headerlink" title="Convergence Analysis"></a>Convergence Analysis</h2><p>Optimality measure $M(x^r)$</p><ul><li>Convex: $||x^r-x^*||$ or $f(x^r)-f^*$</li><li>Non-convex: $||\nabla f(x^r)||$</li></ul><p>Order of convergence $q$ s.t. </p><p>$$<br>\sup\bigg\lbraceq\big| \lim_{r\rightarrow+\infty}\frac{M(x^{r+1})}{M(x^r)^q}&lt;\infty<br>$$</p><ul><li>$q&#x3D;1$ : Linear convergence, $q&#x3D;2$ : quadratic</li></ul><p>Rate of Convergence: Given $q$ , </p><p>$$<br>\lim_{r\rightarrow\infty}\frac{M(r^{r+1})}{M(x^r)^1}&#x3D;n<br>$$</p><ul><li>Sublinear: $\text{Rate} &#x3D; 1$, Superlinear: $\text{Rate} &#x3D; 0$</li></ul><h2 id="Convergence-under-Convexity"><a href="#Convergence-under-Convexity" class="headerlink" title="Convergence under Convexity"></a>Convergence under Convexity</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet13.png" alt="Untitled"></p><h2 id="Convergence-under-Smoothness"><a href="#Convergence-under-Smoothness" class="headerlink" title="Convergence under Smoothness"></a>Convergence under Smoothness</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet14.png" alt="Untitled"></p><h2 id="Convexity-Smoothness"><a href="#Convexity-Smoothness" class="headerlink" title="Convexity &amp; Smoothness"></a>Convexity &amp; Smoothness</h2><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/IML_Final_Cheatsheet15.png" alt="Untitled"></p><h2 id="Upper-Lower-Bound"><a href="#Upper-Lower-Bound" class="headerlink" title="Upper &amp; Lower Bound"></a>Upper &amp; Lower Bound</h2><h3 id="mu-Strong-Convexity"><a href="#mu-Strong-Convexity" class="headerlink" title="$\mu$-Strong Convexity"></a>$\mu$-Strong Convexity</h3><p>$$<br>f(x)\geq f(y)+\nabla f(y)^T(x-y)+\frac{\mu}{2}||x-y||_2^2<br>$$</p><h3 id="L-Smoothness"><a href="#L-Smoothness" class="headerlink" title="L-Smoothness"></a>L-Smoothness</h3><p>$$<br>f(x)\leq f(y)+\nabla f(y)^T(x-y)+\frac{L}{2}||x-y||^2<br>$$</p><h2 id="Implication"><a href="#Implication" class="headerlink" title="Implication"></a>Implication</h2><p>$$<br>\nabla f(x^r)^T(x^r-x^*)\geq f(x^r)-f^*_\frac{\mu}{2}||x^r-x^*||<br>$$</p><p>$$<br>f(x^{r+1})\leq f(x^r)-\frac{r}{2}||\nabla f(x^r)||^2<br>$$</p><h1 id="Lagrangian"><a href="#Lagrangian" class="headerlink" title="Lagrangian"></a>Lagrangian</h1><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><h3 id="Original-Function"><a href="#Original-Function" class="headerlink" title="Original Function"></a>Original Function</h3><p>Minimize $f_0(x)$ with optimal $p^*$ subject to $f_i(x)\leq 0, i &#x3D; 1,…,m$</p><p>We have $L(x,\lambda) &#x3D; f_0(x)+\lambda_1f_1(x)+\cdots+\lambda_mf_m(x)$</p><h3 id="Dual-Function"><a href="#Dual-Function" class="headerlink" title="Dual Function"></a>Dual Function</h3><p>$$<br>⁍<br>$$</p><p><strong>Lower Bound Property: if</strong> $\lambda\geq 0$ and $x$ are primal feasible:</p><p>$$<br>g(\lambda)\leq f_0(x)<br>$$</p><h3 id="Dual-Problem"><a href="#Dual-Problem" class="headerlink" title="Dual Problem"></a>Dual Problem</h3><p>Maximize $g(\lambda)$ with optimal $d^*$ subject to $\lambda\geq 0$</p><p>We have: $d^<em>\leq p^</em>$ , denoted that $p^*-d^*$ the optimal dual gap.</p><p>The Convec Problem have $p^*&#x3D;d^*$</p><h3 id="KKT-Optimal-Condition"><a href="#KKT-Optimal-Condition" class="headerlink" title="KKT Optimal Condition"></a>KKT Optimal Condition</h3><table><thead><tr><th>$f_i(x^*)\leq 0$</th><th>Primal Feasible</th></tr></thead><tbody><tr><td>$\lambda_i^*\geq 0$</td><td>Dual Feasible</td></tr><tr><td>$\lambda_i^<em>f_i(x_i^</em>)&#x3D;0$</td><td>Complementary</td></tr><tr><td>$\nabla f_0(x^*)+\Sigma\lambda_i^<em>\nabla f_i(x^</em>)&#x3D;0$</td><td>Stationary</td></tr></tbody></table><h3 id="Equality-Constraints"><a href="#Equality-Constraints" class="headerlink" title="Equality Constraints"></a>Equality Constraints</h3><p>Minimize $f_0(x)$ subject to $f_i(x)\leq 0, i &#x3D; 1,…,m$ and $h_i(x)&#x3D;0,i &#x3D; 1,…,p$</p><p>We have $L(x,\lambda,v)&#x3D;f_0(x)+\sum \lambda_i f_i(x)+\sum v_ih_i(x)$</p><ul><li>Dual Function: $g(\lambda, v)&#x3D;\inf_x(L(x,\lambda,v))$</li><li>Dual Problem: Maximize $g(\lambda, v)$ subject to $\lambda\geq 0$</li></ul><p>KKT:</p><table><thead><tr><th>$f_i(x^*)\leq 0, h_i(x^*)&#x3D;0$</th><th>Primal Feasible</th></tr></thead><tbody><tr><td>$\lambda_i^*\geq 0$</td><td>Dual Feasible</td></tr><tr><td>$\lambda_i^<em>f_i(x_i^</em>)&#x3D;0$</td><td>Complementary</td></tr><tr><td>$\nabla f_0(x^*)+\sum\lambda_i^<em>\nabla f_i(x^</em>)+\sum v_i^<em>\nabla h_i(x^</em>)&#x3D;0$</td><td>Stationary</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>本科课程</category>
      
      <category>CS182</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CourseReview</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【PaperReading】RTNeRF &amp; Instant3D</title>
    <link href="/2023/05/05/PaperReading/Paper-RTNeRFAndInstant3D/"/>
    <url>/2023/05/05/PaperReading/Paper-RTNeRFAndInstant3D/</url>
    
    <content type="html"><![CDATA[<h1 id="Before"><a href="#Before" class="headerlink" title="Before"></a>Before</h1><p>Gatech 组的主要算法优化策略：</p><ul><li>首先，选择当前的 SOTA 算法</li><li>对 SOTA 算法进行 Profiling，找到性能瓶颈</li><li>以增量式优化为主</li></ul><hr><h1 id="RT-NeRF"><a href="#RT-NeRF" class="headerlink" title="RT-NeRF"></a>RT-NeRF</h1><h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>认为：目前 NeRF 效率低有两个主要原因：</p><ol><li>The commonly used <strong>uniform point sampling</strong> method<ul><li>朴素的采样方法）</li></ul></li><li>The required dense <strong>accesses and computations</strong> for <strong>embeddings</strong><ul><li>密集的 Embedding 访问和计算</li></ul></li></ol><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/nerfmodel.png" title="NeRF Model"><h3 id="先验信息：-Sparsities-of-pre-existing-points"><a href="#先验信息：-Sparsities-of-pre-existing-points" class="headerlink" title="先验信息： Sparsities of pre-existing points"></a>先验信息： Sparsities of pre-existing points</h3><p>最终有效的采样点应该具有稀疏性</p><h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><ol><li>Directly computing the geometry of pre-existing points based on the corresponding non-zero cubes of the occupancy grid<ul><li>通过预计算已经存在于 Occupancy Grid 的几何元素，减少采样点数量</li></ul></li><li>Leverages a coarse-grained view-dependent rendering ordering scheme to avoid processing invisible points<ul><li>通过一个粗粒度的排序，减少对某些不可见点的运算</li><li>Object Ordered 思想</li></ul></li></ol><h2 id="Profiling"><a href="#Profiling" class="headerlink" title="Profiling"></a>Profiling</h2><p>对 TensoRF 的 Rendering Pipeline 进行 Profiling。</p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/tensorfprof.png"><hr><h2 id="Profiling-1"><a href="#Profiling-1" class="headerlink" title="Profiling"></a>Profiling</h2><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/tsnsorfprof-2080ti.png"><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/tensorf-prof-legend.png"><hr><h2 id="Locate-the-pre-existing-points"><a href="#Locate-the-pre-existing-points" class="headerlink" title="Locate the pre-existing points"></a>Locate the pre-existing points</h2><p>All the candidate points <strong>are uniformly sampled along rays</strong> and then the existence of pre-existing points are identified via a <strong>query process</strong> based on the occupancy grid.</p><p>首先在光线上进行一次预采样，通过 Occupancy Grid 来查询点的存在与否</p><h3 id="两个-Inefficiency"><a href="#两个-Inefficiency" class="headerlink" title="两个 Inefficiency:"></a>两个 Inefficiency:</h3><ol><li>The sparsity of the occupancy grid is not leveraged<ul><li>没有利用 Occupancy Grid 的稀疏性先验</li></ul></li><li>The DRAM accesses to the occupancy grid are irregular because the emitted rays can come from any direction, and thus the order of their accesses to the occupancy grid can not be predicted in advance.<ul><li>由于 Ray 的方向并不能预知，Occupancy 的 DRAM-Access 很随机，Locality 差</li></ul></li></ol><hr><h2 id="Proposed-Solution？"><a href="#Proposed-Solution？" class="headerlink" title="Proposed Solution？"></a>Proposed Solution？</h2><p>Directly computes the coordinates of pre-existing points by looping over the non-zero cubes of the occupancy grid.</p><ul><li>按照 <strong>固定的顺序</strong> 访问 Occupancy Grid（也即所谓的“Cube”）</li></ul><h2 id="Efficient-Rendering-Pipeline"><a href="#Efficient-Rendering-Pipeline" class="headerlink" title="Efficient Rendering Pipeline"></a>Efficient Rendering Pipeline</h2><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/effrendpipel.png" width="800"><ol><li>将 Occupancy Grid 中的每个 Non-zero cube 近似为一个球，以方便后续步骤的计算；</li><li>将上述的球投射到要渲染的图像上，成为一个椭圆（Oval）；</li><li>根据待渲染的图像中的 <strong>regular arrangement of points</strong> ，即一个点对应一个像素，确定椭圆内的点；</li><li>使用 Line-Sphere intersections 的解析解来计算出沿着光线射线并且在球内的点的 Geometries。</li></ol><p>只有 Pre-exist points 会被包含在循环中。解决了：</p><ol><li>Occupancy Grid 的 Sparsity 没有被充分利用</li><li>在 SOTA Rendering Pipeline 中， DRAM Access 的不规则性</li></ol><h2 id="Early-Termination-Volume-Rendering"><a href="#Early-Termination-Volume-Rendering" class="headerlink" title="Early Termination: Volume Rendering"></a>Early Termination: Volume Rendering</h2><p>在图形学中，Volume Rendering Integral 的离散化计算主要有两种：</p><ul><li>Front-to-back composition: 从前向后积分<ul><li>$\begin{cases}\hat{C_i}&#x3D;\hat{C}<em>{i+1} + \hat{T</em>{i+1}}C_i\\hat{T_i}&#x3D;\hat{T}_{i+1}(1-\alpha_i)\end{cases}$</li></ul></li><li>Back-to-front composition： 从后向前积分<ul><li>$\begin{cases}\hat{C_i}&#x3D;\hat{C_{i-1}}(1-\alpha_i)\\hat{T}<em>i&#x3D;\hat{T}</em>{i-1}(1-\alpha_i)\end{cases}$</li></ul></li></ul><hr><h2 id="View-Dependent-Rendering-Ordering"><a href="#View-Dependent-Rendering-Ordering" class="headerlink" title="View-Dependent Rendering Ordering"></a>View-Dependent Rendering Ordering</h2><p>主要 Motivation 来自于：</p><ul><li>Early Termination 要求我们在进行点采样的时候按照 Ray Marching 的顺序进行（从前向后）</li><li>如果先访问了暂时还没有 Marching 到的点，那这个数值显然不能拿来计算，相当于是一次无效访问</li><li>如果能让渲染的计算本身变得有序，就能获得更好的 Locality！</li></ul><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/vdro.png"><ol><li>将 Occupancy Grid 分割成八个 Subspace</li><li>先计算最接近 View Origin（光线的原点）的子空间将会先进入计算</li><li>接下来，途中标注 <code>2</code> 的部分再进入计算，再接下来是剩下的</li></ol><hr><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/RTRes.png"><hr><h1 id="Instant-3D"><a href="#Instant-3D" class="headerlink" title="Instant 3D"></a>Instant 3D</h1><p>回顾一下Gatech 组的主要算法优化策略：</p><ul><li>首先，选择当前的 SOTA 算法</li><li>对 SOTA 算法进行 Profiling，找到性能瓶颈</li><li>以增量式优化为主</li></ul><h2 id="选择当前的-SOTA-算法"><a href="#选择当前的-SOTA-算法" class="headerlink" title="选择当前的 SOTA 算法"></a>选择当前的 SOTA 算法</h2><p>—— Instant NGP</p><h2 id="对-SOTA-算法进行-Profiling"><a href="#对-SOTA-算法进行-Profiling" class="headerlink" title="对 SOTA 算法进行 Profiling"></a>对 SOTA 算法进行 Profiling</h2><p>认为 NGP 的主要瓶颈是对 3D Feature 进行三线性插值</p><h2 id="Different-paces-of-Color-and-Density-During-Training"><a href="#Different-paces-of-Color-and-Density-During-Training" class="headerlink" title="Different paces of Color and Density During Training"></a>Different paces of Color and Density During Training</h2><p>重建质量对于 Color 和 Density特征 具有不同的敏感性</p><ul><li>因为 NeRF 本身重建的 Loss 是 RGB-Based，并没有引入几何形状的约束，几何形状的重建本身是“赠品”</li><li>因此，Color 部分并不需要和 Density 部分相同的精度（Color 部分粗糙一些也不影响重建效果）</li></ul><h2 id="两个优化："><a href="#两个优化：" class="headerlink" title="两个优化："></a>两个优化：</h2><ol><li>两个网格的尺寸不需要一样</li><li>两个网格的更新频率不需要一样</li></ol><h3 id="网格尺寸"><a href="#网格尺寸" class="headerlink" title="网格尺寸"></a>网格尺寸</h3><p>遍历了一下两个网格尺寸的比例，找了一些有代表性的结果：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/2023-05-05-22-10-07.png" alt="w:500"></p><p>Color Grid 可以使用更小的大小</p><h3 id="更新频率"><a href="#更新频率" class="headerlink" title="更新频率"></a>更新频率</h3><p>遍历了一下两个网格更新频率的比例，找了一些有代表性的结果：<br><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/2023-05-05-22-11-58.png" alt="w:500"></p><p>Density Grid 可以使用更小的更新频率</p><h2 id="效果-1"><a href="#效果-1" class="headerlink" title="效果"></a>效果</h2><p>We can trim down the runtime by $83.0%$ as compared to the most efficient NeRF training algorithm [24] on the same edge GPU Xavier NX.</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Neural Rendering, Architiecture, Hardware-Software Co-Design</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【行见录】遗憾篇</title>
    <link href="/2023/04/16/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E8%A1%8C%E8%A7%81%E5%BD%95/%E8%A1%8C%E8%A7%81%E5%BD%95-%E9%81%97%E6%86%BE%E7%AF%87/"/>
    <url>/2023/04/16/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E8%A1%8C%E8%A7%81%E5%BD%95/%E8%A1%8C%E8%A7%81%E5%BD%95-%E9%81%97%E6%86%BE%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<blockquote><p>在盛夏的某个中午，人海浮沉，如泡沫的心思在阳光下消融，融入时间的尘埃里，没有人记得，也就没有人忘记。</p></blockquote><hr><p>遗憾是一种风吹不散，时间也无法侵蚀的东西。</p><p>再完满的爱意若没有维系也会随着时间自然淡化，再真挚的情义也难免被名利纠缠在俗世里，退化为现实的枷锁；那些深沉的恨意在复仇以后，随着敌人的消散也一同在漫天风沙里一点点弥散，教人迷茫无所措。</p><p>但遗憾不一样。那是经年岁月中，无可挽回的无可奈何，时空流逝下，深黄的定格。它会褪色却不会淡化，天地不移，江流石不转。它是如此沉重，我们无知觉的拿起，却得用一生的时间去学着放下。</p><p>或者说，所谓放下，说对自身刻意的欺骗，用那些美好光明的虚幻涂鸦去遮掩那些无法被更改的刻痕。</p><p>遗憾是在知道一切无可更改之后的浇不开的块垒。《诡秘之主》里克莱恩被命运胁迫着一路向神位前行，最终却发现梦想回到的家乡已经成为了几万年前的历史；《盘龙》中林雷一路挣扎历经生死，才知道为了救自己燃烧完灵魂的那个德林爷爷再也不能出现在自己面前。那些故事里的遗憾是如此重，让那些能背负命运的主角们——以及作为读者的我们无法放下。</p><p>而现实中的遗憾或许未必一样如山岳般沉重，但你一样放不下它们，只能被选择与它们和解。</p><p>正如高考结束的很多年里，我仍然会做起那些梦。</p><p>那些梦可能是某次考试前的紧张，某次挫败后的懊恼，某些难以言喻的悸动，又或者某些美好灿烂的幻想。那是一段非常沉重而纯粹的回忆。它是如此的沉重，就像是要背着巍峨高山一步一步踏出深深的脚印；它又是如此纯粹，目标是那样的明确，所有人都以不同的方式向着它前进。</p><p>但存在并不代表实现。事实上对于大多数像我这样的人来说，一步一步走下去留下的注定是遗憾，一次一次的努力所证明的是自己的平庸。</p><p>遗憾就是这样，你做着莫欺少年穷的美梦咬牙前行之后，蓦然回首，发现除了与生活与平庸和解以外，失去了别的选择。你终于可以笑着说“原来我也是一个普普通通的人啊”。那些曾经最玄奇最伟大飘渺的幻想被红尘掩埋，埋在那个名叫年少的坟墓里。然后你就再也不需要证明什么了。随着时间的流逝你慢慢老去，然后被人们淡忘，消失在漫长时光的冲刷下，成为历史记录里某个数字的组成部分。</p><p>而此时再看来，在流淌的岁月里沉淀的记忆，已经零零碎碎。剩下的是一片金色的阳光，某个恬静的面庞，还有那个真的相信自己可以倾尽山海的热忱和赤诚。在等若干年后，等自己已经被打磨得圆滑，等着头发变得灰白，等面颊上不可逆转的长出皱纹，我会不会仍然为当年那些年少轻狂——或者未曾年少轻狂——而感到遗憾和后悔？我不知道，也没有人知道。命运的伏线太多，在千百次的推演间我也未曾找到我想要的最优解。那些美好的幻想，永远与我隔着天堑，因为我的平凡和笨拙。</p><p>在盛夏的某个中午，人海浮沉，如泡沫的心思在阳光下消融，融入时间的尘埃里，没有人记得，也就没有人忘记。</p>]]></content>
    
    
    <categories>
      
      <category>散文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【唐宋文学精华 期末论文】婉约词中的风骨</title>
    <link href="/2023/03/10/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%A9%89%E7%BA%A6%E8%AF%8D%E4%B8%AD%E7%9A%84%E9%A3%8E%E9%AA%A8/"/>
    <url>/2023/03/10/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%A9%89%E7%BA%A6%E8%AF%8D%E4%B8%AD%E7%9A%84%E9%A3%8E%E9%AA%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="婉约词中的风骨"><a href="#婉约词中的风骨" class="headerlink" title="婉约词中的风骨"></a>婉约词中的风骨</h1><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>起初的风骨只是一把中性的标尺。但随着时间的推移，我们逐渐把那种豪迈的、悲壮的诗歌当成了风骨的代表。或许是因为有那样多的好汉站在仁义之上，引吭高歌、奋笔疾书，写下充满凛然正气的篇章，让人仿佛以为，谈到有风骨的诗文，就一定要看到有风骨的诗人——于是原本作为中性标尺的风骨，就渐渐被绑缚在豪迈上，言风骨则必称悲壮豪放，似乎诗词之作者没有经历过万般磨难，诗词内容里没有登高一呼或是怆然涕下，就不能和风骨沾边一般。但事实上，风骨绝非是只在经历磨难痛苦的时候所能体现出来的东西。在对镜梳妆的时候，在登楼相思的时候，在追忆往事的时候，在生活的每个片面里，都应该存在风骨的影子。那我们为什么不试着在婉约词中找到风骨的存在呢？<br>风骨何谓？</p><p>风骨，是一个极具中国浪漫特色的词汇。这个词的意蕴颇为复杂，既指向人的品格，描绘出某种顽强不屈、无惧生死的气度，好像让人看到屈原在江边悲叹、陶渊明在南山下微笑；又指向文艺作品——如嵇康疾书广陵散、李白高歌蜀道难，让人感觉到刚健遒劲的、源于内心深处的力量。<br>最开始被携入文学领域的时候，风骨是对于作品的“情”与“辞”的最高要求：“情与气偕，辞共体并”[ （南朝）刘勰撰《文心雕龙》第二十八篇《风骨》]，也就是既有情致，由有内涵。刘勰在《文心雕龙》中说：“是以怡怅述情，必始乎风；沉吟铺辞，莫先於骨。故辞之待骨，如体之树骸；情之含风，犹形之包气。结言端直，则文骨成焉；意气骏爽，则文风清焉。”。在抒发情感的时候，要有气质，要能够有一种感发乃至于教化的作用；而文章的架构内涵又不能浅薄庸俗，要用显豁却动人的表达来让人有所思索，有所感悟。这就是最早的风骨之说。<br>所谓风骨，风为情致，体为架构。我们在这里谈到有风骨的诗词歌赋，是说它既有风一样的情致，又有骨一般的思想内涵。而这里所指的内涵，绝非片面的，被局限的忧国忧民等类的言志之作，而是更加深远的，对于生活和自然，还有更长远的——时间、刹那与永恒、虚幻与真实——的某些思考和揣摩，又或者是在不同境遇下，在日常生活的点滴里不经意间流露出来的情思和风度。 </p><p>中华文化应该是有风骨的文化，中华文化的风骨是由温柔细腻的情思和英勇豪迈的高歌一同铸就的。我们有时过分的强调豪迈的诗词，认为这才是中华文化之所以壮阔伟大的原因，认为中华文化的伟大只有在国破家亡颠沛流离的时候才能体现出来。但谁说在盛世太平间，我们看不到中华文化的堂皇气象？谁说在儿女情长里，你读不出中华文化的细腻温柔？如果说，那些豪迈壮阔的高歌聚集成中华文化的“骨”，那每一首温柔婉转细腻幽深的词句，就萦绕成中华文化的“风”。骨滋养了千年来中华文化不断的血脉，风则绘制出中华文化的万般气象，赋予其更加丰满的情思和内涵。</p><h2 id="冯、李君臣：南唐词的莽苍之气"><a href="#冯、李君臣：南唐词的莽苍之气" class="headerlink" title="冯、李君臣：南唐词的莽苍之气"></a>冯、李君臣：南唐词的莽苍之气</h2><blockquote><p>谁道闲情抛掷久，每到春来，惆怅还依旧。日日花前常病酒，不辞镜里朱颜瘦。 </p><p>河畔青芜堤上柳，为问新愁，此事年年有。独立小桥风满袖，平林新月人归后。 </p><p>——冯延己《鹊踏枝》 [ （南唐）冯延巳撰《阳春集》]</p></blockquote><blockquote><p>菡萏香销翠叶残，西风愁起绿波间。还与韶光共憔悴，不堪看。 </p><p>细雨梦回鸡塞远，小楼吹彻玉笙寒。多少泪珠何限恨，倚栏干。 </p><p>——李璟《山花子》[ （南唐）李璟、李煜撰，（现代）王仲闻修订，《南唐二主词校订》] </p></blockquote><p>官至南唐宰相的冯延巳和南唐中主李璟私交极好，两人在冯延巳二十多岁、李璟十多岁的时候就开始交游。《南唐书》记载说，某日李璟与冯延巳谈话，李璟问：“风乍起，吹皱一池春水，干卿何事？”冯延巳回答：“未若陛下‘小楼吹彻玉笙寒’也。”所提的词句皆是两人的名句。<br>只从字面就能读出，这对君臣的词极其富有兴发之作用。所谓兴发，就是由于周围景色风景环境的微小变化，而引起的内心的波澜壮阔的活动。这种感发性正是“风骨”中“风”的体现。而他们的词不再如温、韦那般流连于房前屋后的花前月下，而是仿佛走到原野中，在迷茫壮阔的天地中歌颂着一种更加深刻的情感——一言以蔽之，有一种“莽苍之气”。</p><p>冯延巳的风骨体现在他的执着里。同是写春愁，是写“惆怅还依旧”，正因为这种冯延巳却能把惆怅写出浓郁的悲剧韵味来。“日日花前常病酒，不辞镜里朱颜瘦”，这句话颇有杜甫“且看欲尽花经眼，莫厌伤多酒入唇[ （唐）杜甫《曲江二首》]”的神韵。花前病酒为何故？是因为这花很快就要零落了，很快就看不见了。这样美好的事物即将消逝，他何故不饮？他何忍不饮？于是就只能将对于花的珍重和惋惜融进酒里，这种珍重和惋惜，到了要为此“朱颜瘦”，要为此身形消瘦、心灵憔悴的深重。冯延巳的风骨就体现在这种对于美的执着里。“不辞镜里朱颜瘦”，“不辞”和“镜里”正是体现了诗人的执着。 </p><p>从体式上看，这是婉约词的风格无疑；从思想情致上看，这首词却具有深刻的执着和悲剧的内涵——正是这种内涵，和唯美深致的描写一起，构成了词的风骨：我们都说，在清醒的状态下经历的苦难才是最可怕的；而如果能在清醒的状态下，在苦难的深重压挫下，仍然执着的坚持自身的追求，就更加难得可贵了。为了“花经眼”，他明知道自己会“朱颜瘦”，仍然愿意在日日饮酒，哪怕看着自己在镜中的模样消瘦枯槁下去。这倒颇有一种在几千年后，刘慈欣在《三体》中写到的，罗辑为自己挖好坟墓然后站在阔大的郊外说“我对三体世界说话”的感受。这种独立荒原的莽苍之气，将本轻柔平淡的惆怅推向了更高的境界。</p><p>李璟的词则富有一种生命衰老凋零的感动。“南唐中主词‘菡萏香销翠叶残，西风愁起绿波间’，大有众荒芜秽、美人迟暮之感”。[ （清）王国维《人间词话》]所谓“众荒芜秽、美人迟暮”，最早见于宋词之中。屈原说：“惟草木之零落兮，恐美人之迟暮。[ （战国）屈原《离骚》]”宋玉说：“悲哉！秋之为气也，萧瑟兮草木摇落而变衰。[ （战国）宋玉《九辩》]”。这种摇落秋天草木的悲哀是一种颇具中国传统特色的审美。而生命的衰老和凋零是极具兴发感动的。“菡萏香销翠叶残，西风愁起绿波间”：荷花凋残，碧色萎靡，风吹过而池水皱，和那凋零憔悴的美丽相映衬，和美人迟暮时的悲哀是同质的。</p><p>这正是婉约词，南唐的婉约词。虽然是用婉约的笔调书写，但谁能说这种锐感的诗心所体悟的情感是没有深度的，谁敢说这样的诗篇是没有风骨的？与豪放词宛如滔滔江河或者银河落瀑的磅礴情感不同，这种感发就像是往平静的池塘里投下一块石头，激起一圈一圈的波纹。在水波的振动摇荡间，也就振动摇荡了性情，扩散出深沉悠远的情致和思索，在莽莽苍苍的荒原上，搭建出深而有致的风骨。 </p><h2 id="晏、欧：北宋词的境界与格局"><a href="#晏、欧：北宋词的境界与格局" class="headerlink" title="晏、欧：北宋词的境界与格局"></a>晏、欧：北宋词的境界与格局</h2><p>晏殊和欧阳修的词风都继承自南唐。王国维评价冯延巳：“晏同叔得其俊，欧阳永叔得其深[ （清）刘熙载《艺概·词曲概》]”，却也正是对两人风格的写照。<br>此三位词人都是有风骨之词人。如果说冯延巳的风骨是“执着的热情”，那晏殊的风骨就是一种“圆融的关照”，欧阳修的风骨就是一种“遣玩的意兴”[ （现代）叶嘉莹《唐宋词十七讲》，北京大学出版社，第一百九十五页]。 </p><p>冯延巳的风骨，“执着的热情”，是“梅落繁枝千万片，犹自多情，学雪随风转[ （南唐）冯延巳《鹊踏枝》]”这样的多情的执着；也是“日日花前常病酒，不辞镜里朱颜瘦”这般对容易逝去的美好的执着。这种执着是深具悲剧韵味的、是富有“莽苍之气”的，但晏殊和欧阳修却不然。 </p><blockquote><p>一曲新词酒一杯，去年天气旧亭台。夕阳西下几时回？ </p><p>无可奈何花落去，似曾相识燕归来。小园香径独徘徊。 </p><p>——晏殊《浣溪沙》 [ （宋）晏殊《浣溪沙》]</p></blockquote><blockquote><p>离歌且莫翻新阕，一曲能教肠寸结。 </p><p>直须看尽洛城花，始共春风容易别。 </p><p>——欧阳修《玉楼春》 [ （宋）欧阳修《玉楼春》]</p></blockquote><p>晏殊的风骨是内敛的，是“圆融”的，读者很难直接从他的词句里读出那种独立荒野的壮阔，而只能从他闲静淡雅的词句里体会出对时间、对人生的观照和思索，从中品味出他高远潇洒的境界，然后感悟到一种近乎于道的风骨。这是一种理性：并非是计较一亩三分地的得失厉害的衡量，而是一种对自身的状态和感情充满反省的理性。这种理性就体现在，他的文字是有节制的，他的感情是有节制的，他的抒情决不是那种放纵的宣泄，而是一种轻柔的感发。“夕阳西下几时回。”明天的太阳还会升起，可是今天的太阳落下去，就不会再回来了。“夕阳西下几时回”并没有多么椎心泣血的呼喊，而是如此闲静淡漠、如此不着痕迹的传达了他的感发，传达了他对于万物流逝无可挽回的无奈。 </p><p>更加绝妙的是，他在后面如是说：“无可奈何花落去，似曾相识燕归来”，虽然无可奈何，但它仍然会以其他的形式回到我们的身边——这是另一种层面上的永恒，是宇宙的循环。他的圆融就来源于此。在“小园香径独徘徊”的时候，你就好像看到他一个人的身影慢慢踱步，看到他的思索，看到他的困惑和释然。这是晏殊的境界，一种潇洒高妙的境界，而在境界中又不经意体现出一种思索的情致。这种面对无可抗力的潇洒风度和深切思致，正是晏殊的风骨所在。<br>欧阳修的风骨则与之不同。同样是面对困境，欧阳修用一种对于美的欣赏来排遣内心的哀伤和忧愁——正所谓“遣玩”。在这种欣赏里，读者能体会到的是“付出最大的精神、情感和力量去做、去欣赏”的意兴和格局，从而一窥他的风骨。</p><p>就只看这《玉楼春》的最后四句：“离歌且莫翻新阕，一曲能教肠寸结。直须看尽洛城花，始共春风容易别。”——不用再做新的离歌了，只是听一听都让人感到肝肠寸断。只有看尽了这洛阳美好的花，我才能轻易和春天告别。 </p><p>《圣经》中有言：“那美好的仗我已经打完了，应行的路我已行尽了，当守的道我守住了。[ 《圣经·新约·提摩太后书》第四章第七节]”这与欧阳修这种“直须看尽洛城花，始共春风容易别”，有相似的境界和格调。或许他写的仅仅是一次离别，但其中所暗含的，诗人对眼前的光阴、所做的事业的一种“付出最大的精神、情感和力量去做、去欣赏”的风度，却真实到仿佛可以触摸。这种风度令词从仅仅刻画离愁别情的“妇人语”里拔升而出，就好像要向着天空去、向着太阳去，于是局限的格局被打开了，俗套的境界被洗刷了，遣玩的潇洒意兴跃然纸上。谁能说这不是一种风骨呢？ </p><p>北宋的词就是这样。你能从词句中无意的抒发里，窥见词人自身的襟袍、格局和境界，这种境界用寥寥几笔就勾画出令人神往的气度，勾画出婉约词派中，真实而不朽的风骨。 </p><h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>若是说冯、李二人在婉约词中写出了悲剧美的韵味，他们的风骨是投入水中的石所激荡摇动的性情，那晏、欧二人就是在经历过繁华之后，轻轻落进“万紫千红总是空”的意境，余韵袅袅，带着一些觉悟和感慨，带着一些思索和哲理，在空中轻轻的荡漾着。这种思索正是王国维所最为推崇的“境界”。在这种境界里，你能看到词人经历过的无数沧桑风云和苦难，但那都被悄然隐去在婉转幽深的词句里。看似只是写着相思的词句，隐藏的却是词人在跌宕起伏间孤独和寂寞的思索，在上上下下中所完成的人格。这种隐约的境界正是婉约词的风骨之所在。它不直接，也不爽朗，实实在在地存在着，就像浩瀚海洋上些微露出的冰山，看似并不宏伟，却深藏自己的内涵。 </p><p>这样婉转的内涵所体现出的作者的修养和襟袍，与那些高亢的豪言壮语一起，共同构成了词文学中的风骨，无分高下，各有千秋，各自屹立在词文化的渺渺平原上，供无数来人欣赏、揣摩，又生长兴发出更多的文化来。 </p><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p>诗、词：</p><ol><li>（唐）杜甫《曲江二首》</li><li>（南唐）李璟《山花子》</li><li>（李璟）冯延巳《鹊踏枝》</li><li>（宋）晏殊《浣溪沙》</li><li>（宋）欧阳修《玉楼春》</li><li>（战国）屈原《离骚》</li><li>（战国）宋玉《九辩》</li><li>《圣经·新约·提摩太后书》第四章第七节</li></ol><p>古书：<br>9. （南朝）刘勰撰《文心雕龙》第二十八篇《风骨》<br>10. （清）王国维《人间词话》<br>11. （清）刘熙载《艺概·词曲概》</p><p>现代作品：<br>12. （现代）叶嘉莹《唐宋词十七讲》，北京大学出版社，第一百九十五页</p><h1 id="文件下载链接"><a href="#文件下载链接" class="headerlink" title="文件下载链接"></a>文件下载链接</h1><ul><li><a href="/files/%E5%A9%89%E7%BA%A6%E8%AF%8D%E4%B8%AD%E7%9A%84%E9%A3%8E%E9%AA%A8.pdf">PDF</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2021下半年-2022年诗词创作</title>
    <link href="/2022/12/31/2021%E4%B8%8B%E5%8D%8A%E5%B9%B4-2022%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/"/>
    <url>/2022/12/31/2021%E4%B8%8B%E5%8D%8A%E5%B9%B4-2022%E5%B9%B4%E8%AF%97%E8%AF%8D%E5%88%9B%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="诗词创作"><a href="#诗词创作" class="headerlink" title="诗词创作"></a>诗词创作</h1><h2 id="离家"><a href="#离家" class="headerlink" title="离家"></a>离家</h2><p>时至今日前事休，天南海北少年游。<br>漫漫长路从此始，不到云霄不回头。</p><h2 id="西江月"><a href="#西江月" class="headerlink" title="西江月"></a>西江月</h2><p>来路云月渺渺，前路风雨茫茫。<br>独自可以对天酌，可怜无人相望。</p><p>相逢不过萍水，寓所更在他乡。<br>谁能相识更相知，便从此无惆怅。</p><h2 id="水调歌头"><a href="#水调歌头" class="headerlink" title="水调歌头"></a>水调歌头</h2><p>沉沉初颜色，雾涌楼第间。<br>正是归来时候，慨叹有天寒。<br>澎湃暴雨如幕，落叶飞花无数，何时见青天。<br>只他忽转瞬，丽日露云前。</p><p>是青春。岁月稠，度流年。<br>花开蝶往，相看舞蹁跹。<br>云游相逢甚好，缘分古来玄奥，谁人可断言。<br>留尔词一阙，天乞与成全。</p><h2 id="打油诗-初秋"><a href="#打油诗-初秋" class="headerlink" title="打油诗 初秋"></a>打油诗 初秋</h2><p>灯影楼相闻，层层复加深。<br>日落思往事，风起忆故人。</p><h2 id="打油诗"><a href="#打油诗" class="headerlink" title="打油诗"></a>打油诗</h2><p>天寒旷野静，灯火已未明。<br>正此夜深时，仰首见繁星。</p><h2 id="踏莎行"><a href="#踏莎行" class="headerlink" title="踏莎行"></a>踏莎行</h2><p>低云如山，霞光似柱。煌煌应是琼霄路。<br>雨疏风骤亦有时，凭栏独好斜阳暮。</p><p>伏案疾书，深情谁诉？拟把归期从今数。<br>东南西北何归途，满身相思向荆楚。</p><h2 id="临江仙"><a href="#临江仙" class="headerlink" title="临江仙"></a>临江仙</h2><p>高树盈盈夏意，碧空淡淡轻烟。<br>翠微无声自绵延。<br>远峰如云浅，缥缈忆从前。</p><p>白云横空如练，莫为风月流连。<br>平生唯爱日高眠。<br>望见青山老，春色属华年。</p><h2 id="鹊踏枝"><a href="#鹊踏枝" class="headerlink" title="鹊踏枝"></a>鹊踏枝</h2><p>炎夏却为秋色敛。慢慢云天，数道光深浅。<br>街上画店绘眉间，河中客舟从篙转。</p><p>稚子嬉游时时见。一曲《童年》，岁月随波远。<br>茶尽日重已入夕，此刻竟为浮生满。</p>]]></content>
    
    
    <categories>
      
      <category>诗与词</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【行见录】相逢篇</title>
    <link href="/2022/12/18/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E8%A1%8C%E8%A7%81%E5%BD%95/%E8%A1%8C%E8%A7%81%E5%BD%95-%E7%9B%B8%E9%80%A2%E7%AF%87/"/>
    <url>/2022/12/18/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E8%A1%8C%E8%A7%81%E5%BD%95/%E8%A1%8C%E8%A7%81%E5%BD%95-%E7%9B%B8%E9%80%A2%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<blockquote><p>“青春时节的相逢就是这样一个美好的事情，它足够热烈，是一瞬间绽放的烟火；又足够短暂，短暂到沉重的现实来不及侵入和玷污它就灰飞烟灭，消散在流逝的时光里，只剩下一抹浅浅的泡影。”</p><p>——行见录·相逢篇</p></blockquote><blockquote><p>从别后，忆相逢，几回魂梦与君同。今宵剩把银釭照，犹恐相逢是梦中。</p><p>——晏几道《鹧鸪天》</p></blockquote><hr><p>什么是相逢？</p><p>小的时候，每天回家看到迎接自己的父母，称得上相逢吗？</p><p>每天早上从宿舍起来看到正在学习的舍友，称得上相逢吗？</p><p>每天在去考勤的路上与某位教授擦肩而过，称得上相逢吗？</p><p>我觉得不算。</p><p>西方语言学中有一个叫做“语码”的概念。在一个有着相同文化传统的群体里，一个语言符号，可以引发人们共同（“普遍”）的联想。这时候，这个语言符号（语码），就像一个按钮，按下它，就会引起这个有着相同文化传统的群体里的人比较接近的联想。</p><p>相逢就是这样一个语码。听到相逢这两个字，就好像看到明媚的春天里的狂奔，在春风中飞扬的花瓣擦过自己的脸庞，而恍然未觉的你只是看着眼前与你相见的人，她的眼睛是如此的明亮而深邃，就像是每个深夜入梦时头顶的星空。</p><p>青春时节的相逢就是这样一个美好的事情，它足够热烈，是一瞬间绽放的烟火；又足够短暂，短暂到沉重的现实来不及侵入和玷污它就灰飞烟灭，消散在流逝的时光里，剩下一道泡影。</p><p>曾几何时，我也经历过这样的相逢：</p><blockquote><p>今年天气去年新，昨夜凭窗望月明。</p><p>红笺急草封心意，字字句句重千金。</p><p>春天树，夏天云，风景难寄此时情。</p><p>乘我小舟轻渡浪，江流回转始逢君。</p></blockquote><p>那时的相逢这样的。你会紧张到无法入眠，看着窗外逐渐温暖却爽朗清新的天气，看着窗外的明月在干净的夜空下莹莹烁烁，在淡淡的层云间洒下薄薄的辉光。你沉思良久，有好多好多想说的话，又害怕自己说不出口，只好提笔，用信的格式写下那些无从抒发的心绪。你是如此郑重、真诚和热忱，每一句话都从最深的心底发出，你相信你永远也不会违背自己现在所说的一切。</p><p>春夏之交，你望着那些绿树层云，它们都是相逢路上的注解，这些淡漠的风景怎能抒发那种迫切又梦幻的心情？在渡过浩渺的长江的时候，你想到苏轼曾经在这里写下“渺沧海之一粟”，但这样的宽广浩瀚在相逢的迫切下也显得如此微茫。在几个小时的奔波之后，你终于满头大汗的见到了你想见的人，阳光斜斜地穿过树荫，落在她微侧的脸庞上，你看着她清澈的眼睛，感到如此兴奋和幸福，就好像整个世界都被你收入眼里。</p><p>哪怕你知道这次相见之后，就是……永别。</p><p>但这一瞬间也已经足够。</p><p>我们说相逢的欢喜是永恒的，而它又会以极快的速度逝去。永恒是什么？永恒刻画的是深度，从不是持续的时间。消失的喜悦留下的梦幻一般的回忆被各种各样的思绪填满，越是长久，越是深沉，最后酿成夹杂喜怒哀乐的一句感慨，藏着当年的小心翼翼和满心期盼，藏着未说出口的话，藏到你自己都忘却，藏到岁月的尘埃把它们掩埋。</p><p>是啊，每个生命都在时间的洪流里疾行，本来也没有多少时间给我们留下来蹉跎和温存。</p><p>相逢这种东西太易碎了，“江南无所有，聊赠一枝春”，又或者“正是江南好风景，落花时节又逢君”，都是不敢言说的相思和喜悦。大都好物不坚牢，彩云易散琉璃脆。相逢是如此的美妙，以致于我们不敢直言，怕一说出口它就变成了梦幻和泡影。</p><p>刘慈欣在《球状闪电》的结尾也曾经写过一种“相逢”：</p><blockquote><p>我猛地睁开双眼，就在书桌上的紫水晶花瓶上，出现了一朵蓝色的玫瑰，但玫瑰在我看到它的瞬间就消失了，只剩空花瓶静静地立在那里。但那朵玫瑰的每一个细节都印在我的脑海中，它充满了生机，透出一种冰雪的灵气。</p></blockquote><blockquote><p>我以后再也没有看到蓝色玫瑰，但知道它在那里就够了。有时夜深人静，我就将水晶花瓶移到窗前，然后背对着它站着，这时我往往能闻到缥缈的花香，就知道它肯定已经在那里了，心灵的眼睛能看清它的每一个细节。我用心来抚摸着它的每一个花瓣，看它在来自窗外的夜风中微微摇曳……它是一朵我只能用心来看的花。</p></blockquote><blockquote><p>不过，我还是希望在此生再用自己的眼睛看到一次蓝色玫瑰，据丁仪说，从量子力学的角度来讲，人的死亡过程就是由一个强观察者变为弱观察者再变为非观察者的过程，当我变成弱观察者时，玫瑰的概率云向毁灭态的坍缩速度就会慢一些，我就有希望看到它。</p></blockquote><blockquote><p>当我走到人生的尽头，当我在弥留之际最后一次睁开眼睛，那时我所有的知性和记忆都消失在过去的深渊中，又回到童年纯真的感觉和梦幻之中，那就是量子玫瑰向我微笑的时候。</p></blockquote><p>这就是相逢。蓝色的玫瑰引着我们从时间的长河里腾空，跨越一生的时光，回到那个你不曾回去的年岁。那是你从别后就一直在回忆的东西。我想，当玫瑰在我离去的那一刻开放的时候，再现的玫瑰正如同晏几道的相逢一样，那一瞬间，往昔的杨柳明月桃花清风都再一次浮现在眼前，栩栩如生一如当年；那一刻再短暂得像是春天的清晨树梢滑落的露水，却又被一帧帧拉长，慢放到足以回忆起一生的欢喜和忧伤。我想晏几道在人生的终点闭上双眼的时候，或许是含着期待去的。在离去的那一个，一生的岁月如走马灯一般略过眼前的时候，他终于可以再一次回味那时候的欢喜，回味那个彩袖飞舞的相逢。</p>]]></content>
    
    
    <categories>
      
      <category>散文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【中华文明通论 期末论文】元代之后陆上丝绸之路凋敝的必然性</title>
    <link href="/2022/05/28/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%85%83%E4%BB%A3%E4%B9%8B%E5%90%8E%E9%99%86%E4%B8%8A%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%E5%87%8B%E6%95%9D%E7%9A%84%E5%BF%85%E7%84%B6%E6%80%A7/"/>
    <url>/2022/05/28/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E4%BA%BA%E6%96%87%E8%AF%BE%E8%AE%BA%E6%96%87/%E5%85%83%E4%BB%A3%E4%B9%8B%E5%90%8E%E9%99%86%E4%B8%8A%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%E5%87%8B%E6%95%9D%E7%9A%84%E5%BF%85%E7%84%B6%E6%80%A7/</url>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>近年来，丝绸之路研究中，存在重汉唐、轻明清，重海路、轻陆路的倾向。对于丝绸之路的发展和繁盛，有相当多的论文从经济、政治、文化、宗教等各个角度对丝绸之路进行解构和分析。但在元朝之后，明清时代的陆上丝路，由于其衰败，反而少有人提及。本文系统整理元代及以后与陆上丝绸之路相关的军事、政治、经济、文化、科技和自然环境因素的综合变化，论证在元代以后、新中国成立之前，陆上丝绸之路走向凋敝的必然性。</p><blockquote><p>关键词：陆上丝路 凋敝 必然性 元代之后 综合作用</p></blockquote><hr><p>古代陆上丝绸之路的兴衰历程可谓是一波三折：从汉武帝时期的初步形成，到南北朝时期受到中国内地战乱的冲击；从盛唐时期的繁华鼎盛，到宋时期的衰落，又到元代的“回光返照”，最终一蹶不振，为海上丝绸之路所最终取代。为什么在元朝之前，陆上丝绸之路尽管兴衰起伏，但总有复兴之机；而在元之后的五百年里，却彻底凋敝，“已为陈迹”？这是否是必然的？如果是，又有哪些必然的原因呢？本文便试图通过剖析丝绸之路兴盛的原因和元代之后诸多条件的变化，来论证元代以后陆上丝绸之路彻底凋敝的必然性。</p><h1 id="一、背景：陆上丝绸之路的兴衰历程"><a href="#一、背景：陆上丝绸之路的兴衰历程" class="headerlink" title="一、背景：陆上丝绸之路的兴衰历程"></a>一、背景：陆上丝绸之路的兴衰历程</h1><p>古代陆上丝绸之路形成于汉武帝时期：一方面，张骞受汉武帝委托，出于军事目的，前往西域寻找大月氏，欲与之联手，夹击匈奴，但也间接促使汉朝与西域各国形成贸易关系；另一方面，汉武帝南征北战，收河套、逐匈奴于漠北，令细君公主和亲乌孙；正是在汉武帝军事、外交双重手段下，陆上丝绸之路得以初步形成。</p><p>魏晋南北朝时期，中国内部战乱，对丝绸之路形成了一定冲击，但丝绸之路并没有断绝，商业和文化的贸易往来一直在进行着。<br>隋唐时期，中国归于一统，国力堪称鼎盛，对外的经济贸易、政治交流、文化交流都是通过丝绸之路完成的。这段时间可以说是丝绸之路发展历程中的最兴盛时期。</p><p>但是好景不长。围绕安西四镇，大唐和吐蕃殊死争夺。安西四镇几度易手。为了让远离中央的军镇形成合力，唐政府给予节度使极大的权力——这也就为后面安史之乱埋下伏笔。玄宗时期，玄宗用人不当，节度使安禄山做大引发安史之乱，安西都护府大量精兵内援致丝路力量薄弱，最终安西四镇相继失陷。安史之乱后，唐代虽然也出现过明君，主导了三次中兴，但始终也没能把影响力重新覆盖到西域。反而深陷节度使废立泥沼不可自拔。</p><p>宋因为河东节度使石敬瑭割让燕云十六州于契丹，宋朝立国初期面临北面巨大军事压力，一时无暇西顾，定难军节度使世袭至李元昊时终于称帝建立西夏。宋神宗一朝和西夏屡战屡败，永乐城一役更是三十万大军全军覆没。至此中原政权再无力西进。</p><p>蒙古帝国时期，<em>“经过四位汗王半个多世纪的努力，蒙古帝国的版图已经横跨欧亚两大洲，这客观上促使古代欧亚诸民族、族群走出了孤立封闭的地域，逐步摆脱了复杂的陆上丝绸之路的通商关卡，开启了对外交流门户的通道”</em>。[ 孙秀君：《论蒙古帝国时期蒙古人对陆上丝绸之路的贡献》，《西部蒙古论坛》2016年第1期。]</p><p>蒙古帝国作为游牧民族所形成的政权，其游牧性经济势必需求他们与外界进行物资的交换。而蒙古周围存在诸多少数民族政权，诸如金、辽、西夏等。当时仍然处于游牧经济阶段的蒙古，其经济形式仍然处于物物交换的形式，甚至存在“可能还不知道使用货币”[ 《蒙古族简史》编写组、《蒙古族简史》修订本编写组：《蒙古族简史》，民族出版社2009年版，第14页。]的情况。在此背景下，其贸易必然经历其他政权的经济剥削，致使蒙古人必须向西发展贸易。</p><p>成吉思汗在位期间，多次西征南征，攻占乃蛮、征伐西夏，周边少数民族政权都为蒙古所政府或主动归附了蒙古，实现了领土上的大一统。</p><p>在这种背景下，再加之，蒙古政权游牧民族的本质所带来的重商主义让蒙古政权的政策非常重视商业贸易。<em>成吉思汗曾经派遣了450名商人带上几乎等于蒙古帝国初期所有的财产和国书去花剌子模经商，可见其对商业和商人的重视以及对能与邻国长期友好通商往来的期盼。</em>[ 孙秀君：《论蒙古帝国时期蒙古人对陆上丝绸之路的贡献》，《西部蒙古论坛》2016年第1期。]</p><p>不仅如此，蒙古政权还采取了一系列措施来保障丝绸之路的交通和贸易，如修路设驿、驻军遣官等。元朝统治期间，陆上丝绸之路再度繁荣起来。<br>元朝之后，陆上西部丝绸之路从未中断，但是它在明清以来东西文化交流中日渐边缘化。清代的陆上丝绸之路衰落起始，学界有所争议。有学人认为持续到18世纪，“历时两千五百多年、横亘欧亚大陆的丝绸之路是人类文明的运河，东西方文化交流的桥梁。在公元后，以中国、印度、罗马帝国、安息（波斯）和阿拉伯世界为枢纽，汇聚欧亚主要文明和沿途各民族文化的丝绸之路的功能和格局，一直延续到18世纪末，直到19世纪西方列强掀起瓜分世界的狂潮，丝绸之路平等文明的经济文化交流被打破为止”[ 吴四伍：《明清时期陆上西部丝绸之路再审视》，《历史档案》2019年第2期<br>]。但总体而言，元代以后，陆上丝绸之路失去其原有的经济地位，只剩下少量官府主导的、含有政治性的贸易，并且绝大多数作用由海上丝路贸易取而代之，是不争的事实。</p><h1 id="二、陆上丝绸之路兴盛的必要条件"><a href="#二、陆上丝绸之路兴盛的必要条件" class="headerlink" title="二、陆上丝绸之路兴盛的必要条件"></a>二、陆上丝绸之路兴盛的必要条件</h1><p>观察陆上丝绸之路的兴衰历程，我们不难发现，陆上丝绸之路最为兴盛的三个时期：汉、唐、元，都具有某些相似的特征：军事上实力强大、政策上放开商业、文化宗教上外向包容……进一步归纳，我们可以从六个角度分析丝绸之路兴盛的必要条件：</p><ul><li>军事因素。陆上丝绸之路途经一连串不同的地域。以西汉时期长安为起点（东汉时为洛阳），经河西走廊到敦煌。从敦煌起分为南北两路：南路从敦煌经楼兰、于阗、莎车，穿越葱岭今帕米尔到大月氏、安息，往西到达条支、大秦；北路从敦煌到交河、龟兹、疏勒，穿越葱岭到大宛，往西经安息到达大秦。当地国家政权与民族地区的控制，势必影响丝绸之路的全线畅通。因此，丝绸之路的稳定需要<strong>一个军事实力强大的中原政府</strong>，至少需要能够实际控制河西走廊地区，并对周围的政权形成强而有力的威慑。</li><li>政治因素。陆上丝绸之路的本质是商业贸易和宗教传播。作为丝绸之路的一极，<strong>中原政府是否对各种文化宗教充满包容、是否重视商业</strong>，直接决定了丝绸之路的兴盛与否。</li><li>经济因素。陆上丝绸之路“贸易”的性质决定了西域诸国必须有各自的特色，才能在贸易中有攫取利益的能力。倘若西域国家都经济凋零，那“贸易”就会无所进行——<strong>西域的蓬勃发展无疑是陆上丝绸之路的重要支撑。</strong></li><li>文化因素。汉、唐时期，中原丰富而多彩的文化对西域人民的冲击和震撼是难以言喻的。在中原文化的辐射下，中原政权与西域诸国的关系建立更为顺畅，与中国进行贸易的商人在路途中的隐性成本无疑被大大降低。因此，<strong>中原文化的强大向心力，是丝绸之路兴盛的重要条件。</strong></li><li>科技因素。海上丝绸之路开辟于汉代，可那个时候人类的造船技术和航海技术的落后，使得海上丝绸之路并不兴盛。自唐代开始普及效率更高的磁针开始，加之中国的造船技术的持续发展，天文知识的不断积累，中国的航海技术越来越发达，跨洋航行越来越成熟。在技术成熟的条件下，航海贸易下的海上丝绸之路比陆地丝绸之路更有效率，也相对更安全。因此，<strong>陆上丝绸之路的兴盛是建立在海上丝绸之路难以维系的前提下的。</strong></li><li>自然因素。丝绸之路经过的沙漠地区，其自然环境——如绿洲的密度、沙尘暴的频率等等，对商人的影响是巨大的。因此，<strong>丝绸之路的兴盛无疑需要良好的沿线自然环境。</strong></li></ul><p>以上可以看出，丝绸之路的兴衰是多种因素复合作用的结果，军事、政治、经济、文化、科技和自然因素缺一不可。不难推断，元代之后，陆上丝绸之路的彻底凋敝也与这些因素的不可逆变化有着密不可分的联系。</p><h1 id="三、陆上丝绸之路的衰败"><a href="#三、陆上丝绸之路的衰败" class="headerlink" title="三、陆上丝绸之路的衰败"></a>三、陆上丝绸之路的衰败</h1><h2 id="1-军事-政治角度：元之后中原对西域的失控"><a href="#1-军事-政治角度：元之后中原对西域的失控" class="headerlink" title="1. 军事&amp;政治角度：元之后中原对西域的失控"></a>1. 军事&amp;政治角度：元之后中原对西域的失控</h2><p>通过比对汉（武帝）、唐（玄宗，前期）、宋、元、明五个时代的地图，我们可以很清楚地看到中原政府所能控制的实际领土的大小：</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222151749.png"></p><p>图 1: 汉武帝时期中原政府领土</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222151844.png"></p><p>图 2: 唐前期中原政府领土</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222151855.png"></p><p>图 3: 北宋时期中原政府领土</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222151900.png"></p><p>图 4: 元时期中原政府领土</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222152030.png"></p><p>图 5: 明朝时期中原政府的领土</p><p>纵观五朝地图，我们可以发现：丝绸之路贸易往来繁荣的三个朝代——汉、唐和元，中原政府的军事控制力均能够有效地蔓延到西域。或者说，古代丝绸之路这样的贸易线路的本质，是 <strong>“依附于某个中央强权的松散小邦合集”</strong> ——中原政府无疑扮演着这样一个“中央强权”的角色：其与周边国家之间，看似具有明确的臣属关系，但实际上完全是以利益为纽带的。如果出现某些变故，导致中央“强权”军事控制力的削弱，周围的小政权就会立刻反噬，为各自的利益进行一系列行动。</p><p>而值得注意的是，明朝以后，中国再无向外扩张的行动。一方面，宋朝的理学鼓吹“华夷之防”，让儒生主导的中原政权整体策略转入以防守为主，失去了向外的动力——自然也不会去经略西域；另一方面，目前的历史经验已经可以说明，唐朝的节度使制度是古代生产条件下唯一能够在远离中原的边陲建立长效统治的制度，但宋朝以后，出于政权稳定性的考虑，中央对武将可能的拥兵自重加以高度提防，彻底断绝了节度使的产生。没有军政一体的节度使在边境进行组织，中原政权自然也失去了维持丝路稳定的能力。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222152123.png"></p><p>图 6: 十五世纪奥斯曼帝国的领土</p><p>值得一提的是明朝初年，中亚地区，奥斯曼土耳其政权的崛起。奥斯曼帝国作为15到19世纪唯一能与欧洲国家抗衡的伊斯兰势力，坐落于东西文明的交汇处，掌握东西文明的陆上交通线达六个世纪之久，直至大英帝国在18世纪通过直布罗舵打通地中海航线为止。奥斯曼帝国天然掌握了丝绸之路沿线的大部分地域。奥斯曼帝国出于自身利益，隔绝陆上丝绸之路的贸易，进一步导致了陆上丝绸之路的衰落。</p><p>两方面因素的综合作用下，元朝以后，中原政权的军事影响力彻底退出河西走廊等地带，对丝绸之路沿线失去了控制力，原本依赖于中原政权军事保障的陆上丝绸之路也随之逐渐衰落下去。</p><p>当然，这并不意味着中国与欧洲经济、文化交流的结束。欧洲大航海时代的开启、中国海上丝路的开辟，都是在这种情况下作出的应对之策。这些应对之策所产生的新交流方式和贸易路线，最终逐渐取代了原本陆上丝路的地位。这部分内容将会在“科技因素：航海技术的发展与海上丝绸之路的兴起”中进行更加详细的分析和叙述。</p><h2 id="2-经济角度－中原：明清社会经济倾向的改变"><a href="#2-经济角度－中原：明清社会经济倾向的改变" class="headerlink" title="2. 经济角度－中原：明清社会经济倾向的改变"></a>2. 经济角度－中原：明清社会经济倾向的改变</h2><p>元代之后的明清时期，政府采取重农抑商的经济政策，实行对商品经济的垄断。其中，除了对食盐和茶叶的垄断之外，明清时期对于民营手工业也实行了严格制裁，具体表现为：</p><h3 id="2-1-实行严格的等级进贡制"><a href="#2-1-实行严格的等级进贡制" class="headerlink" title="2.1. 实行严格的等级进贡制"></a>2.1. 实行严格的等级进贡制</h3><p><em>“明清时期的统治者为了实行更好地统治，倡导节俭制度，尤其是明太祖朱元璋，颁布的《大明律》中，严禁官吏贪污。并且身体力行，带头倡导节俭。《大清律》同样有类似的内容。”</em>[ 《重农抑商政策与明清社会经济》，《史志研究》总第396期]但是，到了明清两代的中后期，统治阶级的生活仍然不可避免地奢侈起来。为了维护其作为统治阶级的利益，其需求不可能全部通过商品买卖的方式获得。</p><p>为此，明清政府采用“任土作贡”的制度：所需物品由相应的产区直接供应，以便实现统治阶级的直接使用；各地按照相应的等级，对于各种需要的物品由民间直接进贡。——比如，隆庆六年，令 <em>“广东采珠八百两</em>”[ 张廷玉《明史》，北京：中华书局，1974]，由官府以极低的价格出钱购买，加之官员中饱私囊，一般平民和小商人不堪重负，“相率避匿”。</p><h3 id="2-2-实行官营手工业以缓解供需矛盾"><a href="#2-2-实行官营手工业以缓解供需矛盾" class="headerlink" title="2.2. 实行官营手工业以缓解供需矛盾"></a>2.2. 实行官营手工业以缓解供需矛盾</h3><p>明清政府开办政府控制下的手工工场以解决供需矛盾。例如，工部在北京城内外设置了诸如崇文门外的神木厂等五大厂成为为官府服务的官窑以及官场，商业发展具有浓厚的官府控制色彩[ 肖溱《重农抑商政策与明清社会经济》，《史志研究》总第396期]。</p><p>由此可以看出，相比于汉、唐时期相对发达的民营手工业来说，明清时期大量的官营手工业主要只是负责供给统治阶级的需求。</p><p>历朝历代的工业结构都是以官工业为主的。但是，在中国商品经济较为繁荣的时代——例如唐代，即使官工业占据工业结构的统治地位，仍然不能阻止私营手工业的发展。<em>“唐代的手工业除官工业外，基本上都是商品生产”</em>[   傅筑夫《唐宋时代商品经济的发展与资本主义因素的萌芽》]。另一方面，唐代也有规模极大的私营工业。如 <em>“唐定州何明远，大富，主官中三驿，每于驿边起店停商，专以袭胡为业，资财巨万，家有绫机五百张”</em> [ 《太平广记》，卷二百四十三，何明远条]，他生产的商品，有很大一部分都流入市场进行交易——丝路上的很多手工业品都来源于此。</p><p>而明清与之相比，对于商品经济的打压则更加彻底：政府实行严格的户籍管理制度，将农业经济作为社会发展的主产业；向农民征收沉重的赋税，让农民的生活水平低下，没有多余的资本去市场购买商品。在这种背景下，人们从事商业经济几乎都是无奈而为之——也导致从事商业经济的商人素质偏低，难以突破自身的眼界和经历限制。</p><p>在这种背景下，丝路经济的重要支柱：中国对外的手工业品输出，被充分地遏制了。对于在元朝之后，已经逐渐衰落停摆的陆上丝路而言，这一事实更是雪上加霜。因此，陆上丝路在元代之后不可逆地衰落下去，从中原的社会经济结构的角度来分析，无疑是一种必然。</p><h3 id="2-3-经济角度－西域：蒙古西征之后西北地区人口、经济的凋零"><a href="#2-3-经济角度－西域：蒙古西征之后西北地区人口、经济的凋零" class="headerlink" title="2.3. 经济角度－西域：蒙古西征之后西北地区人口、经济的凋零"></a>2.3. 经济角度－西域：蒙古西征之后西北地区人口、经济的凋零</h3><p>蒙古帝国历史上有三次较为大规模的西征。</p><table><thead><tr><th>蒙古历史上的三次西征</th><th>时间&#x2F;公元</th><th>执政者</th><th>进攻目标</th></tr></thead><tbody><tr><td>第一次西征</td><td>1219年</td><td>成吉思汗</td><td>花剌子模、中亚、伊朗、阿富汗</td></tr><tr><td>第二次西征</td><td>1235年至1241年</td><td>窝阔台</td><td>保加利亚、俄罗斯、波兰、匈牙利等</td></tr><tr><td>第三次西征</td><td>1251年至1259年</td><td>蒙哥</td><td>伊朗、阿拉伯、叙利亚</td></tr></tbody></table><p>表 1: 蒙古帝国的三次西征</p><p>由上表，我们可以感受到蒙古帝国扩张期间对欧洲的军事行动之频繁。</p><p>虽然蒙古对于欧洲地区有多次军事行动，但是事实上，蒙古对于西欧的“土地”并不感兴趣——至少在当时是如此。蒙古攻打匈牙利的主要原因是政治性的：警告贝拉对库曼人提供保护甚至拒绝将库曼人交出来的行为。残酷的屠杀昭告了这样一个事实：抵抗必然遭到惩罚，不惜一切代价。</p><p>正因为蒙古帝国的军事行动并不以统治，而以惩戒为目的——其给被征服地区带来的灾难也格外深重。大量的文献资料生动地描绘了1219年蒙古人进攻花剌子模时的凄惨场景：</p><p>入侵者 <em>“来了，打了仗，放了火，杀了人，抢了东西，然后离开了”，一位历史学家这样写道。我宁愿没生在这世上，那样就不必亲历如此残酷的场景了，另一位作者说。穆斯林只求消灭他们的基督教敌人，但蒙古人不一样，他们“谁都不放过，他们杀女人、杀男人、杀孩子，甚至将孕妇开膛破肚，杀死还未出生的胚胎”。</em>[ 彼得·弗兰科潘《丝绸之路：一部全新的世界史》，第九章：地狱之路]</p><p>概而言之，蒙古帝国西征所到之处的城市和地区都遭到严重的倒退和破坏，其人口、生产力和文化都经历了残酷的摧残和蹂躏。他们所采用的“焚城”和“屠城”的手段，对于途径国家都造成了毁灭性的打击。</p><p>西北诸国深受其害，以西藏地区为例：西藏人口在 <em>“七世纪强盛时期，约有五百万至九百万”</em> [ 《西北人口》1982年第2期]，而在 <em>“十三世纪，蒙古人一统西藏地区时，藏族人口不可能超过三十万”</em> [ H·E·Richardson:《Tibet and its history》, ]。可见，蒙古帝国的征伐给西藏地区带来的毁灭性打击。</p><table><thead><tr><th>时期</th><th>西藏地区人口</th></tr></thead><tbody><tr><td>七世纪（唐朝，西藏为吐蕃统治）</td><td>一千万人左右</td></tr><tr><td>十三世纪（元朝统治期间）</td><td>数十万人</td></tr><tr><td>十七世纪（清代雍正时期）</td><td>一百二十万人左右[ 见《西藏历史新篇章》 ]</td></tr></tbody></table><p>表 2: 西藏地区在不同时期的人口变化</p><p>正是这种摧残，让西域地区的各个国家在蒙古帝国的远征结束之后，仍然没有足够的自我恢复、繁衍和发展的能力。相比于中原而言，西域本来就脆弱的自然环境和薄弱的农业生产基础，让西域的人民遭遇了更大的苦难：人口的减少带来土地的荒芜，于是百姓更加流离失所，形成的大量流民在叛军组织下烧杀抢掠，如此往复、恶性循环。纵使忽必烈在西域采取屯田策略，仍然无法挽回长期战争所带来的破坏。</p><p>元代之后，西北地区再无重新繁盛的能力。明朝中叶，东察合台汗国演变为叶尔羌汗国（1514－1678年），直到清朝初年才被由瓦剌演变而来的漠西蒙古所灭。清代，漠西蒙古成为新疆重要势力，准格尔部在康雍乾三朝与清军进行了长期的军事冲突，最终在乾隆朝彻底平定，中央王朝重新在新疆建立统治。乾隆朝间相继平定大小和卓叛乱，并迎回东归的漠西蒙古土尔扈特部，此后直至清末，一直对新疆进行着稳定的——但也仅仅是稳定的统治。但随着清朝势力的衰落与西方列强的兴起，最终丢失了巴尔喀什湖以东以南的50万平方公里领土，一度全疆陷落于中亚的浩罕王国。直到左宗棠率领湘军收复新疆，并于1884年设立新疆省。</p><p>总而言之，蒙古西征之前，西北地区的人口总体在随时代的进步而缓慢发展。但在经历数十年战火的摧残之后，西北地区元气大伤，与中原地区的贸易也随之凋零衰败下来。蒙古帝国出于“惩罚”而非“统治”的征伐，直接导致在西征结束之后，丝绸之路在西北地区沿线诸国再无力如汉、唐时期那般积极主动地谋求参与陆上丝路的贸易，这也是元代以后，陆上丝绸之路彻底凋敝的重要原因。</p><h2 id="4-文化角度－以河湟地区为例，元明时期西域伊斯兰教的传播发展"><a href="#4-文化角度－以河湟地区为例，元明时期西域伊斯兰教的传播发展" class="headerlink" title="4. 文化角度－以河湟地区为例，元明时期西域伊斯兰教的传播发展"></a>4. 文化角度－以河湟地区为例，元明时期西域伊斯兰教的传播发展</h2><p>河湟地区，指黄河上游、湟水流域、大通河流域，古称“三河间”，主要包括今天青海东部地区和甘肃西部与青海接壤地带。这一地区是陆上丝绸之路和唐蕃古道两条大动脉的交汇处。这里是伊斯兰教传播较早的地区。</p><p>伊斯兰教很早就在河湟地区传播了。其传入的时间可以上溯到一千多年以前。河湟正值丝绸之路的要津，特别是唐宋以来，丝绸之路的河湟支线空前繁荣，有的来甘青经商的大食人和波斯人就在河湟一带安家落户，这些外来民族就是河湟地区最早的穆斯林和伊斯兰教的传播者。</p><p>元代，河湟地区的穆斯林数量达到了前所未有的高峰。新入居河湟的穆斯林大大人数超过了以往各个时期，主要包含以下几类：[ 余超，《浅探元明时期河湟地区新民族的形成与伊斯兰教的传播发展》，《学海纵横》]</p><table><thead><tr><th>新入居的穆斯林</th><th>例子</th></tr></thead><tbody><tr><td>亚洲西部各族</td><td>西突厥乌古思部的撒鲁尔人，中亚突厥中的撒尔塔人，“回回军”中的其他部落</td></tr><tr><td>国内河湟地区以外迁居于此的穆斯林</td><td>信仰伊斯兰教的流亡西夏人</td></tr><tr><td>皈依伊斯兰教的国内其他民族</td><td>元西宁王速来蛮及其所属部众</td></tr></tbody></table><p> 总的来说，在“1.军事&amp;政治角度：元之后中原对西域的失控”中，我们论述过，古代丝绸之路这样的贸易线路的本质，是 <strong>“依附于某个中央强权的松散小邦合集”</strong> 。这种“强权”，不仅是军事上的，也是文化上的。</p><p>在汉、唐时期，周边的小政权在派出使团参观过中原地区以后，都确确实实以中国为“天朝上国”，抱着憧憬和学习的心态对待中原地区与其所推崇的儒家文化。正是这种无形的文化崇拜，让中原政府在对周边区域进行行政控制变得更加简单：他们自带了一种“先进”的标签，这种标签，让当地民众对于中原地区的管理和统治方式天然地亲近和向往。这极大地减少了中原政府传播自身影响力的隐藏成本，对于陆上丝绸之路的维系和稳定具有极大的帮助。</p><p>而随着伊斯兰教的传播，儒家文化在以河湟地区为代表的西域地区影响力逐渐减弱。这个时期，河湟地区有诸多新民族形成，诸如回族、保安族、撒拉族、东乡族等等，这直接与伊斯兰教的传播相关：<em>“一方面，河湟地区信仰伊斯兰教的新民族的形成得益于伊斯兰教的传播；另一方面，这些民族形成之后又进一步促进了伊斯兰教的传播。”</em>[ 余超，《浅探元明时期河湟地区新民族的形成与伊斯兰教的传播发展》，《学海纵横》]这些原本由元朝安置在丝路沿线的民族随着时代发展，形成了自己独有的文化，而不再以汉文化或佛教文化为主。这无形中是中原“中央强权”文化霸权的衰退。随着中原政府军事霸权的衰落，西域诸小邦在文化上也不再对中原抱有依赖性。</p><p>文化霸权的衰退是隐形和持久的。在双方都没有意识到的时候，随着信仰的变迁和民族的迁徙，“泱泱华夏”的文化影响力在不断衰弱着。这是陆上丝路衰败不可忽视的重要推手。</p><h2 id="5-科技角度－航海技术的发展与海上丝绸之路的兴起"><a href="#5-科技角度－航海技术的发展与海上丝绸之路的兴起" class="headerlink" title="5. 科技角度－航海技术的发展与海上丝绸之路的兴起"></a>5. 科技角度－航海技术的发展与海上丝绸之路的兴起</h2><p>尽管明代在明太祖朱元璋立国之初就规定“片板不许下海”，但并不意味着明代航海技术无所发展。相反，明代是我国造船技术取得重大突破的时代：明代造船技术取得重大突破，如船舶体积增大和配套设施齐全，郑和下西洋所用的船，在当时世界上是最先进的。同时，航海技术也日趋成熟，尤其是天文和地文航海技术的运用，将我国古代航海技术又向前推进了一大步。</p><p>《两种海道针经》是由《顺风相送》和《指南正法》两本航海科技专著所组成的。此书反映了明代航海科技的明显进步，比如[   孙光圻《明清航海》，世界海运2011年第11期]：</p><ol><li>观测方法更为精细，如定潮水消长，除了时刻之外，配以水色、流向和海生物等等资料。</li><li>出现了新的定位与导航技术，如定三方针法和定四方针法。</li><li>航路指南更加具体。</li></ol><p>在这种背景下，即使明清时代均有较严格的海禁政策，海上丝绸之路依然发展了起来。</p><p><em>“海上丝路”的南北航线在元明时期达到最大程度的交融。元明时期的中国，经济中心在南方而政治中心在北方，相对先进的航海技术使得南北方之间的海运成为保证南方粮食、丝绸、瓷器等北上的重要运输方式。在对外贸易上，明朝中期的郑和率船队七下西洋，开创了中国远洋航海的新时代。</em>[ 《“丝绸之路”是谁发明的》，人民网]</p><p>在这一时期，明代海上丝绸之路的航线已经扩展到全球：向西航行，有郑和七下西洋；向东航行，也有“广州－拉丁美洲航线”。<em>这样，开始于汉代的海上丝绸之路，经唐、宋、元日趋发达，迄于明代，达到高峰。郑和远航的成功，标志着海上丝路发展到了极盛时期。</em>[ 《海上丝绸之路千年兴衰史》，人民网]</p><p>在技术成熟的条件下，海上贸易是比陆上贸易更加有效率和安全的选择。陆上丝路的贸易，需要货源、市场需求、专门从业人员（商人）、便利的交通设施、保证贸易畅通的环境等一系列环境。而海上丝路，在有成熟的导航技术和大船的情况下，不光运力远高于依赖驼夫和骆驼的陆上运输，海运的速度也比陆运快上一筹：<br>古代马的时速大概在35km&#x2F;h左右，和明清时代的船只相当。考虑到丝路的路况艰难，并且骆驼的时速比马更低一些，加上旅人需要休息，可以计算出陆上丝路的实际时速在海上丝路的一半左右。</p><p>考虑到海上丝路需要绕路，两者在时效上并没有很明显的差距，因此运输效率的差距就成了海上丝路优异的主要因素。明代时期，船只的排水量就已经达到了数万吨（郑和的旗舰“宝船”排水量足有2.5万吨）。这是海上丝路的最大优势。</p><p>因此，在陆上丝路逐渐衰败的同时，这部分贸易需求被很好地转移到了海上丝路——换言之，海上丝绸之路是更优的替代选择。这是一个不可逆的过程。因此，在海上丝绸之路兴起的同时，陆上丝绸之路的衰落就成了无可逆转的过程。</p><h2 id="6-自然角度－以罗布泊地区为例分析西部地区的自然气候变迁"><a href="#6-自然角度－以罗布泊地区为例分析西部地区的自然气候变迁" class="headerlink" title="6. 自然角度－以罗布泊地区为例分析西部地区的自然气候变迁"></a>6. 自然角度－以罗布泊地区为例分析西部地区的自然气候变迁</h2><h3 id="6-1-罗布泊地区的重要意义"><a href="#6-1-罗布泊地区的重要意义" class="headerlink" title="6.1. 罗布泊地区的重要意义"></a>6.1. 罗布泊地区的重要意义</h3><p>罗布泊地区对于古代丝绸之路的中外交通繁荣具有重要意义：</p><p>首先从地理位置看，这里连接着河西走廊与地域的广大地区，自东向西分别形成以敦煌和楼兰为中转枢纽的丝绸之路交通网络。而就文化交往而言，罗布泊地区是中外文明传播交流的前沿阵地，荟萃着华夏文明、印度文明、伊朗文明和希腊文明等亚欧大陆诸多文明。</p><p>汉唐时期所谓“汉唐盛世”，除了国家稳定、军事强大、文化昌盛等原因之外，积极展开对外交流也是呈现于传播中国盛世形象的主要推动力。因此，作为当时沟通中国与外部世界的主要通道之一，其盛衰变迁不仅体现了中原社会变革的兴衰起伏，也影响着古代陆上丝绸之路东西文明交往的沉浮历程。[ 唐尚书《汉唐间罗布泊地区的环境演变研究》]</p><h3 id="6-2-罗布泊地区的自然气候变迁"><a href="#6-2-罗布泊地区的自然气候变迁" class="headerlink" title="6.2.罗布泊地区的自然气候变迁"></a>6.2.罗布泊地区的自然气候变迁</h3><p>两汉至西晋时罗布泊地区气候大体经历着逐渐由暖湿转向冷干类型变化的过程。从西汉时罗布泊沿岸植被“多葭苇、柽柳、胡桐、白草”之情况以及两汉时期楼兰等地兴盛的屯田活动也可以印证罗布泊地区水源较充足与当时气候暖湿背景有关。</p><p>魏晋时期冷干气候使得罗布泊地区面临着水资源日趋减少与沙漠化日益扩大等生态失衡的情况，深刻影响着当地人们的生产生活。楼兰简牍文书内容曾反映出魏晋时期楼兰地区士兵日用口粮大幅减少，由两汉楼兰全盛时期口粮人均一斗二升的标准降低到了而西晋泰始年间人均日食五升、六升。楼兰尼雅240号文书记载：<em>“出黑粟三斛六斗禀战车成辅，一人日食一斗二升起二月一尽卅日，咸熙三年二月一日监。”文书中的曹魏咸熙三年（266）表明当时还保持着人均每天供应口粮一斗二升。然而此后的时期已经有了明显的减少。</em>[ 唐尚书《汉唐间罗布泊地区的环境演变研究》]</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222153008.png"><br>图 7: 魏晋以后罗布泊水系推测图</p><p>南北朝时期气候长期干旱背景下，社会政权交替混乱以及绿洲生态脆弱地区 的水土开发等人类活动行为的耦合叠加进一步改变了区域景观形态，同时也加剧 了罗布泊地区自然环境变迁的进程。</p><p><img src="https://raw.githubusercontent.com/HypoxanthineOvO/HypoImager/main/20240222153034.png"></p><p>图 8: 唐代寒暖气候事件累计曲线图</p><p>隋唐时的自然气候处于竺可桢学说中的温暖期。学界又将该时期称之为隋唐温暖期或普兰店温暖期，其温暖程度“如与现代气候相比较，则当时年平均温度高1℃左右，气候带的纬度北移1°左右”。</p><p>满志敏先生的结论认为唐代并不是一个稳定的温暖期，以8世纪中叶为界分为两个阶段：8世纪50年代以前是温暖期，而8世纪60年代以后气候变寒冷。[  满志敏《关于唐代气候冷暖问题的讨论》，《第四纪研宂》1998年第1期，第20-30页。]</p><p>众所周知分布在罗布泊地区的河流水系主要依靠南北两边的高山冰川融水，其河水径流量受季节变化影响明显。湿润时期降水量增多，高山冰川的雪线降低，冰川面积增加，因此河流水源补给充足，有利于绿洲的稳固发展。反之在气候干旱时期区域而蒸发量大，高山雪线升高、冰川后退，致使河流水源补给不足，进而造成终端湖罗布泊面积衰减收缩，同时也造成绿洲土地涵养水分能力进一步减退甚至消失，加剧地区土地干旱化与沙漠化程度。可见对于干旱和半干旱地区而言，气候干湿情况的影响相比冷暖类型的影响更为重要与深刻。</p><p>从《隋书》《旧唐书》等正史文献中的干旱、水涝等自然灾害的记录：</p><table><thead><tr><th>年份</th><th>干旱次数</th><th>洪涝次数</th></tr></thead><tbody><tr><td>581-600</td><td>4</td><td>2</td></tr><tr><td>601-620</td><td>4</td><td>2</td></tr><tr><td>621-640</td><td>8</td><td>3</td></tr><tr><td>641-660</td><td>4</td><td>5</td></tr><tr><td>661-680</td><td>4</td><td>1</td></tr><tr><td>681-700</td><td>3</td><td>3</td></tr><tr><td>701-720</td><td>3</td><td>2</td></tr><tr><td>721-740</td><td>4</td><td>3</td></tr><tr><td>741-760</td><td>0</td><td>3</td></tr><tr><td>761-780</td><td>3</td><td>2</td></tr><tr><td>781-800</td><td>2</td><td>4</td></tr><tr><td>801-820</td><td>4</td><td>4</td></tr><tr><td>821-840</td><td>3</td><td>6</td></tr><tr><td>841-860</td><td>2</td><td>2</td></tr><tr><td>861-880</td><td>4</td><td>1</td></tr><tr><td>881-900</td><td>2</td><td>0</td></tr></tbody></table><p>表格注释：</p><ol><li>施雅风《中国西北气候存暖干向暖湿转型的特征和趋势探讨》，《第四纪研究》，2003年第2期，第 161 页。</li><li>张敏《自然环境变迁与十六闺政权割据局面的出现》，《史学门刊》2003年第5期，第24页。</li><li>注：正史文献的灾害记录中有的可能只是反映的某个特定州县等显然不具有地域代表性。例如：麟德二年（665） <em>“六月，州大水，坏居人庐舍。”</em>；光化三年(900) <em>“冬，京师旱，至于四年春。”</em>因此在进行数据统计时只针对当时自然灾害地理范围相对比较大的年份视为有效数据。本研究所采用的以同时期自然灾害影响州县数馈超过十个为参考标准。</li></ol><p>表 2: 隋唐时期（581-900）自然灾害数量统计表（以二十年为尺度）</p><p>吴敬禄等学者对新疆艾比湖地区近1500年来气候演变的研究结论中认为“公元500-660年，温度较高且较干。大约公元620年发生有一次明显的暖干气候事件：公元660-760年，温度较前期有所降低但气候干湿波动大：公元760-1050 年，温度降低湿度增加。尤其是公元900-1050年间时段体现了气候偏冷湿。”[  吴敬禄、刘建军、王苏民《近1500年来新观艾比湖同位素记录的气候环境演化特征》，《第四纪研宂》， 2004年第5期，第587页。]另外《中国历朝气候变化》中论述：“对天山东段巴里坤湖泊沉积物地化特征的 综合分析表明，隋唐时期当地气候以为界，表现出前湿后干的特征。”[  葛全胜等著《中国历朝气候变化》，第321页。]上述结论与计量分析结果所反映出的隋唐时期我国西部气候干湿变化情况基本一致。由此也推断出隋唐罗布泊地区的气候以大体以公元8世纪中期为界经历了由暖湿到冷干的转变。其中隋唐换代之际还带有魏晋寒冷期向中世纪暖期过渡阶段部分冷干气候的残余。以当时西北地区突厥内部发生的气候灾害为例，一个是隋朝初年突厥境内发生有干旱和蝗灾事件。《隋书·突厥传》记载：“去岁四时，竟无雨雪，川枯蝗暴，卉木烧尽，饥疫死亡，人畜相半。”[    [唐]魏征等撰《隋书》卷84《突厥》，第1867页。]表明当时气候的冷干性质。另外唐贞观三年（629）突厥境内出现“其国大雪，平地数尺，羊马皆死，人大饥”[  [后晋]刘岣等撰《旧唐书》卷194《突厥上》，第5158页。]以及“塞北霜旱，糇粮乏绝”[  [北宋]司马光编著《资治通鉴》卷193《唐纪九》，北京：中华书局，1976年，第6065页。]等寒冷十旱灾难严重的情况。</p><p>唐代安史之乱后罗布泊地区便游离于中原治理体系之外，先后辗转依附于张氏归义军、仲云、沙州回鹘等政权。正如马端临《文献通考》中评论隋唐时期河西地区社会变迁时云：“盖河西之地，自唐中叶以后，一论异域，顿化为龙荒沙漠之区，无复昔之殷富繁华矣。唐自安史之乱，西北土地皆不能如旧。然北方如卢龙、沧景虽世为强藩所据，自擅其兵赋而奉正朔、请旌节，犹唐之臣也。风声气习文物礼乐犹承平之旧也。独西陲沦于吐蕃，遂有夷夏之分，致使数百年中华衣冠之地，复变为左衽，不能自拔。”[  [元]马端临撰《文献通考》卷322《舆地考八北京：中华书局，1986年，第2537页。]该评论从文化变迁的角度指出唐中期吐蕃占领之后的河西地区也包括罗布泊地区已经弃绝中原的“风声气习，文武礼乐”而成为“龙荒沙漠”之地，同时也可以推断出安史之乱后罗布泊地区生态环境此前一度改善良好的情况再度陷入停滞与倒退之中。</p><p>这一系列气候变化直接提高了陆上丝绸之路上商人运输的成本。从唐之后，丝路的重心逐渐从陆地转移到海上，沿线自然环境逐渐恶化产生了很大的影响。</p><h1 id="四、结论：陆上丝绸之路的衰落是综合因素导致的必然"><a href="#四、结论：陆上丝绸之路的衰落是综合因素导致的必然" class="headerlink" title="四、结论：陆上丝绸之路的衰落是综合因素导致的必然"></a>四、结论：陆上丝绸之路的衰落是综合因素导致的必然</h1><p>综合全文来看，从这几个角度，我们都能推出丝绸之路在元代之后行将凋敝的结论：</p><ul><li>从军事角度来说：元代之后中原政府基本失去了对河西走廊等西北地域的控制，难以支持对丝绸之路的维系；</li><li>从经济角度来说：元代之后中原的经济政策趋向内向和保守，严格控制民间的对外贸易；陆上丝路沿线的各个小政权被蒙古帝国的屠杀摧残的元气大伤，大量经济产出用于自身的恢复而非对外交易上；</li><li>从文化角度来说：中原儒家文化和佛文化在西域的影响力随着伊斯兰教的传播而逐渐消退，直接导致了中原文化影响力的减弱，加速了丝绸之路的凋敝；</li><li>从科技角度来说：成熟的航海技术催熟了海上丝绸之路，逐渐取代了原本陆上丝路的地位，政府不再有维护陆上丝路的理由和动力；</li><li>从自然角度来说：丝绸之路沿线同时经历了过度开发和自然气候变迁两个因素的作用，自然环境逐渐恶化，商队的成本大幅增加，遏制了陆上丝路的复兴。</li></ul><p>由此可见，古代陆上丝绸之路在元代之后的凋敝并非是单一因素造成的偶然，而是多重因素同时作用所造成的必然。原先繁荣昌盛的丝绸之路，在时光长河里逐渐沉寂、凋敝，无疑令人惋惜；但是，在它凋零衰落的同时，我们也应从中试图发掘出历史发展和变迁的规律，“以史为鉴、以明当世”，让现世我们的经济发展更加稳定、更加向好。这或许是我们研究历史的重大意义之一。</p><p>〔作者贺云翔，上海科技大学信息学院本科生〕</p><h1 id="文件下载链接："><a href="#文件下载链接：" class="headerlink" title="文件下载链接："></a>文件下载链接：</h1><ul><li><a href="/files/%E5%85%83%E4%BB%A3%E4%B9%8B%E5%90%8E%E9%99%86%E4%B8%8A%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%E5%87%8B%E6%95%9D%E7%9A%84%E5%BF%85%E7%84%B6%E6%80%A7.docx">Docx</a></li><li><a href="/files/%E5%85%83%E4%BB%A3%E4%B9%8B%E5%90%8E%E9%99%86%E4%B8%8A%E4%B8%9D%E7%BB%B8%E4%B9%8B%E8%B7%AF%E5%87%8B%E6%95%9D%E7%9A%84%E5%BF%85%E7%84%B6%E6%80%A7.pdf">PDF</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>文学论文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【高中作品小记】江城忆（二） 灯河</title>
    <link href="/2021/02/20/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E9%AB%98%E4%B8%AD%E4%BD%9C%E5%93%81%E5%B0%8F%E8%AE%B0/%E7%81%AF%E6%B2%B3/"/>
    <url>/2021/02/20/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E9%AB%98%E4%B8%AD%E4%BD%9C%E5%93%81%E5%B0%8F%E8%AE%B0/%E7%81%AF%E6%B2%B3/</url>
    
    <content type="html"><![CDATA[<blockquote><p>“这是沉没在灯河中的我们最后的幻想，企盼我们也有鱼跃龙门，水击三千里的那一天。”<br>——《灯河》</p></blockquote><p>如果你在晚上登上一座有窗的楼来俯瞰街道，你会看到川流不息的灯光，像很多很多坠落于地的银河。</p><p>很巧合的是学校的有一扇大窗户正对着大街，于是每次晚自习我都不自觉欣赏城市的灯光或急或徐的流淌，透过丛丛树叶在稀薄的雾气中抛撒下斑驳的影。刚开始或许未注意到这美妙的变化，但不久后我便沉浸其中，于是每天晚上我都要抽出几分钟溜出教室，潜心欣赏一番灯火城市，欣赏它的春夏秋冬，欣赏它的热闹繁华、车来车往，也欣赏历史的船在时光长河上漂游时，缘舟而落的宝剑深深插入河底的泥土，最终成为各处老房子上凝固的时光，以及人们进出时不经意瞥见的历史侧影。</p><p>作为城里的孩子，我很享受在灯河里漫游，在那“河底”的柏油路上散步。</p><p>你一步步走在斑驳的影中，刺目与柔和的形色灯光在你眼前交替，呼啸而过的车声是流逝着时光的注脚。有行人匆忙安静走过，有三两成群的学生嬉笑着或高谈阔论；穿布衣的大妈们在炉中烧菜，光着膀子的老大爷们聚在马扎上下棋谈天。油腻的柏油路在灯光下五光十色，充满了俗气却又像是另一种形式的仙境，那是所有神明最终的归所，名叫人间。</p><p>——是啊，灯河之底是大地，大地上的是人生百态，是世俗，是红尘。</p><p>红尘万象无不让人留恋。我们渴望着衣锦还乡，渴望着光宗耀祖，所追求的一切不过都是属于红尘的认可。有人沉沦在眼前风尘间，于是他们成为市井，生活都是父母孩子柴米油盐车子房子，想在灯河之底筑一座巢，老婆孩子热炕头，从此了却余生；也有人想游向河面去一览河中全貌，在某个下班或出差的夜晚站在大楼顶上俯瞰着通明的城夜；更有甚者，决意冲出河面，去到那些灯光照不到的地方，那里是云层之上，是太阳和月亮管辖的地方。</p><p>但即使是最最市井的人也梦到过爬上云霄，即使是井底之蛙也会用自己狭窄的眼界去幻想井外的天空。这也是为什么人到了某些时候会爆发出难以想象的力量，因为阳光照过来了——看到篝火的飞蛾怎能不拼命扑火？那时人们的心底焕发出最原始的向往，那时每个人都向上爬。</p><p>因此我们不甘平凡，因此我们勇往直前，我们向往河流入海，那里是鱼的天空。</p><p>突然想到很多精英都喜欢在高楼上买大房子，房子的落地窗直面城市最繁华的街区，在某个夜晚开着雕花吊灯，看一帘城市灯火在你眼前展开。那时候这河流并不只蜿蜒在空间上，更盘桓在时间里。太阳升起的时候灯光退潮而去，留下光裸的大地，打底衫的人们顶着刺目的阳光匆匆忙忙来来去去，虎牙人与人出没在河面的浮游动植物们，退潮的河水将他们留在浅滩上挣扎，相濡以沫或者相忘于江湖。但是任何一个城市都不会缺少我们这样的底层，正如生产者从阳光中攫取能量支撑起宏伟的生态金字塔。来来去去的我们朝九晚五，从事手头乏味或者有趣的工作，像是点燃一颗颗微小的星火，最终星火联结铸成熔炉，熔炉中烧制出一个个精美的工艺品，刻上中国之名展示于世界——这时每个平凡的我们又与伟大连接，不分彼此，这时共同的我们人生间突然又有了交界。</p><p>但我又不太喜欢如那些精英一样离城市太远，年轻的灵魂会觉得这样未免缺乏几分世俗的热闹感。或许我更喜欢在某个五六楼的房间里对着窗户注视着人们的来来往往，哭笑嗔怒，就好像那些情感发生在我自己的身上。</p><p>我是灯河中潜水的鱼儿，在形形色色中棋罢斧烂，想借着世俗的热闹和别人的人生延长自己的人生。</p><p>很多人喜欢看电视剧而我喜欢看小说，喜欢看林雷和迪莉娅在乌山的吻别，看秦羽和姜立在神界的相拥；看林动寻找清竹，看萧炎燃烧异火；看蓝牧的坚持白歌的向往，看墨穷不负上善若水的黑帝之名，看黄极说“我是一个医生，你的文明病了而我要治好他”时的无限自信和肩负。这就像是小时候去看水族馆，你在那种长长的水底隧道里穿过，步行而过的你看见鱼儿游过你身边，你突然宛如鱼儿一样要在这封锁的水底度过一生。于是你惊惶又好奇，把自己当做鱼儿转身游去，游出水族馆游入我们的灯河。电视剧与小说就是我们的隧道，带你捕捉或幻想灯河中转瞬即逝的另一种生活，那种生活的目的是那样高远，即使过程痛苦万分你仍然激动不已，像回到儿时的水族馆里，蓦然发现自己与鱼儿们生出翅膀，化鹏振翅，奔向难以企及又触手可及天空与远方。</p><p>是啊，电视剧与小说，这些文学艺术是在灯河中沉没的我们最后的幻想，企盼自己也有鱼跃龙门、水击三千里的那一天。</p><p>所以我们要挣扎，使出浑身解数，只为一览灯河之外的风景，然后衣锦还乡在灯河中长眠而去，带着全新的梦沉睡而去，美梦永不醒来。</p>]]></content>
    
    
    <categories>
      
      <category>散文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>【高中作品小记】江城忆（一）楼林</title>
    <link href="/2021/02/15/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E9%AB%98%E4%B8%AD%E4%BD%9C%E5%93%81%E5%B0%8F%E8%AE%B0/%E6%A5%BC%E6%9E%97/"/>
    <url>/2021/02/15/%E4%B8%AA%E4%BA%BA%E5%88%9B%E4%BD%9C/%E9%AB%98%E4%B8%AD%E4%BD%9C%E5%93%81%E5%B0%8F%E8%AE%B0/%E6%A5%BC%E6%9E%97/</url>
    
    <content type="html"><![CDATA[<blockquote><p>“他们怀念乡村的草木清新，殊不知我们在棱角分明的楼林间成长，回到原始而质朴的怀抱。”——《楼林》</p></blockquote><p>武汉有个绰号叫“江城”，又有人说武汉是“百湖之城”。每当坐飞机飞向天河机场的时候，俯瞰下的城市总是被倾斜交错的江与河划分成一块又一块，让这城市如纵横错落的荒原；荒原上又有一棵棵枯树屹立，像是人们将给时光立下的纪念碑。</p><p>古人没有飞机：他们的楼肯定很矮，既因为那时尚没有高楼的建筑工艺，又使得他们只需要登上黄鹤楼就能极目远眺，将千里风光尽收眼底。现在则不行：即使现在你于晴天登上武昌那座四百米的世界高楼，也只能看到丛立而起的大厦高楼层层叠叠，遮住了地面的人来人往、灯红酒绿，那是人类给大地穿上的装甲。</p><p>我小时候武汉还不曾有那么多高楼，他们和我一同长大，最终矗立在每一寸天边，站成一座坚实厚重又流光溢彩的钢铁森林：</p><p>这是机械对自然的解构，又是城市孩子的浪漫。如果说过去中国人成长在草原和山川，那现在我们长于森林——楼的森林。我们在森林里攀援上下，每日忙碌不止的去觅食，争斗或求偶，我们在自己创造的全新自然中返祖，又回到数千万年前。那时候人们在丛林和荒原中寻找火种，一如当下的我们寻找全新的精神怀抱。</p><p>最早走过这里的时候，我还不知事。那时武汉天地还是一片荒地，区政府大楼还是三幢民房，江滩没有华丽的单门，如今看来十分土气的洋车在土路上来来往往，弥漫起刺鼻的烟尘。公交车喷着黑烟似在马路上飞行，如《逍遥游》中绝云气负青天的大鸟。</p><p>那时候我害怕过马路，害怕猛兽般咆哮的大车，它们在矮楼间穿行，现在想来他们是如此的简单粗暴，是原始幼稚无所畏惧的幼兽。如今它们成长又成熟，优雅安静，不再咆哮也不再向你冲来，只是在柏油马路上安静地伏行着，带着车上的人和属于他们的故事，驶向他要去的地方。</p><p>车会更新换代，人会长大变老，也有不变的东西。比如黄浦路大转盘，沿江大道的二初门口，卢沟桥路和中山大道的交汇口……每天早晨七点与傍晚六点，车流和车中的人们在这里相遇，相互鸣笛致意以后分别奔向各自的远方，无论风还是雨亦或是晴空万里。坐在早晨的车流里是一件有趣又让人恼火的事情。恼火是因为自己的事——上班或者上学会被耽误；有趣的确实周围的人们：有人急急忙忙向前挤却不得寸进，有人不慌不忙稳若泰山，自顾自的行驶在直行道上；有的笨蛋走错了路，在路中央来个大转弯，也有技艺高超的昆虫一般的骑手穿越在车流中一骑绝尘，片叶不沾身，好不潇洒。</p><p>突然想到动物世界开场的时候，万类霜天，正如同早晨的城市；我们看似在钢铁城市里却也在森林中，很多人逃避自己的原始却不知我们回到的正是原始的怀抱。</p><p>动物的进化不是一朝一夕的事情，城市的返祖亦然。三体中曾写到：“与上一个时代相比，掩体世界远不是理想社会，向太阳系边缘的大移民使得早已消失的一些社会形态又出现了，但这不是倒退而是螺旋形上升，是开拓新疆域必然出现的东西。”掩体世界的建成花费了数十年时间，我们的城市彻底“建成”又需要多久？时至如今的上一辈人们仍然难以控制随地吐痰之类我们公认的陋习，那是因为他们从本质上仍然属于乡村——那个建立在平原上的小小聚居地，而古代的城市纵然雕楼画栋，亦不过是“村庄Pro”，一切美的本质仍然来自修饰的木材、烧制的琉璃和源于泥土的砖瓦。直到水泥和混凝土的发明，直到蒸汽机和重型机械的问世，人们才受到时代变迁的改造，从灵魂上逐渐演变成另一种无所谓优劣却决然不同的生命。</p><p>是啊，我们在城市里长大，我们是城市的孩子。楼林间川行的我们忘却曾经土地上以人情为核心的道德秩序，转而遵循城市森林的法则。法律的底线和秩序的追求，从形而下的“术”到形而上的“道”，从一村之野到开阖的目光，我们在改变着自己，时代的旋进不会留恋任何人，当城市的形式被淘汰我们也将成为怀念过去的保守者，在赛博朋克的时代我们会怀念童年的小区和大商场，怀念关窗锁门一个人居家的安宁，怀念夏日午后独自醒来时内心的孤单，怀念学校，怀念青春，就如当前的他们。</p><p>深夜的楼林浸没在暮色里，黝黑只看见重叠的影，似在风中摇曳又厚重如山川。走在楼下时仰起头，楼檐与深蓝色的天空融为一体，像一口没有尽头的井。一抹抹霓虹被随意地抹在云上，幽幽的闪烁着。画家是楼间的灯带，整座城市的灯光又一个中央系统管控，立体的画面在城市中展示，却只有少少的窗口可以欣赏，余下的被抛入虚无的夜空中和喧嚣一同落幕。</p><p>每日每夜我穿行在楼林间，像原始森林上下攀爬的猿猴。想到乡土作家们感叹乡村应该是所有人的故乡，我又暗自哂笑他们自以为代表了人类。他们怀念乡村的自然和清新，殊不知我们在横平竖直又纵横穿插的楼林间出生和成长，回到茂密的原始森林的质朴怀抱，在沉睡间寻找到我们的故乡。</p>]]></content>
    
    
    <categories>
      
      <category>散文</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
